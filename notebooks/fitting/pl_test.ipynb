{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97abbd29-617f-443b-8384-e77a15638747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import glob\n",
    "import random\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "\n",
    "import shap\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "\n",
    "import mdtraj as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b0ac053-5cda-4286-8850-78c6d294023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, \"../../python\")\n",
    "sys.path.insert(1, \"../../..\")\n",
    "import util\n",
    "import plotting\n",
    "import ga_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afae8a0d-7b15-483c-aff4-001cea6ead29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"custom\")  # custom style sheet\n",
    "plt.style.use(\"muted\")  # muted color theme from SciencePlots\n",
    "cm_seq = sns.cubehelix_palette(\n",
    "    start=0, rot=-0.70, gamma=0.40, light=0.9, dark=0.1, as_cmap=True, reverse=True\n",
    ")\n",
    "cm_seq2 = sns.cubehelix_palette(\n",
    "    start=0, rot=-0.70, gamma=0.40, light=0.8, dark=0.1, as_cmap=True, reverse=False\n",
    ")\n",
    "colors = mpl.colors.to_rgba_array(\n",
    "    [\n",
    "        \"#364B9A\",\n",
    "        \"#4A7BB7\",\n",
    "        \"#6EA6CD\",\n",
    "        \"#98CAE1\",\n",
    "        \"#C2E4EF\",\n",
    "        \"#EAECCC\",\n",
    "        \"#FEDA8B\",\n",
    "        \"#FDB366\",\n",
    "        \"#F67E4B\",\n",
    "        \"#DD3D2D\",\n",
    "        \"#A50026\",\n",
    "    ]\n",
    ")\n",
    "cm_div = mpl.colors.LinearSegmentedColormap.from_list(\"\", colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d29848c-32eb-4414-8130-bd215e67678c",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce4d804b-dd37-4035-bc3f-dd79a02a70e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_trajs = list(\n",
    "    np.load(\"../../data/raw_feat/cv_dist_spin_anton.npy\", allow_pickle=True)\n",
    ")\n",
    "cv_trajs.extend(np.load(\"../../data/raw_feat/cv_dist_spin_anton2.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ad070b3-c915-476c-8384-a791734a975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_labels = []\n",
    "for r in (\"R217\", \"R223\", \"R226\", \"R229\", \"R232\"):\n",
    "    for n in (\"D129\", \"D136\", \"D151\", \"D164\", \"E183\", \"D186\"):\n",
    "        sb_labels.append(f\"{r} - {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8509bfe3-e0ab-4dc3-9562-e295d677f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_trajs = list(np.load(\"../../data/raw_feat/feat2_raw_anton.npy\", allow_pickle=True))\n",
    "sb_trajs.extend(np.load(\"../../data/raw_feat/feat2_raw_anton2.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2d88050-dbf1-4b1f-b6de-c3e130642ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4150115, 2) (4150115, 60)\n"
     ]
    }
   ],
   "source": [
    "cv_arr = np.concatenate(cv_trajs)\n",
    "sb_arr = np.concatenate(sb_trajs)\n",
    "print(cv_arr.shape, sb_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d08d22d-6b2b-4db0-b5e1-0d32732ffaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load committors\n",
    "q = np.load(\"../../data/feat2_dist_du_anton2/qp_downup_3.npy\", allow_pickle=True)[\n",
    "    8\n",
    "]  # 50 ns\n",
    "w = np.load(\n",
    "    \"../../data/feat2_dist_du_anton2/weights_3_feat5ivac.npy\", allow_pickle=True\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "95fa923b-51d5-4c88-87c6-f57661aa3a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4150115, 62]) torch.Size([4150115, 1])\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor(np.hstack((cv_arr, sb_arr)))\n",
    "y = torch.Tensor(np.concatenate(q)).unsqueeze(-1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaf68992-fd10-4a0d-a88e-e7dc9f7de68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc7395b4-8116-4da4-97c9-f4fd73202718",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerNet(pl.LightningModule):\n",
    "    \"\"\"Neural network with a multiple hidden layers\n",
    "    and sigmoid activation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, input_dim, hidden_dim=30, output_dim=1, n_hidden=5, verbose=True\n",
    "    ):\n",
    "        super(MultiLayerNet, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "        for _ in range(n_hidden):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        # Compute prediction and loss\n",
    "        pred = self.net(X)\n",
    "        loss = F.mse_loss(pred, y)\n",
    "\n",
    "        if self.verbose:\n",
    "            # if batch_idx % 100 == 0:\n",
    "            #     loss, current = loss.item(), batch * len(X)\n",
    "            #     print(f\"loss: {loss:>7f}  [{current:>5d}/]\")\n",
    "            self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=4e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        pred = self.net(x)\n",
    "        loss = F.mse_loss(pred, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        pred = self.net(x)\n",
    "        loss = F.mse_loss(pred, y)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bde813fc-387f-4291-9d26-1e3fce7a419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X.shape[-1]\n",
    "hidden_dim = 30\n",
    "n_layers = 3\n",
    "mlp = MultiLayerNet(input_dim, hidden_dim=hidden_dim, n_hidden=n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a36bb80e-3495-43cc-98d4-c314c056d573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3320092, 62]) torch.Size([622517, 62]) torch.Size([207506, 62]) torch.Size([3320092, 1]) torch.Size([622517, 1]) torch.Size([207506, 1])\n"
     ]
    }
   ],
   "source": [
    "# 80/15/5 train/val/test split\n",
    "train_X, val_X, train_y, val_y = sklearn.model_selection.train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123\n",
    ")\n",
    "val_X, test_X, val_y, test_y = sklearn.model_selection.train_test_split(val_X, val_y, test_size=0.25, random_state=123)\n",
    "print(train_X.shape, val_X.shape, test_X.shape, train_y.shape, val_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f11f8bc1-eda1-447f-b561-4aae6ad59648",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16384\n",
    "train_dataset = ga_pl.CommittorDataset(train_X, train_y)\n",
    "train_batches = DataLoader(train_dataset, batch_size=batch_size, num_workers=32)\n",
    "val_dataset = ga_pl.CommittorDataset(val_X, val_y)\n",
    "val_batches = DataLoader(val_dataset, batch_size=batch_size, num_workers=32)\n",
    "test_dataset = ga_pl.CommittorDataset(test_X, test_y)\n",
    "test_batches = DataLoader(test_dataset, batch_size=batch_size, num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d5382919-5a4f-4a5e-b259-331d4a4fe6a5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "`trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.fit(train_dataloaders)` instead. HINT: added 's'\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | net  | Sequential | 4.7 K \n",
      "------------------------------------\n",
      "4.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.7 K     Total params\n",
      "0.019     Total estimated model params size (MB)\n",
      "Checkpoint directory /project/dinner/scguo/ci-vsd/notebooks/nn/lightning_logs/version_3845523/checkpoints exists and is not empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  84%|████████▍ | 203/241 [00:04<00:00, 47.50it/s, loss=0.00207, v_num=3845523, train_loss_step=0.00198]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 0:  91%|█████████▏| 220/241 [00:05<00:00, 37.75it/s, loss=0.00207, v_num=3845523, train_loss_step=0.00198]\n",
      "Epoch 0: 100%|██████████| 241/241 [00:05<00:00, 40.39it/s, loss=0.00207, v_num=3845523, train_loss_step=0.00198]\n",
      "Epoch 1:  84%|████████▍ | 203/241 [00:03<00:00, 52.92it/s, loss=0.00141, v_num=3845523, train_loss_step=0.00148, train_loss_epoch=0.0084]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 1:  90%|█████████ | 217/241 [00:05<00:00, 40.09it/s, loss=0.00141, v_num=3845523, train_loss_step=0.00148, train_loss_epoch=0.0084]\n",
      "Epoch 1: 100%|██████████| 241/241 [00:05<00:00, 43.39it/s, loss=0.00141, v_num=3845523, train_loss_step=0.00148, train_loss_epoch=0.0084]\n",
      "Epoch 2:  84%|████████▍ | 203/241 [00:03<00:00, 55.65it/s, loss=0.00107, v_num=3845523, train_loss_step=0.00105, train_loss_epoch=0.00168]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 2:  90%|████████▉ | 216/241 [00:05<00:00, 41.05it/s, loss=0.00107, v_num=3845523, train_loss_step=0.00105, train_loss_epoch=0.00168]\n",
      "Epoch 2: 100%|██████████| 241/241 [00:05<00:00, 44.52it/s, loss=0.00107, v_num=3845523, train_loss_step=0.00105, train_loss_epoch=0.00168]\n",
      "Epoch 3:  84%|████████▍ | 203/241 [00:03<00:00, 51.43it/s, loss=0.001, v_num=3845523, train_loss_step=0.001, train_loss_epoch=0.00124]      \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 3:  90%|████████▉ | 216/241 [00:05<00:00, 38.90it/s, loss=0.001, v_num=3845523, train_loss_step=0.001, train_loss_epoch=0.00124]\n",
      "Epoch 3: 100%|██████████| 241/241 [00:05<00:00, 42.25it/s, loss=0.001, v_num=3845523, train_loss_step=0.001, train_loss_epoch=0.00124]\n",
      "Epoch 4:  84%|████████▍ | 203/241 [00:03<00:00, 54.96it/s, loss=0.000824, v_num=3845523, train_loss_step=0.000945, train_loss_epoch=0.00102]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 4:  90%|████████▉ | 216/241 [00:05<00:00, 40.77it/s, loss=0.000824, v_num=3845523, train_loss_step=0.000945, train_loss_epoch=0.00102]\n",
      "Epoch 4: 100%|██████████| 241/241 [00:05<00:00, 44.24it/s, loss=0.000824, v_num=3845523, train_loss_step=0.000945, train_loss_epoch=0.00102]\n",
      "Epoch 5:  84%|████████▍ | 203/241 [00:03<00:00, 55.18it/s, loss=0.000744, v_num=3845523, train_loss_step=0.000701, train_loss_epoch=0.000871]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 5:  90%|████████▉ | 216/241 [00:05<00:00, 41.26it/s, loss=0.000744, v_num=3845523, train_loss_step=0.000701, train_loss_epoch=0.000871]\n",
      "Epoch 5: 100%|██████████| 241/241 [00:05<00:00, 44.71it/s, loss=0.000744, v_num=3845523, train_loss_step=0.000701, train_loss_epoch=0.000871]\n",
      "Epoch 6:  84%|████████▍ | 203/241 [00:04<00:00, 50.19it/s, loss=0.00062, v_num=3845523, train_loss_step=0.000644, train_loss_epoch=0.000795] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 6:  90%|████████▉ | 216/241 [00:05<00:00, 38.31it/s, loss=0.00062, v_num=3845523, train_loss_step=0.000644, train_loss_epoch=0.000795]\n",
      "Epoch 6: 100%|██████████| 241/241 [00:05<00:00, 41.64it/s, loss=0.00062, v_num=3845523, train_loss_step=0.000644, train_loss_epoch=0.000795]\n",
      "Epoch 7:  84%|████████▍ | 203/241 [00:03<00:00, 51.96it/s, loss=0.000627, v_num=3845523, train_loss_step=0.000657, train_loss_epoch=0.000765]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 7:  90%|████████▉ | 216/241 [00:05<00:00, 38.60it/s, loss=0.000627, v_num=3845523, train_loss_step=0.000657, train_loss_epoch=0.000765]\n",
      "Epoch 7: 100%|██████████| 241/241 [00:05<00:00, 41.56it/s, loss=0.000627, v_num=3845523, train_loss_step=0.000657, train_loss_epoch=0.000765]\n",
      "Epoch 8:  84%|████████▍ | 203/241 [00:04<00:00, 49.42it/s, loss=0.000637, v_num=3845523, train_loss_step=0.0006, train_loss_epoch=0.000642]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "                                                              s=0.000637, v_num=3845523, train_loss_step=0.0006, train_loss_epoch=0.000642]\n",
      "Epoch 8: 100%|██████████| 241/241 [00:05<00:00, 40.54it/s, loss=0.000637, v_num=3845523, train_loss_step=0.0006, train_loss_epoch=0.000642]\n",
      "Epoch 9:  84%|████████▍ | 203/241 [00:03<00:00, 52.49it/s, loss=0.000554, v_num=3845523, train_loss_step=0.000569, train_loss_epoch=0.000621]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "                                                              \n",
      "Epoch 9:  90%|████████▉ | 216/241 [00:05<00:00, 38.63it/s, loss=0.000554, v_num=3845523, train_loss_step=0.000569, train_loss_epoch=0.000621]\n",
      "Epoch 9: 100%|██████████| 241/241 [00:05<00:00, 41.65it/s, loss=0.000554, v_num=3845523, train_loss_step=0.000569, train_loss_epoch=0.000621]\n",
      "Epoch 10:  84%|████████▍ | 203/241 [00:04<00:00, 50.65it/s, loss=0.000518, v_num=3845523, train_loss_step=0.000544, train_loss_epoch=0.000575]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 10:  90%|████████▉ | 216/241 [00:05<00:00, 37.83it/s, loss=0.000518, v_num=3845523, train_loss_step=0.000544, train_loss_epoch=0.000575]\n",
      "Validating:  63%|██████▎   | 24/38 [00:01<00:00, 19.00it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 241/241 [00:05<00:00, 40.68it/s, loss=0.000518, v_num=3845523, train_loss_step=0.000544, train_loss_epoch=0.000575]\n",
      "Epoch 11:  84%|████████▍ | 203/241 [00:03<00:00, 55.63it/s, loss=0.000494, v_num=3845523, train_loss_step=0.000488, train_loss_epoch=0.000558]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "                                                              ss=0.000494, v_num=3845523, train_loss_step=0.000488, train_loss_epoch=0.000558]\n",
      "Validating:  42%|████▏     | 16/38 [00:01<00:01, 12.71it/s]\u001b[A\n",
      "Epoch 11: 100%|██████████| 241/241 [00:05<00:00, 43.36it/s, loss=0.000494, v_num=3845523, train_loss_step=0.000488, train_loss_epoch=0.000558]\n",
      "Epoch 12:  84%|████████▍ | 203/241 [00:03<00:00, 50.98it/s, loss=0.000496, v_num=3845523, train_loss_step=0.000465, train_loss_epoch=0.000542]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "                                                              \n",
      "Epoch 12:  90%|████████▉ | 216/241 [00:05<00:00, 38.18it/s, loss=0.000496, v_num=3845523, train_loss_step=0.000465, train_loss_epoch=0.000542]\n",
      "Epoch 12: 100%|██████████| 241/241 [00:05<00:00, 41.21it/s, loss=0.000496, v_num=3845523, train_loss_step=0.000465, train_loss_epoch=0.000542]\n",
      "Epoch 13:  84%|████████▍ | 203/241 [00:03<00:00, 51.51it/s, loss=0.000476, v_num=3845523, train_loss_step=0.000491, train_loss_epoch=0.000536]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 13:  90%|████████▉ | 216/241 [00:05<00:00, 38.16it/s, loss=0.000476, v_num=3845523, train_loss_step=0.000491, train_loss_epoch=0.000536]\n",
      "Epoch 13: 100%|██████████| 241/241 [00:05<00:00, 41.17it/s, loss=0.000476, v_num=3845523, train_loss_step=0.000491, train_loss_epoch=0.000536]\n",
      "Epoch 14:  84%|████████▍ | 203/241 [00:03<00:00, 54.37it/s, loss=0.000462, v_num=3845523, train_loss_step=0.000478, train_loss_epoch=0.000508]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 14:  90%|████████▉ | 216/241 [00:05<00:00, 39.98it/s, loss=0.000462, v_num=3845523, train_loss_step=0.000478, train_loss_epoch=0.000508]\n",
      "Epoch 14: 100%|██████████| 241/241 [00:05<00:00, 43.04it/s, loss=0.000462, v_num=3845523, train_loss_step=0.000478, train_loss_epoch=0.000508]\n",
      "Epoch 15:  84%|████████▍ | 203/241 [00:03<00:00, 53.89it/s, loss=0.000453, v_num=3845523, train_loss_step=0.000422, train_loss_epoch=0.000496]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 15:  90%|████████▉ | 216/241 [00:05<00:00, 39.37it/s, loss=0.000453, v_num=3845523, train_loss_step=0.000422, train_loss_epoch=0.000496]\n",
      "Epoch 15: 100%|██████████| 241/241 [00:05<00:00, 42.40it/s, loss=0.000453, v_num=3845523, train_loss_step=0.000422, train_loss_epoch=0.000496]\n",
      "Epoch 16:  84%|████████▍ | 203/241 [00:04<00:00, 47.14it/s, loss=0.000459, v_num=3845523, train_loss_step=0.000415, train_loss_epoch=0.000477]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 16:  90%|████████▉ | 216/241 [00:05<00:00, 36.45it/s, loss=0.000459, v_num=3845523, train_loss_step=0.000415, train_loss_epoch=0.000477]\n",
      "Epoch 16: 100%|██████████| 241/241 [00:06<00:00, 39.36it/s, loss=0.000459, v_num=3845523, train_loss_step=0.000415, train_loss_epoch=0.000477]\n",
      "Epoch 17:  84%|████████▍ | 203/241 [00:04<00:00, 47.46it/s, loss=0.000517, v_num=3845523, train_loss_step=0.000469, train_loss_epoch=0.000468]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 17:  90%|████████▉ | 216/241 [00:05<00:00, 36.43it/s, loss=0.000517, v_num=3845523, train_loss_step=0.000469, train_loss_epoch=0.000468]\n",
      "Epoch 17: 100%|██████████| 241/241 [00:06<00:00, 39.36it/s, loss=0.000517, v_num=3845523, train_loss_step=0.000469, train_loss_epoch=0.000468]\n",
      "Epoch 18:  84%|████████▍ | 203/241 [00:04<00:00, 42.18it/s, loss=0.000496, v_num=3845523, train_loss_step=0.000435, train_loss_epoch=0.000464]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 18:  90%|████████▉ | 216/241 [00:06<00:00, 33.34it/s, loss=0.000496, v_num=3845523, train_loss_step=0.000435, train_loss_epoch=0.000464]\n",
      "Epoch 18: 100%|██████████| 241/241 [00:06<00:00, 36.06it/s, loss=0.000496, v_num=3845523, train_loss_step=0.000435, train_loss_epoch=0.000464]\n",
      "Epoch 19:  84%|████████▍ | 203/241 [00:04<00:00, 41.64it/s, loss=0.000395, v_num=3845523, train_loss_step=0.000386, train_loss_epoch=0.000451]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "                                                              \n",
      "Epoch 19:  90%|████████▉ | 216/241 [00:06<00:00, 32.80it/s, loss=0.000395, v_num=3845523, train_loss_step=0.000386, train_loss_epoch=0.000451]\n",
      "Epoch 19: 100%|██████████| 241/241 [00:06<00:00, 35.54it/s, loss=0.000395, v_num=3845523, train_loss_step=0.000386, train_loss_epoch=0.000451]\n",
      "Epoch 20:  84%|████████▍ | 203/241 [00:05<00:00, 40.21it/s, loss=0.000465, v_num=3845523, train_loss_step=0.000446, train_loss_epoch=0.000435]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 20:  90%|████████▉ | 216/241 [00:06<00:00, 32.25it/s, loss=0.000465, v_num=3845523, train_loss_step=0.000446, train_loss_epoch=0.000435]\n",
      "Epoch 20: 100%|██████████| 241/241 [00:06<00:00, 34.88it/s, loss=0.000465, v_num=3845523, train_loss_step=0.000446, train_loss_epoch=0.000435]\n",
      "Epoch 21:  84%|████████▍ | 203/241 [00:04<00:00, 48.34it/s, loss=0.000397, v_num=3845523, train_loss_step=0.000398, train_loss_epoch=0.000437]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 21:  90%|████████▉ | 216/241 [00:05<00:00, 36.66it/s, loss=0.000397, v_num=3845523, train_loss_step=0.000398, train_loss_epoch=0.000437]\n",
      "Epoch 21: 100%|██████████| 241/241 [00:06<00:00, 39.56it/s, loss=0.000397, v_num=3845523, train_loss_step=0.000398, train_loss_epoch=0.000437]\n",
      "Epoch 22:  84%|████████▍ | 203/241 [00:04<00:00, 45.95it/s, loss=0.000411, v_num=3845523, train_loss_step=0.000363, train_loss_epoch=0.000418]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 22:  90%|████████▉ | 216/241 [00:06<00:00, 35.33it/s, loss=0.000411, v_num=3845523, train_loss_step=0.000363, train_loss_epoch=0.000418]\n",
      "Validating:  37%|███▋      | 14/38 [00:01<00:02, 11.25it/s]\u001b[A\n",
      "Epoch 22: 100%|██████████| 241/241 [00:06<00:00, 38.22it/s, loss=0.000411, v_num=3845523, train_loss_step=0.000363, train_loss_epoch=0.000418]\n",
      "Epoch 23:  84%|████████▍ | 203/241 [00:04<00:00, 48.36it/s, loss=0.000463, v_num=3845523, train_loss_step=0.000392, train_loss_epoch=0.000418]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 23:  90%|████████▉ | 216/241 [00:05<00:00, 37.40it/s, loss=0.000463, v_num=3845523, train_loss_step=0.000392, train_loss_epoch=0.000418]\n",
      "Epoch 23: 100%|██████████| 241/241 [00:05<00:00, 40.19it/s, loss=0.000463, v_num=3845523, train_loss_step=0.000392, train_loss_epoch=0.000418]\n",
      "Epoch 24:  84%|████████▍ | 203/241 [00:04<00:00, 46.70it/s, loss=0.000397, v_num=3845523, train_loss_step=0.00043, train_loss_epoch=0.000413] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "                                                              \n",
      "Epoch 24:  90%|████████▉ | 216/241 [00:06<00:00, 35.74it/s, loss=0.000397, v_num=3845523, train_loss_step=0.00043, train_loss_epoch=0.000413]\n",
      "Epoch 24: 100%|██████████| 241/241 [00:06<00:00, 38.65it/s, loss=0.000397, v_num=3845523, train_loss_step=0.00043, train_loss_epoch=0.000413]\n",
      "Epoch 25:  84%|████████▍ | 203/241 [00:04<00:00, 46.18it/s, loss=0.000385, v_num=3845523, train_loss_step=0.000347, train_loss_epoch=0.0004] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 25:  90%|████████▉ | 216/241 [00:06<00:00, 35.53it/s, loss=0.000385, v_num=3845523, train_loss_step=0.000347, train_loss_epoch=0.0004]\n",
      "Epoch 25: 100%|██████████| 241/241 [00:06<00:00, 38.39it/s, loss=0.000385, v_num=3845523, train_loss_step=0.000347, train_loss_epoch=0.0004]\n",
      "Epoch 26:  84%|████████▍ | 203/241 [00:04<00:00, 50.15it/s, loss=0.000429, v_num=3845523, train_loss_step=0.00037, train_loss_epoch=0.000395] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 26:  90%|████████▉ | 216/241 [00:05<00:00, 37.50it/s, loss=0.000429, v_num=3845523, train_loss_step=0.00037, train_loss_epoch=0.000395]\n",
      "Epoch 26: 100%|██████████| 241/241 [00:05<00:00, 40.57it/s, loss=0.000429, v_num=3845523, train_loss_step=0.00037, train_loss_epoch=0.000395]\n",
      "Epoch 27:  84%|████████▍ | 203/241 [00:04<00:00, 50.73it/s, loss=0.000365, v_num=3845523, train_loss_step=0.00039, train_loss_epoch=0.000394] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 27:  90%|████████▉ | 216/241 [00:05<00:00, 37.88it/s, loss=0.000365, v_num=3845523, train_loss_step=0.00039, train_loss_epoch=0.000394]\n",
      "Epoch 27: 100%|██████████| 241/241 [00:05<00:00, 40.90it/s, loss=0.000365, v_num=3845523, train_loss_step=0.00039, train_loss_epoch=0.000394]\n",
      "Epoch 28:  84%|████████▍ | 203/241 [00:04<00:00, 49.71it/s, loss=0.000365, v_num=3845523, train_loss_step=0.000349, train_loss_epoch=0.000385]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                              \n",
      "Epoch 28:  90%|████████▉ | 216/241 [00:05<00:00, 36.16it/s, loss=0.000365, v_num=3845523, train_loss_step=0.000349, train_loss_epoch=0.000385]\n",
      "Epoch 28: 100%|██████████| 241/241 [00:06<00:00, 38.95it/s, loss=0.000365, v_num=3845523, train_loss_step=0.000349, train_loss_epoch=0.000385]\n",
      "Epoch 29:  84%|████████▍ | 203/241 [00:03<00:00, 51.85it/s, loss=0.000342, v_num=3845523, train_loss_step=0.00032, train_loss_epoch=0.000377] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 29:  90%|████████▉ | 216/241 [00:05<00:00, 41.88it/s, loss=0.000342, v_num=3845523, train_loss_step=0.00032, train_loss_epoch=0.000377]\n",
      "Epoch 29: 100%|██████████| 241/241 [00:05<00:00, 45.37it/s, loss=0.000342, v_num=3845523, train_loss_step=0.00032, train_loss_epoch=0.000377]\n",
      "Epoch 30:  84%|████████▍ | 203/241 [00:03<00:00, 57.41it/s, loss=0.000329, v_num=3845523, train_loss_step=0.000315, train_loss_epoch=0.000376]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 30:  90%|████████▉ | 216/241 [00:04<00:00, 45.09it/s, loss=0.000329, v_num=3845523, train_loss_step=0.000315, train_loss_epoch=0.000376]\n",
      "Epoch 30: 100%|██████████| 241/241 [00:04<00:00, 48.72it/s, loss=0.000329, v_num=3845523, train_loss_step=0.000315, train_loss_epoch=0.000376]\n",
      "Epoch 31:  84%|████████▍ | 203/241 [00:03<00:00, 53.35it/s, loss=0.000368, v_num=3845523, train_loss_step=0.000429, train_loss_epoch=0.00037] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 31:  90%|████████▉ | 216/241 [00:05<00:00, 42.96it/s, loss=0.000368, v_num=3845523, train_loss_step=0.000429, train_loss_epoch=0.00037]\n",
      "Epoch 31: 100%|██████████| 241/241 [00:05<00:00, 46.43it/s, loss=0.000368, v_num=3845523, train_loss_step=0.000429, train_loss_epoch=0.00037]\n",
      "Epoch 32:  84%|████████▍ | 203/241 [00:04<00:00, 44.04it/s, loss=0.000401, v_num=3845523, train_loss_step=0.000445, train_loss_epoch=0.000369]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 32:  90%|████████▉ | 216/241 [00:05<00:00, 36.89it/s, loss=0.000401, v_num=3845523, train_loss_step=0.000445, train_loss_epoch=0.000369]\n",
      "Epoch 32: 100%|██████████| 241/241 [00:06<00:00, 40.08it/s, loss=0.000401, v_num=3845523, train_loss_step=0.000445, train_loss_epoch=0.000369]\n",
      "Epoch 33:  84%|████████▍ | 203/241 [00:03<00:00, 51.01it/s, loss=0.000331, v_num=3845523, train_loss_step=0.000349, train_loss_epoch=0.000362]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 33:  90%|████████▉ | 216/241 [00:05<00:00, 40.90it/s, loss=0.000331, v_num=3845523, train_loss_step=0.000349, train_loss_epoch=0.000362]\n",
      "Validating:  63%|██████▎   | 24/38 [00:01<00:00, 24.82it/s]\u001b[A\n",
      "Epoch 33: 100%|██████████| 241/241 [00:05<00:00, 44.38it/s, loss=0.000331, v_num=3845523, train_loss_step=0.000349, train_loss_epoch=0.000362]\n",
      "Epoch 34:  84%|████████▍ | 203/241 [00:03<00:00, 51.26it/s, loss=0.000325, v_num=3845523, train_loss_step=0.000344, train_loss_epoch=0.000355]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 34:  90%|████████▉ | 216/241 [00:05<00:00, 41.17it/s, loss=0.000325, v_num=3845523, train_loss_step=0.000344, train_loss_epoch=0.000355]\n",
      "Epoch 34: 100%|██████████| 241/241 [00:05<00:00, 44.55it/s, loss=0.000325, v_num=3845523, train_loss_step=0.000344, train_loss_epoch=0.000355]\n",
      "Epoch 35:  84%|████████▍ | 203/241 [00:03<00:00, 52.50it/s, loss=0.000357, v_num=3845523, train_loss_step=0.000405, train_loss_epoch=0.00035] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 35:  90%|████████▉ | 216/241 [00:05<00:00, 42.04it/s, loss=0.000357, v_num=3845523, train_loss_step=0.000405, train_loss_epoch=0.00035]\n",
      "Epoch 35: 100%|██████████| 241/241 [00:05<00:00, 45.55it/s, loss=0.000357, v_num=3845523, train_loss_step=0.000405, train_loss_epoch=0.00035]\n",
      "Epoch 36:  84%|████████▍ | 203/241 [00:03<00:00, 52.71it/s, loss=0.000347, v_num=3845523, train_loss_step=0.000297, train_loss_epoch=0.000349]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 36:  90%|████████▉ | 216/241 [00:05<00:00, 41.85it/s, loss=0.000347, v_num=3845523, train_loss_step=0.000297, train_loss_epoch=0.000349]\n",
      "Epoch 36: 100%|██████████| 241/241 [00:05<00:00, 45.44it/s, loss=0.000347, v_num=3845523, train_loss_step=0.000297, train_loss_epoch=0.000349]\n",
      "Epoch 37:  84%|████████▍ | 203/241 [00:04<00:00, 47.54it/s, loss=0.000355, v_num=3845523, train_loss_step=0.000362, train_loss_epoch=0.000346]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 37:  90%|████████▉ | 216/241 [00:05<00:00, 39.24it/s, loss=0.000355, v_num=3845523, train_loss_step=0.000362, train_loss_epoch=0.000346]\n",
      "Epoch 37: 100%|██████████| 241/241 [00:05<00:00, 42.59it/s, loss=0.000355, v_num=3845523, train_loss_step=0.000362, train_loss_epoch=0.000346]\n",
      "Epoch 38:  84%|████████▍ | 203/241 [00:03<00:00, 57.03it/s, loss=0.000319, v_num=3845523, train_loss_step=0.000329, train_loss_epoch=0.000351]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 38:  90%|████████▉ | 216/241 [00:05<00:00, 42.11it/s, loss=0.000319, v_num=3845523, train_loss_step=0.000329, train_loss_epoch=0.000351]\n",
      "Epoch 38: 100%|██████████| 241/241 [00:05<00:00, 45.62it/s, loss=0.000319, v_num=3845523, train_loss_step=0.000329, train_loss_epoch=0.000351]\n",
      "Epoch 39:  84%|████████▍ | 203/241 [00:03<00:00, 54.24it/s, loss=0.000296, v_num=3845523, train_loss_step=0.000289, train_loss_epoch=0.000341]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:55,  1.51s/it]\u001b[A\n",
      "Epoch 39:  90%|████████▉ | 216/241 [00:05<00:00, 40.22it/s, loss=0.000296, v_num=3845523, train_loss_step=0.000289, train_loss_epoch=0.000341]\n",
      "Epoch 39: 100%|██████████| 241/241 [00:05<00:00, 43.53it/s, loss=0.000296, v_num=3845523, train_loss_step=0.000289, train_loss_epoch=0.000341]\n",
      "Epoch 40:  84%|████████▍ | 203/241 [00:03<00:00, 58.91it/s, loss=0.000306, v_num=3845523, train_loss_step=0.000289, train_loss_epoch=0.000331]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 40:  90%|████████▉ | 216/241 [00:05<00:00, 42.93it/s, loss=0.000306, v_num=3845523, train_loss_step=0.000289, train_loss_epoch=0.000331]\n",
      "Validating:  47%|████▋     | 18/38 [00:01<00:01, 15.45it/s]\u001b[A\n",
      "Epoch 40: 100%|██████████| 241/241 [00:05<00:00, 46.43it/s, loss=0.000306, v_num=3845523, train_loss_step=0.000289, train_loss_epoch=0.000331]\n",
      "Epoch 41:  84%|████████▍ | 203/241 [00:03<00:00, 60.48it/s, loss=0.000305, v_num=3845523, train_loss_step=0.000302, train_loss_epoch=0.000334]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 41:  90%|████████▉ | 216/241 [00:05<00:00, 40.60it/s, loss=0.000305, v_num=3845523, train_loss_step=0.000302, train_loss_epoch=0.000334]\n",
      "Epoch 41: 100%|██████████| 241/241 [00:05<00:00, 43.94it/s, loss=0.000305, v_num=3845523, train_loss_step=0.000302, train_loss_epoch=0.000334]\n",
      "Epoch 42:  84%|████████▍ | 203/241 [00:03<00:00, 54.30it/s, loss=0.000296, v_num=3845523, train_loss_step=0.000279, train_loss_epoch=0.000333]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 42:  90%|████████▉ | 216/241 [00:05<00:00, 36.10it/s, loss=0.000296, v_num=3845523, train_loss_step=0.000279, train_loss_epoch=0.000333]\n",
      "Epoch 42: 100%|██████████| 241/241 [00:06<00:00, 39.20it/s, loss=0.000296, v_num=3845523, train_loss_step=0.000279, train_loss_epoch=0.000333]\n",
      "Epoch 43:  84%|████████▍ | 203/241 [00:03<00:00, 57.42it/s, loss=0.000334, v_num=3845523, train_loss_step=0.000312, train_loss_epoch=0.000328]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 43:  90%|████████▉ | 216/241 [00:05<00:00, 40.62it/s, loss=0.000334, v_num=3845523, train_loss_step=0.000312, train_loss_epoch=0.000328]\n",
      "Epoch 43: 100%|██████████| 241/241 [00:05<00:00, 44.11it/s, loss=0.000334, v_num=3845523, train_loss_step=0.000312, train_loss_epoch=0.000328]\n",
      "Epoch 44:  84%|████████▍ | 203/241 [00:03<00:00, 54.38it/s, loss=0.000317, v_num=3845523, train_loss_step=0.000381, train_loss_epoch=0.000326]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 44:  90%|████████▉ | 216/241 [00:05<00:00, 39.82it/s, loss=0.000317, v_num=3845523, train_loss_step=0.000381, train_loss_epoch=0.000326]\n",
      "Epoch 44: 100%|██████████| 241/241 [00:05<00:00, 43.24it/s, loss=0.000317, v_num=3845523, train_loss_step=0.000381, train_loss_epoch=0.000326]\n",
      "Epoch 45:  84%|████████▍ | 203/241 [00:03<00:00, 57.52it/s, loss=0.000342, v_num=3845523, train_loss_step=0.000363, train_loss_epoch=0.000325]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 45:  90%|████████▉ | 216/241 [00:05<00:00, 42.16it/s, loss=0.000342, v_num=3845523, train_loss_step=0.000363, train_loss_epoch=0.000325]\n",
      "Epoch 45: 100%|██████████| 241/241 [00:05<00:00, 45.76it/s, loss=0.000342, v_num=3845523, train_loss_step=0.000363, train_loss_epoch=0.000325]\n",
      "Epoch 46:  84%|████████▍ | 203/241 [00:03<00:00, 56.69it/s, loss=0.000322, v_num=3845523, train_loss_step=0.000273, train_loss_epoch=0.000318]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 46:  90%|████████▉ | 216/241 [00:05<00:00, 36.30it/s, loss=0.000322, v_num=3845523, train_loss_step=0.000273, train_loss_epoch=0.000318]\n",
      "Epoch 46: 100%|██████████| 241/241 [00:06<00:00, 39.55it/s, loss=0.000322, v_num=3845523, train_loss_step=0.000273, train_loss_epoch=0.000318]\n",
      "Epoch 47:  84%|████████▍ | 203/241 [00:04<00:00, 50.39it/s, loss=0.00032, v_num=3845523, train_loss_step=0.000294, train_loss_epoch=0.000316] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 47:  90%|████████▉ | 216/241 [00:05<00:00, 37.87it/s, loss=0.00032, v_num=3845523, train_loss_step=0.000294, train_loss_epoch=0.000316]\n",
      "Epoch 47: 100%|██████████| 241/241 [00:05<00:00, 41.11it/s, loss=0.00032, v_num=3845523, train_loss_step=0.000294, train_loss_epoch=0.000316]\n",
      "Epoch 48:  84%|████████▍ | 203/241 [00:03<00:00, 53.10it/s, loss=0.000299, v_num=3845523, train_loss_step=0.000355, train_loss_epoch=0.000318]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:56,  1.53s/it]\u001b[A\n",
      "Epoch 48:  90%|████████▉ | 216/241 [00:05<00:00, 39.48it/s, loss=0.000299, v_num=3845523, train_loss_step=0.000355, train_loss_epoch=0.000318]\n",
      "Epoch 48: 100%|██████████| 241/241 [00:05<00:00, 42.90it/s, loss=0.000299, v_num=3845523, train_loss_step=0.000355, train_loss_epoch=0.000318]\n",
      "Epoch 49:  84%|████████▍ | 203/241 [00:03<00:00, 54.87it/s, loss=0.000296, v_num=3845523, train_loss_step=0.000284, train_loss_epoch=0.000307]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 49:  90%|████████▉ | 216/241 [00:05<00:00, 40.31it/s, loss=0.000296, v_num=3845523, train_loss_step=0.000284, train_loss_epoch=0.000307]\n",
      "Epoch 49: 100%|██████████| 241/241 [00:05<00:00, 43.87it/s, loss=0.000296, v_num=3845523, train_loss_step=0.000284, train_loss_epoch=0.000307]\n",
      "Epoch 50:  84%|████████▍ | 203/241 [00:04<00:00, 49.98it/s, loss=0.00037, v_num=3845523, train_loss_step=0.000352, train_loss_epoch=0.000314] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 50:  90%|████████▉ | 216/241 [00:05<00:00, 38.30it/s, loss=0.00037, v_num=3845523, train_loss_step=0.000352, train_loss_epoch=0.000314]\n",
      "Epoch 50: 100%|██████████| 241/241 [00:05<00:00, 41.59it/s, loss=0.00037, v_num=3845523, train_loss_step=0.000352, train_loss_epoch=0.000314]\n",
      "Epoch 51:  84%|████████▍ | 203/241 [00:04<00:00, 49.90it/s, loss=0.000298, v_num=3845523, train_loss_step=0.000287, train_loss_epoch=0.000307]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 51:  90%|████████▉ | 216/241 [00:05<00:00, 38.56it/s, loss=0.000298, v_num=3845523, train_loss_step=0.000287, train_loss_epoch=0.000307]\n",
      "Epoch 51: 100%|██████████| 241/241 [00:05<00:00, 41.95it/s, loss=0.000298, v_num=3845523, train_loss_step=0.000287, train_loss_epoch=0.000307]\n",
      "Epoch 52:  84%|████████▍ | 203/241 [00:03<00:00, 53.51it/s, loss=0.000325, v_num=3845523, train_loss_step=0.000353, train_loss_epoch=0.000304]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 52:  90%|████████▉ | 216/241 [00:05<00:00, 39.58it/s, loss=0.000325, v_num=3845523, train_loss_step=0.000353, train_loss_epoch=0.000304]\n",
      "Epoch 52: 100%|██████████| 241/241 [00:05<00:00, 42.94it/s, loss=0.000325, v_num=3845523, train_loss_step=0.000353, train_loss_epoch=0.000304]\n",
      "Epoch 53:  84%|████████▍ | 203/241 [00:04<00:00, 49.13it/s, loss=0.000331, v_num=3845523, train_loss_step=0.00028, train_loss_epoch=0.000308] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 53:  90%|████████▉ | 216/241 [00:06<00:00, 34.95it/s, loss=0.000331, v_num=3845523, train_loss_step=0.00028, train_loss_epoch=0.000308]\n",
      "Epoch 53: 100%|██████████| 241/241 [00:06<00:00, 38.01it/s, loss=0.000331, v_num=3845523, train_loss_step=0.00028, train_loss_epoch=0.000308]\n",
      "Epoch 54:  84%|████████▍ | 203/241 [00:03<00:00, 53.35it/s, loss=0.000316, v_num=3845523, train_loss_step=0.000317, train_loss_epoch=0.000299]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 54:  90%|████████▉ | 216/241 [00:05<00:00, 39.32it/s, loss=0.000316, v_num=3845523, train_loss_step=0.000317, train_loss_epoch=0.000299]\n",
      "Epoch 54: 100%|██████████| 241/241 [00:05<00:00, 42.65it/s, loss=0.000316, v_num=3845523, train_loss_step=0.000317, train_loss_epoch=0.000299]\n",
      "Epoch 55:  84%|████████▍ | 203/241 [00:03<00:00, 51.40it/s, loss=0.000286, v_num=3845523, train_loss_step=0.000252, train_loss_epoch=0.000301]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:58,  1.58s/it]\u001b[A\n",
      "Epoch 55:  90%|████████▉ | 216/241 [00:05<00:00, 37.35it/s, loss=0.000286, v_num=3845523, train_loss_step=0.000252, train_loss_epoch=0.000301]\n",
      "Epoch 55: 100%|██████████| 241/241 [00:05<00:00, 40.60it/s, loss=0.000286, v_num=3845523, train_loss_step=0.000252, train_loss_epoch=0.000301]\n",
      "Epoch 56:  84%|████████▍ | 203/241 [00:03<00:00, 53.08it/s, loss=0.000297, v_num=3845523, train_loss_step=0.000325, train_loss_epoch=0.000297]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 56:  90%|████████▉ | 216/241 [00:05<00:00, 38.22it/s, loss=0.000297, v_num=3845523, train_loss_step=0.000325, train_loss_epoch=0.000297]\n",
      "Epoch 56: 100%|██████████| 241/241 [00:05<00:00, 41.56it/s, loss=0.000297, v_num=3845523, train_loss_step=0.000325, train_loss_epoch=0.000297]\n",
      "Epoch 57:  84%|████████▍ | 203/241 [00:04<00:00, 50.27it/s, loss=0.000297, v_num=3845523, train_loss_step=0.000307, train_loss_epoch=0.000299]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 57:  90%|████████▉ | 216/241 [00:05<00:00, 38.68it/s, loss=0.000297, v_num=3845523, train_loss_step=0.000307, train_loss_epoch=0.000299]\n",
      "Epoch 57: 100%|██████████| 241/241 [00:05<00:00, 41.96it/s, loss=0.000297, v_num=3845523, train_loss_step=0.000307, train_loss_epoch=0.000299]\n",
      "Epoch 58:  84%|████████▍ | 203/241 [00:03<00:00, 52.12it/s, loss=0.000288, v_num=3845523, train_loss_step=0.000252, train_loss_epoch=0.000291]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 58:  90%|████████▉ | 216/241 [00:05<00:00, 39.31it/s, loss=0.000288, v_num=3845523, train_loss_step=0.000252, train_loss_epoch=0.000291]\n",
      "Epoch 58: 100%|██████████| 241/241 [00:05<00:00, 42.70it/s, loss=0.000288, v_num=3845523, train_loss_step=0.000252, train_loss_epoch=0.000291]\n",
      "Epoch 59:  84%|████████▍ | 203/241 [00:03<00:00, 52.12it/s, loss=0.000251, v_num=3845523, train_loss_step=0.000268, train_loss_epoch=0.000293]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 59:  90%|████████▉ | 216/241 [00:05<00:00, 39.54it/s, loss=0.000251, v_num=3845523, train_loss_step=0.000268, train_loss_epoch=0.000293]\n",
      "Epoch 59: 100%|██████████| 241/241 [00:05<00:00, 42.87it/s, loss=0.000251, v_num=3845523, train_loss_step=0.000268, train_loss_epoch=0.000293]\n",
      "Epoch 60:  84%|████████▍ | 203/241 [00:03<00:00, 54.48it/s, loss=0.000299, v_num=3845523, train_loss_step=0.000331, train_loss_epoch=0.000289]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 60:  90%|████████▉ | 216/241 [00:05<00:00, 40.70it/s, loss=0.000299, v_num=3845523, train_loss_step=0.000331, train_loss_epoch=0.000289]\n",
      "Epoch 60: 100%|██████████| 241/241 [00:05<00:00, 44.12it/s, loss=0.000299, v_num=3845523, train_loss_step=0.000331, train_loss_epoch=0.000289]\n",
      "Epoch 61:  84%|████████▍ | 203/241 [00:04<00:00, 50.17it/s, loss=0.000301, v_num=3845523, train_loss_step=0.00026, train_loss_epoch=0.000291] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 61:  90%|████████▉ | 216/241 [00:05<00:00, 37.41it/s, loss=0.000301, v_num=3845523, train_loss_step=0.00026, train_loss_epoch=0.000291]\n",
      "Epoch 61: 100%|██████████| 241/241 [00:05<00:00, 40.31it/s, loss=0.000301, v_num=3845523, train_loss_step=0.00026, train_loss_epoch=0.000291]\n",
      "Epoch 62:  84%|████████▍ | 203/241 [00:03<00:00, 53.44it/s, loss=0.000295, v_num=3845523, train_loss_step=0.000366, train_loss_epoch=0.000288]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:57,  1.56s/it]\u001b[A\n",
      "Epoch 62:  90%|████████▉ | 216/241 [00:05<00:00, 38.99it/s, loss=0.000295, v_num=3845523, train_loss_step=0.000366, train_loss_epoch=0.000288]\n",
      "Validating:  63%|██████▎   | 24/38 [00:01<00:00, 23.82it/s]\u001b[A\n",
      "Epoch 62: 100%|██████████| 241/241 [00:05<00:00, 42.09it/s, loss=0.000295, v_num=3845523, train_loss_step=0.000366, train_loss_epoch=0.000288]\n",
      "Epoch 63:  84%|████████▍ | 203/241 [00:03<00:00, 52.80it/s, loss=0.000248, v_num=3845523, train_loss_step=0.000246, train_loss_epoch=0.000285]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:59,  1.61s/it]\u001b[A\n",
      "Epoch 63:  90%|████████▉ | 216/241 [00:05<00:00, 37.57it/s, loss=0.000248, v_num=3845523, train_loss_step=0.000246, train_loss_epoch=0.000285]\n",
      "Epoch 63: 100%|██████████| 241/241 [00:05<00:00, 40.55it/s, loss=0.000248, v_num=3845523, train_loss_step=0.000246, train_loss_epoch=0.000285]\n",
      "Epoch 64:  84%|████████▍ | 203/241 [00:03<00:00, 51.90it/s, loss=0.000288, v_num=3845523, train_loss_step=0.000372, train_loss_epoch=0.000284]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 64:  90%|████████▉ | 216/241 [00:05<00:00, 37.60it/s, loss=0.000288, v_num=3845523, train_loss_step=0.000372, train_loss_epoch=0.000284]\n",
      "Epoch 64: 100%|██████████| 241/241 [00:05<00:00, 40.60it/s, loss=0.000288, v_num=3845523, train_loss_step=0.000372, train_loss_epoch=0.000284]\n",
      "Epoch 65:  84%|████████▍ | 203/241 [00:03<00:00, 55.67it/s, loss=0.000242, v_num=3845523, train_loss_step=0.00025, train_loss_epoch=0.000282] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 65:  90%|████████▉ | 216/241 [00:05<00:00, 38.28it/s, loss=0.000242, v_num=3845523, train_loss_step=0.00025, train_loss_epoch=0.000282]\n",
      "Epoch 65: 100%|██████████| 241/241 [00:05<00:00, 41.34it/s, loss=0.000242, v_num=3845523, train_loss_step=0.00025, train_loss_epoch=0.000282]\n",
      "Epoch 66:  84%|████████▍ | 203/241 [00:03<00:00, 51.16it/s, loss=0.000276, v_num=3845523, train_loss_step=0.000266, train_loss_epoch=0.000276]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 66:  90%|████████▉ | 216/241 [00:05<00:00, 38.14it/s, loss=0.000276, v_num=3845523, train_loss_step=0.000266, train_loss_epoch=0.000276]\n",
      "Epoch 66: 100%|██████████| 241/241 [00:05<00:00, 41.13it/s, loss=0.000276, v_num=3845523, train_loss_step=0.000266, train_loss_epoch=0.000276]\n",
      "Epoch 67:  84%|████████▍ | 203/241 [00:04<00:00, 50.21it/s, loss=0.000249, v_num=3845523, train_loss_step=0.000301, train_loss_epoch=0.00028] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 67:  90%|████████▉ | 216/241 [00:05<00:00, 38.23it/s, loss=0.000249, v_num=3845523, train_loss_step=0.000301, train_loss_epoch=0.00028]\n",
      "Epoch 67: 100%|██████████| 241/241 [00:05<00:00, 41.16it/s, loss=0.000249, v_num=3845523, train_loss_step=0.000301, train_loss_epoch=0.00028]\n",
      "Epoch 68:  84%|████████▍ | 203/241 [00:03<00:00, 52.98it/s, loss=0.000263, v_num=3845523, train_loss_step=0.000254, train_loss_epoch=0.00028]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 68:  90%|████████▉ | 216/241 [00:05<00:00, 39.45it/s, loss=0.000263, v_num=3845523, train_loss_step=0.000254, train_loss_epoch=0.00028]\n",
      "Epoch 68: 100%|██████████| 241/241 [00:05<00:00, 42.45it/s, loss=0.000263, v_num=3845523, train_loss_step=0.000254, train_loss_epoch=0.00028]\n",
      "Epoch 69:  84%|████████▍ | 203/241 [00:03<00:00, 52.87it/s, loss=0.000371, v_num=3845523, train_loss_step=0.000297, train_loss_epoch=0.000281]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:02,  1.68s/it]\u001b[A\n",
      "Epoch 69:  90%|████████▉ | 216/241 [00:05<00:00, 37.58it/s, loss=0.000371, v_num=3845523, train_loss_step=0.000297, train_loss_epoch=0.000281]\n",
      "Epoch 69: 100%|██████████| 241/241 [00:05<00:00, 40.54it/s, loss=0.000371, v_num=3845523, train_loss_step=0.000297, train_loss_epoch=0.000281]\n",
      "Epoch 70:  84%|████████▍ | 203/241 [00:04<00:00, 44.25it/s, loss=0.000308, v_num=3845523, train_loss_step=0.00027, train_loss_epoch=0.000283] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:09,  1.88s/it]\u001b[A\n",
      "Epoch 70:  90%|████████▉ | 216/241 [00:06<00:00, 32.83it/s, loss=0.000308, v_num=3845523, train_loss_step=0.00027, train_loss_epoch=0.000283]\n",
      "Epoch 70: 100%|██████████| 241/241 [00:06<00:00, 35.59it/s, loss=0.000308, v_num=3845523, train_loss_step=0.00027, train_loss_epoch=0.000283]\n",
      "Epoch 71:  84%|████████▍ | 203/241 [00:04<00:00, 43.95it/s, loss=0.000282, v_num=3845523, train_loss_step=0.000322, train_loss_epoch=0.000269]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 71:  90%|████████▉ | 216/241 [00:06<00:00, 34.46it/s, loss=0.000282, v_num=3845523, train_loss_step=0.000322, train_loss_epoch=0.000269]\n",
      "Validating:  37%|███▋      | 14/38 [00:01<00:02, 11.55it/s]\u001b[A\n",
      "Epoch 71: 100%|██████████| 241/241 [00:06<00:00, 37.25it/s, loss=0.000282, v_num=3845523, train_loss_step=0.000322, train_loss_epoch=0.000269]\n",
      "Epoch 72:  84%|████████▍ | 203/241 [00:04<00:00, 47.92it/s, loss=0.000254, v_num=3845523, train_loss_step=0.000227, train_loss_epoch=0.000271]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:56,  1.54s/it]\u001b[A\n",
      "Epoch 72:  90%|████████▉ | 216/241 [00:05<00:00, 36.12it/s, loss=0.000254, v_num=3845523, train_loss_step=0.000227, train_loss_epoch=0.000271]\n",
      "Epoch 72: 100%|██████████| 241/241 [00:06<00:00, 38.96it/s, loss=0.000254, v_num=3845523, train_loss_step=0.000227, train_loss_epoch=0.000271]\n",
      "Epoch 73:  84%|████████▍ | 203/241 [00:04<00:00, 44.92it/s, loss=0.00027, v_num=3845523, train_loss_step=0.000236, train_loss_epoch=0.000273] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 73:  90%|████████▉ | 216/241 [00:06<00:00, 34.72it/s, loss=0.00027, v_num=3845523, train_loss_step=0.000236, train_loss_epoch=0.000273]\n",
      "Epoch 73: 100%|██████████| 241/241 [00:06<00:00, 37.63it/s, loss=0.00027, v_num=3845523, train_loss_step=0.000236, train_loss_epoch=0.000273]\n",
      "Epoch 74:  84%|████████▍ | 203/241 [00:04<00:00, 43.14it/s, loss=0.000299, v_num=3845523, train_loss_step=0.000327, train_loss_epoch=0.000266]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:59,  1.61s/it]\u001b[A\n",
      "Epoch 74:  90%|████████▉ | 216/241 [00:06<00:00, 33.32it/s, loss=0.000299, v_num=3845523, train_loss_step=0.000327, train_loss_epoch=0.000266]\n",
      "Epoch 74: 100%|█████████▉| 240/241 [00:06<00:00, 36.06it/s, loss=0.000299, v_num=3845523, train_loss_step=0.000327, train_loss_epoch=0.000266]\n",
      "Epoch 74: 100%|██████████| 241/241 [00:06<00:00, 35.37it/s, loss=0.000299, v_num=3845523, train_loss_step=0.000327, train_loss_epoch=0.000266]\n",
      "Epoch 75:  84%|████████▍ | 203/241 [00:04<00:00, 46.99it/s, loss=0.0003, v_num=3845523, train_loss_step=0.000309, train_loss_epoch=0.000269]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:04,  1.73s/it]\u001b[A\n",
      "Epoch 75:  90%|████████▉ | 216/241 [00:06<00:00, 34.42it/s, loss=0.0003, v_num=3845523, train_loss_step=0.000309, train_loss_epoch=0.000269]\n",
      "Epoch 75: 100%|██████████| 241/241 [00:06<00:00, 37.33it/s, loss=0.0003, v_num=3845523, train_loss_step=0.000309, train_loss_epoch=0.000269]\n",
      "Epoch 76:  84%|████████▍ | 203/241 [00:04<00:00, 47.13it/s, loss=0.000317, v_num=3845523, train_loss_step=0.000332, train_loss_epoch=0.000269]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 76:  90%|████████▉ | 216/241 [00:05<00:00, 36.29it/s, loss=0.000317, v_num=3845523, train_loss_step=0.000332, train_loss_epoch=0.000269]\n",
      "Epoch 76: 100%|██████████| 241/241 [00:06<00:00, 39.22it/s, loss=0.000317, v_num=3845523, train_loss_step=0.000332, train_loss_epoch=0.000269]\n",
      "Epoch 77:  84%|████████▍ | 203/241 [00:04<00:00, 47.31it/s, loss=0.000275, v_num=3845523, train_loss_step=0.000253, train_loss_epoch=0.000264]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 77:  90%|████████▉ | 216/241 [00:05<00:00, 36.38it/s, loss=0.000275, v_num=3845523, train_loss_step=0.000253, train_loss_epoch=0.000264]\n",
      "Epoch 77: 100%|██████████| 241/241 [00:06<00:00, 39.26it/s, loss=0.000275, v_num=3845523, train_loss_step=0.000253, train_loss_epoch=0.000264]\n",
      "Epoch 78:  84%|████████▍ | 203/241 [00:04<00:00, 47.31it/s, loss=0.000239, v_num=3845523, train_loss_step=0.000232, train_loss_epoch=0.000264]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:12,  1.96s/it]\u001b[A\n",
      "Epoch 78:  90%|████████▉ | 216/241 [00:06<00:00, 33.96it/s, loss=0.000239, v_num=3845523, train_loss_step=0.000232, train_loss_epoch=0.000264]\n",
      "Epoch 78: 100%|██████████| 241/241 [00:06<00:00, 36.77it/s, loss=0.000239, v_num=3845523, train_loss_step=0.000232, train_loss_epoch=0.000264]\n",
      "Epoch 79:  84%|████████▍ | 203/241 [00:04<00:00, 47.60it/s, loss=0.000267, v_num=3845523, train_loss_step=0.000312, train_loss_epoch=0.00026] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:04,  1.75s/it]\u001b[A\n",
      "Epoch 79:  90%|████████▉ | 216/241 [00:06<00:00, 34.74it/s, loss=0.000267, v_num=3845523, train_loss_step=0.000312, train_loss_epoch=0.00026]\n",
      "Epoch 79: 100%|██████████| 241/241 [00:06<00:00, 37.71it/s, loss=0.000267, v_num=3845523, train_loss_step=0.000312, train_loss_epoch=0.00026]\n",
      "Epoch 80:  84%|████████▍ | 203/241 [00:04<00:00, 47.82it/s, loss=0.000238, v_num=3845523, train_loss_step=0.000241, train_loss_epoch=0.000263]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 80:  90%|████████▉ | 216/241 [00:05<00:00, 36.63it/s, loss=0.000238, v_num=3845523, train_loss_step=0.000241, train_loss_epoch=0.000263]\n",
      "Epoch 80: 100%|██████████| 241/241 [00:06<00:00, 39.59it/s, loss=0.000238, v_num=3845523, train_loss_step=0.000241, train_loss_epoch=0.000263]\n",
      "Epoch 81:  84%|████████▍ | 203/241 [00:04<00:00, 47.28it/s, loss=0.000269, v_num=3845523, train_loss_step=0.000324, train_loss_epoch=0.000257]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 81:  90%|████████▉ | 216/241 [00:06<00:00, 34.93it/s, loss=0.000269, v_num=3845523, train_loss_step=0.000324, train_loss_epoch=0.000257]\n",
      "Epoch 81: 100%|██████████| 241/241 [00:06<00:00, 37.78it/s, loss=0.000269, v_num=3845523, train_loss_step=0.000324, train_loss_epoch=0.000257]\n",
      "Epoch 82:  84%|████████▍ | 203/241 [00:04<00:00, 45.52it/s, loss=0.000261, v_num=3845523, train_loss_step=0.000224, train_loss_epoch=0.000255]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 82:  90%|████████▉ | 216/241 [00:05<00:00, 37.83it/s, loss=0.000261, v_num=3845523, train_loss_step=0.000224, train_loss_epoch=0.000255]\n",
      "Epoch 82: 100%|██████████| 241/241 [00:05<00:00, 41.14it/s, loss=0.000261, v_num=3845523, train_loss_step=0.000224, train_loss_epoch=0.000255]\n",
      "Epoch 83:  84%|████████▍ | 203/241 [00:03<00:00, 50.94it/s, loss=0.000246, v_num=3845523, train_loss_step=0.000261, train_loss_epoch=0.000262]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 83:  90%|████████▉ | 216/241 [00:05<00:00, 41.05it/s, loss=0.000246, v_num=3845523, train_loss_step=0.000261, train_loss_epoch=0.000262]\n",
      "Epoch 83: 100%|██████████| 241/241 [00:05<00:00, 44.49it/s, loss=0.000246, v_num=3845523, train_loss_step=0.000261, train_loss_epoch=0.000262]\n",
      "Epoch 84:  84%|████████▍ | 203/241 [00:04<00:00, 44.05it/s, loss=0.000294, v_num=3845523, train_loss_step=0.000238, train_loss_epoch=0.000255]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 84:  90%|████████▉ | 216/241 [00:05<00:00, 37.06it/s, loss=0.000294, v_num=3845523, train_loss_step=0.000238, train_loss_epoch=0.000255]\n",
      "Epoch 84: 100%|██████████| 241/241 [00:05<00:00, 40.26it/s, loss=0.000294, v_num=3845523, train_loss_step=0.000238, train_loss_epoch=0.000255]\n",
      "Epoch 85:  84%|████████▍ | 203/241 [00:03<00:00, 57.20it/s, loss=0.000244, v_num=3845523, train_loss_step=0.000238, train_loss_epoch=0.00026] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 85:  90%|████████▉ | 216/241 [00:04<00:00, 44.40it/s, loss=0.000244, v_num=3845523, train_loss_step=0.000238, train_loss_epoch=0.00026]\n",
      "Validating:  34%|███▍      | 13/38 [00:01<00:01, 13.34it/s]\u001b[A\n",
      "Epoch 85: 100%|██████████| 241/241 [00:05<00:00, 48.07it/s, loss=0.000244, v_num=3845523, train_loss_step=0.000238, train_loss_epoch=0.00026]\n",
      "Epoch 86:  84%|████████▍ | 203/241 [00:04<00:00, 47.66it/s, loss=0.000284, v_num=3845523, train_loss_step=0.000283, train_loss_epoch=0.000255]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 86:  90%|████████▉ | 216/241 [00:05<00:00, 38.71it/s, loss=0.000284, v_num=3845523, train_loss_step=0.000283, train_loss_epoch=0.000255]\n",
      "Epoch 86: 100%|██████████| 241/241 [00:05<00:00, 42.05it/s, loss=0.000284, v_num=3845523, train_loss_step=0.000283, train_loss_epoch=0.000255]\n",
      "Epoch 87:  84%|████████▍ | 203/241 [00:04<00:00, 49.28it/s, loss=0.000254, v_num=3845523, train_loss_step=0.000221, train_loss_epoch=0.000256]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 87:  90%|████████▉ | 216/241 [00:05<00:00, 39.68it/s, loss=0.000254, v_num=3845523, train_loss_step=0.000221, train_loss_epoch=0.000256]\n",
      "Epoch 87: 100%|██████████| 241/241 [00:05<00:00, 43.03it/s, loss=0.000254, v_num=3845523, train_loss_step=0.000221, train_loss_epoch=0.000256]\n",
      "Epoch 88:  84%|████████▍ | 203/241 [00:04<00:00, 50.39it/s, loss=0.000224, v_num=3845523, train_loss_step=0.000212, train_loss_epoch=0.000248]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 88:  90%|████████▉ | 216/241 [00:05<00:00, 40.69it/s, loss=0.000224, v_num=3845523, train_loss_step=0.000212, train_loss_epoch=0.000248]\n",
      "Epoch 88: 100%|██████████| 241/241 [00:05<00:00, 44.16it/s, loss=0.000224, v_num=3845523, train_loss_step=0.000212, train_loss_epoch=0.000248]\n",
      "Epoch 89:  84%|████████▍ | 203/241 [00:04<00:00, 45.68it/s, loss=0.000243, v_num=3845523, train_loss_step=0.000253, train_loss_epoch=0.000245]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 89:  90%|████████▉ | 216/241 [00:05<00:00, 37.47it/s, loss=0.000243, v_num=3845523, train_loss_step=0.000253, train_loss_epoch=0.000245]\n",
      "Epoch 89: 100%|██████████| 241/241 [00:05<00:00, 40.73it/s, loss=0.000243, v_num=3845523, train_loss_step=0.000253, train_loss_epoch=0.000245]\n",
      "Epoch 90:  84%|████████▍ | 203/241 [00:04<00:00, 44.48it/s, loss=0.000291, v_num=3845523, train_loss_step=0.000277, train_loss_epoch=0.000257]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 90:  90%|████████▉ | 216/241 [00:05<00:00, 36.91it/s, loss=0.000291, v_num=3845523, train_loss_step=0.000277, train_loss_epoch=0.000257]\n",
      "Epoch 90: 100%|██████████| 241/241 [00:05<00:00, 40.18it/s, loss=0.000291, v_num=3845523, train_loss_step=0.000277, train_loss_epoch=0.000257]\n",
      "Epoch 91:  84%|████████▍ | 203/241 [00:04<00:00, 46.86it/s, loss=0.000301, v_num=3845523, train_loss_step=0.000315, train_loss_epoch=0.00025] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 91:  90%|████████▉ | 216/241 [00:06<00:00, 35.74it/s, loss=0.000301, v_num=3845523, train_loss_step=0.000315, train_loss_epoch=0.00025]\n",
      "Epoch 91: 100%|██████████| 241/241 [00:06<00:00, 38.91it/s, loss=0.000301, v_num=3845523, train_loss_step=0.000315, train_loss_epoch=0.00025]\n",
      "Epoch 92:  84%|████████▍ | 203/241 [00:03<00:00, 51.58it/s, loss=0.000234, v_num=3845523, train_loss_step=0.000225, train_loss_epoch=0.000248]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 92:  90%|████████▉ | 216/241 [00:06<00:00, 35.70it/s, loss=0.000234, v_num=3845523, train_loss_step=0.000225, train_loss_epoch=0.000248]\n",
      "Epoch 92: 100%|██████████| 241/241 [00:06<00:00, 38.87it/s, loss=0.000234, v_num=3845523, train_loss_step=0.000225, train_loss_epoch=0.000248]\n",
      "Epoch 93:  84%|████████▍ | 203/241 [00:03<00:00, 55.05it/s, loss=0.000263, v_num=3845523, train_loss_step=0.000264, train_loss_epoch=0.000241]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 93:  90%|████████▉ | 216/241 [00:05<00:00, 40.77it/s, loss=0.000263, v_num=3845523, train_loss_step=0.000264, train_loss_epoch=0.000241]\n",
      "Epoch 93: 100%|██████████| 241/241 [00:05<00:00, 44.09it/s, loss=0.000263, v_num=3845523, train_loss_step=0.000264, train_loss_epoch=0.000241]\n",
      "Epoch 94:  84%|████████▍ | 203/241 [00:03<00:00, 58.38it/s, loss=0.000235, v_num=3845523, train_loss_step=0.000236, train_loss_epoch=0.000251]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:54,  1.48s/it]\u001b[A\n",
      "Epoch 94:  90%|████████▉ | 216/241 [00:05<00:00, 42.13it/s, loss=0.000235, v_num=3845523, train_loss_step=0.000236, train_loss_epoch=0.000251]\n",
      "Epoch 94: 100%|██████████| 241/241 [00:05<00:00, 45.61it/s, loss=0.000235, v_num=3845523, train_loss_step=0.000236, train_loss_epoch=0.000251]\n",
      "Epoch 95:  84%|████████▍ | 203/241 [00:03<00:00, 57.02it/s, loss=0.000237, v_num=3845523, train_loss_step=0.000212, train_loss_epoch=0.000245]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 95:  90%|████████▉ | 216/241 [00:05<00:00, 42.41it/s, loss=0.000237, v_num=3845523, train_loss_step=0.000212, train_loss_epoch=0.000245]\n",
      "Epoch 95: 100%|██████████| 241/241 [00:05<00:00, 45.92it/s, loss=0.000237, v_num=3845523, train_loss_step=0.000212, train_loss_epoch=0.000245]\n",
      "Epoch 96:  84%|████████▍ | 203/241 [00:03<00:00, 59.83it/s, loss=0.000233, v_num=3845523, train_loss_step=0.000218, train_loss_epoch=0.000241]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 96:  90%|████████▉ | 216/241 [00:05<00:00, 43.03it/s, loss=0.000233, v_num=3845523, train_loss_step=0.000218, train_loss_epoch=0.000241]\n",
      "Epoch 96: 100%|██████████| 241/241 [00:05<00:00, 46.52it/s, loss=0.000233, v_num=3845523, train_loss_step=0.000218, train_loss_epoch=0.000241]\n",
      "Epoch 97:  84%|████████▍ | 203/241 [00:03<00:00, 57.80it/s, loss=0.000265, v_num=3845523, train_loss_step=0.000227, train_loss_epoch=0.000242]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 97:  90%|████████▉ | 216/241 [00:05<00:00, 41.02it/s, loss=0.000265, v_num=3845523, train_loss_step=0.000227, train_loss_epoch=0.000242]\n",
      "Epoch 97: 100%|██████████| 241/241 [00:05<00:00, 44.49it/s, loss=0.000265, v_num=3845523, train_loss_step=0.000227, train_loss_epoch=0.000242]\n",
      "Epoch 98:  84%|████████▍ | 203/241 [00:03<00:00, 52.74it/s, loss=0.000264, v_num=3845523, train_loss_step=0.000237, train_loss_epoch=0.000244]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 98:  90%|████████▉ | 216/241 [00:05<00:00, 38.51it/s, loss=0.000264, v_num=3845523, train_loss_step=0.000237, train_loss_epoch=0.000244]\n",
      "Epoch 98: 100%|██████████| 241/241 [00:05<00:00, 41.74it/s, loss=0.000264, v_num=3845523, train_loss_step=0.000237, train_loss_epoch=0.000244]\n",
      "Epoch 99:  84%|████████▍ | 203/241 [00:03<00:00, 56.04it/s, loss=0.000232, v_num=3845523, train_loss_step=0.00021, train_loss_epoch=0.000241] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 99:  90%|████████▉ | 216/241 [00:05<00:00, 38.51it/s, loss=0.000232, v_num=3845523, train_loss_step=0.00021, train_loss_epoch=0.000241]\n",
      "Epoch 99: 100%|██████████| 241/241 [00:05<00:00, 41.83it/s, loss=0.000232, v_num=3845523, train_loss_step=0.00021, train_loss_epoch=0.000241]\n",
      "Epoch 100:  84%|████████▍ | 203/241 [00:03<00:00, 55.87it/s, loss=0.000216, v_num=3845523, train_loss_step=0.000207, train_loss_epoch=0.000238]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 100:  90%|████████▉ | 216/241 [00:05<00:00, 40.97it/s, loss=0.000216, v_num=3845523, train_loss_step=0.000207, train_loss_epoch=0.000238]\n",
      "Epoch 100: 100%|██████████| 241/241 [00:05<00:00, 44.45it/s, loss=0.000216, v_num=3845523, train_loss_step=0.000207, train_loss_epoch=0.000238]\n",
      "Epoch 101:  84%|████████▍ | 203/241 [00:03<00:00, 55.48it/s, loss=0.000311, v_num=3845523, train_loss_step=0.000339, train_loss_epoch=0.000236]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 101:  90%|████████▉ | 216/241 [00:05<00:00, 41.11it/s, loss=0.000311, v_num=3845523, train_loss_step=0.000339, train_loss_epoch=0.000236]\n",
      "Epoch 101: 100%|██████████| 241/241 [00:05<00:00, 44.40it/s, loss=0.000311, v_num=3845523, train_loss_step=0.000339, train_loss_epoch=0.000236]\n",
      "Epoch 102:  84%|████████▍ | 203/241 [00:03<00:00, 55.25it/s, loss=0.00022, v_num=3845523, train_loss_step=0.000198, train_loss_epoch=0.000246] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 102:  90%|████████▉ | 216/241 [00:05<00:00, 38.05it/s, loss=0.00022, v_num=3845523, train_loss_step=0.000198, train_loss_epoch=0.000246]\n",
      "Epoch 102: 100%|██████████| 241/241 [00:05<00:00, 41.35it/s, loss=0.00022, v_num=3845523, train_loss_step=0.000198, train_loss_epoch=0.000246]\n",
      "Epoch 103:  84%|████████▍ | 203/241 [00:04<00:00, 49.75it/s, loss=0.00024, v_num=3845523, train_loss_step=0.000207, train_loss_epoch=0.000234] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 103:  90%|████████▉ | 216/241 [00:05<00:00, 36.91it/s, loss=0.00024, v_num=3845523, train_loss_step=0.000207, train_loss_epoch=0.000234]\n",
      "Epoch 103: 100%|██████████| 241/241 [00:06<00:00, 40.14it/s, loss=0.00024, v_num=3845523, train_loss_step=0.000207, train_loss_epoch=0.000234]\n",
      "Epoch 104:  84%|████████▍ | 203/241 [00:04<00:00, 49.63it/s, loss=0.000222, v_num=3845523, train_loss_step=0.000253, train_loss_epoch=0.000237]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:58,  1.58s/it]\u001b[A\n",
      "Epoch 104:  90%|████████▉ | 216/241 [00:05<00:00, 37.11it/s, loss=0.000222, v_num=3845523, train_loss_step=0.000253, train_loss_epoch=0.000237]\n",
      "Epoch 104: 100%|██████████| 241/241 [00:05<00:00, 40.34it/s, loss=0.000222, v_num=3845523, train_loss_step=0.000253, train_loss_epoch=0.000237]\n",
      "Epoch 105:  84%|████████▍ | 203/241 [00:04<00:00, 48.17it/s, loss=0.000298, v_num=3845523, train_loss_step=0.000317, train_loss_epoch=0.000231]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 105:  90%|████████▉ | 216/241 [00:06<00:00, 35.83it/s, loss=0.000298, v_num=3845523, train_loss_step=0.000317, train_loss_epoch=0.000231]\n",
      "Epoch 105: 100%|██████████| 241/241 [00:06<00:00, 39.00it/s, loss=0.000298, v_num=3845523, train_loss_step=0.000317, train_loss_epoch=0.000231]\n",
      "Epoch 106:  84%|████████▍ | 203/241 [00:04<00:00, 49.45it/s, loss=0.000242, v_num=3845523, train_loss_step=0.000196, train_loss_epoch=0.00024] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 106:  90%|████████▉ | 216/241 [00:05<00:00, 37.81it/s, loss=0.000242, v_num=3845523, train_loss_step=0.000196, train_loss_epoch=0.00024]\n",
      "Validating:  47%|████▋     | 18/38 [00:01<00:01, 15.26it/s]\u001b[A\n",
      "Epoch 106: 100%|██████████| 241/241 [00:05<00:00, 41.12it/s, loss=0.000242, v_num=3845523, train_loss_step=0.000196, train_loss_epoch=0.00024]\n",
      "Epoch 107:  84%|████████▍ | 203/241 [00:03<00:00, 55.36it/s, loss=0.000226, v_num=3845523, train_loss_step=0.000204, train_loss_epoch=0.00023]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 107:  90%|████████▉ | 216/241 [00:05<00:00, 40.98it/s, loss=0.000226, v_num=3845523, train_loss_step=0.000204, train_loss_epoch=0.00023]\n",
      "Epoch 107: 100%|██████████| 241/241 [00:05<00:00, 44.44it/s, loss=0.000226, v_num=3845523, train_loss_step=0.000204, train_loss_epoch=0.00023]\n",
      "Epoch 108:  84%|████████▍ | 203/241 [00:03<00:00, 52.55it/s, loss=0.000208, v_num=3845523, train_loss_step=0.000198, train_loss_epoch=0.000235]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 108:  90%|████████▉ | 216/241 [00:05<00:00, 39.60it/s, loss=0.000208, v_num=3845523, train_loss_step=0.000198, train_loss_epoch=0.000235]\n",
      "Epoch 108: 100%|██████████| 241/241 [00:05<00:00, 42.95it/s, loss=0.000208, v_num=3845523, train_loss_step=0.000198, train_loss_epoch=0.000235]\n",
      "Epoch 109:  84%|████████▍ | 203/241 [00:03<00:00, 51.22it/s, loss=0.000278, v_num=3845523, train_loss_step=0.000289, train_loss_epoch=0.000226]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 109:  90%|████████▉ | 216/241 [00:06<00:00, 35.44it/s, loss=0.000278, v_num=3845523, train_loss_step=0.000289, train_loss_epoch=0.000226]\n",
      "Epoch 109: 100%|██████████| 241/241 [00:06<00:00, 38.65it/s, loss=0.000278, v_num=3845523, train_loss_step=0.000289, train_loss_epoch=0.000226]\n",
      "Epoch 110:  84%|████████▍ | 203/241 [00:03<00:00, 53.68it/s, loss=0.000271, v_num=3845523, train_loss_step=0.000235, train_loss_epoch=0.000233]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:08,  1.86s/it]\u001b[A\n",
      "Epoch 110:  90%|████████▉ | 216/241 [00:05<00:00, 37.48it/s, loss=0.000271, v_num=3845523, train_loss_step=0.000235, train_loss_epoch=0.000233]\n",
      "Epoch 110: 100%|██████████| 241/241 [00:05<00:00, 40.73it/s, loss=0.000271, v_num=3845523, train_loss_step=0.000235, train_loss_epoch=0.000233]\n",
      "Epoch 111:  84%|████████▍ | 203/241 [00:03<00:00, 54.31it/s, loss=0.000202, v_num=3845523, train_loss_step=0.000193, train_loss_epoch=0.000229]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 111:  90%|████████▉ | 216/241 [00:05<00:00, 41.05it/s, loss=0.000202, v_num=3845523, train_loss_step=0.000193, train_loss_epoch=0.000229]\n",
      "Epoch 111: 100%|██████████| 241/241 [00:05<00:00, 44.43it/s, loss=0.000202, v_num=3845523, train_loss_step=0.000193, train_loss_epoch=0.000229]\n",
      "Epoch 112:  84%|████████▍ | 203/241 [00:03<00:00, 53.65it/s, loss=0.000224, v_num=3845523, train_loss_step=0.000203, train_loss_epoch=0.000231]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 112:  90%|████████▉ | 216/241 [00:05<00:00, 39.36it/s, loss=0.000224, v_num=3845523, train_loss_step=0.000203, train_loss_epoch=0.000231]\n",
      "Validating:  34%|███▍      | 13/38 [00:01<00:02, 10.38it/s]\u001b[A\n",
      "Epoch 112: 100%|██████████| 241/241 [00:05<00:00, 42.41it/s, loss=0.000224, v_num=3845523, train_loss_step=0.000203, train_loss_epoch=0.000231]\n",
      "Epoch 113:  84%|████████▍ | 203/241 [00:03<00:00, 53.48it/s, loss=0.000231, v_num=3845523, train_loss_step=0.0002, train_loss_epoch=0.00023]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:07,  1.82s/it]\u001b[A\n",
      "Epoch 113:  90%|████████▉ | 216/241 [00:05<00:00, 37.28it/s, loss=0.000231, v_num=3845523, train_loss_step=0.0002, train_loss_epoch=0.00023]\n",
      "Epoch 113: 100%|██████████| 241/241 [00:05<00:00, 40.20it/s, loss=0.000231, v_num=3845523, train_loss_step=0.0002, train_loss_epoch=0.00023]\n",
      "Epoch 114:  84%|████████▍ | 203/241 [00:03<00:00, 51.91it/s, loss=0.000249, v_num=3845523, train_loss_step=0.000239, train_loss_epoch=0.000227]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:00,  1.62s/it]\u001b[A\n",
      "Epoch 114:  90%|████████▉ | 216/241 [00:05<00:00, 38.11it/s, loss=0.000249, v_num=3845523, train_loss_step=0.000239, train_loss_epoch=0.000227]\n",
      "Epoch 114: 100%|██████████| 241/241 [00:05<00:00, 41.19it/s, loss=0.000249, v_num=3845523, train_loss_step=0.000239, train_loss_epoch=0.000227]\n",
      "Epoch 115:  84%|████████▍ | 203/241 [00:03<00:00, 54.75it/s, loss=0.000265, v_num=3845523, train_loss_step=0.000237, train_loss_epoch=0.000225]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 115:  90%|████████▉ | 216/241 [00:05<00:00, 40.69it/s, loss=0.000265, v_num=3845523, train_loss_step=0.000237, train_loss_epoch=0.000225]\n",
      "Epoch 115: 100%|██████████| 241/241 [00:05<00:00, 43.42it/s, loss=0.000265, v_num=3845523, train_loss_step=0.000237, train_loss_epoch=0.000225]\n",
      "Epoch 116:  84%|████████▍ | 203/241 [00:03<00:00, 54.38it/s, loss=0.000219, v_num=3845523, train_loss_step=0.000214, train_loss_epoch=0.000235]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 116:  90%|████████▉ | 216/241 [00:05<00:00, 39.74it/s, loss=0.000219, v_num=3845523, train_loss_step=0.000214, train_loss_epoch=0.000235]\n",
      "Epoch 116: 100%|██████████| 241/241 [00:05<00:00, 42.85it/s, loss=0.000219, v_num=3845523, train_loss_step=0.000214, train_loss_epoch=0.000235]\n",
      "Epoch 117:  84%|████████▍ | 203/241 [00:03<00:00, 51.33it/s, loss=0.000235, v_num=3845523, train_loss_step=0.000245, train_loss_epoch=0.000223]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:08,  1.85s/it]\u001b[A\n",
      "Epoch 117:  90%|████████▉ | 216/241 [00:05<00:00, 36.17it/s, loss=0.000235, v_num=3845523, train_loss_step=0.000245, train_loss_epoch=0.000223]\n",
      "Epoch 117: 100%|██████████| 241/241 [00:06<00:00, 39.06it/s, loss=0.000235, v_num=3845523, train_loss_step=0.000245, train_loss_epoch=0.000223]\n",
      "Epoch 118:  84%|████████▍ | 203/241 [00:03<00:00, 51.54it/s, loss=0.000196, v_num=3845523, train_loss_step=0.000197, train_loss_epoch=0.000221]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 118:  90%|████████▉ | 216/241 [00:05<00:00, 38.34it/s, loss=0.000196, v_num=3845523, train_loss_step=0.000197, train_loss_epoch=0.000221]\n",
      "Validating:  34%|███▍      | 13/38 [00:01<00:02, 10.44it/s]\u001b[A\n",
      "Epoch 118: 100%|██████████| 241/241 [00:05<00:00, 41.43it/s, loss=0.000196, v_num=3845523, train_loss_step=0.000197, train_loss_epoch=0.000221]\n",
      "Epoch 119:  84%|████████▍ | 203/241 [00:03<00:00, 52.03it/s, loss=0.000236, v_num=3845523, train_loss_step=0.000237, train_loss_epoch=0.000221]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 119:  90%|████████▉ | 216/241 [00:05<00:00, 37.97it/s, loss=0.000236, v_num=3845523, train_loss_step=0.000237, train_loss_epoch=0.000221]\n",
      "Epoch 119: 100%|██████████| 241/241 [00:05<00:00, 41.01it/s, loss=0.000236, v_num=3845523, train_loss_step=0.000237, train_loss_epoch=0.000221]\n",
      "Epoch 120:  84%|████████▍ | 203/241 [00:03<00:00, 50.91it/s, loss=0.000225, v_num=3845523, train_loss_step=0.000222, train_loss_epoch=0.00023] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:00,  1.63s/it]\u001b[A\n",
      "Epoch 120:  90%|████████▉ | 216/241 [00:05<00:00, 36.34it/s, loss=0.000225, v_num=3845523, train_loss_step=0.000222, train_loss_epoch=0.00023]\n",
      "Validating:  39%|███▉      | 15/38 [00:01<00:01, 13.39it/s]\u001b[A\n",
      "Epoch 120: 100%|██████████| 241/241 [00:06<00:00, 39.25it/s, loss=0.000225, v_num=3845523, train_loss_step=0.000222, train_loss_epoch=0.00023]\n",
      "Epoch 121:  84%|████████▍ | 203/241 [00:03<00:00, 50.76it/s, loss=0.000264, v_num=3845523, train_loss_step=0.000234, train_loss_epoch=0.000218]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 121:  90%|████████▉ | 216/241 [00:05<00:00, 38.72it/s, loss=0.000264, v_num=3845523, train_loss_step=0.000234, train_loss_epoch=0.000218]\n",
      "Epoch 121: 100%|██████████| 241/241 [00:05<00:00, 41.76it/s, loss=0.000264, v_num=3845523, train_loss_step=0.000234, train_loss_epoch=0.000218]\n",
      "Epoch 122:  84%|████████▍ | 203/241 [00:04<00:00, 45.15it/s, loss=0.00026, v_num=3845523, train_loss_step=0.000249, train_loss_epoch=0.000221] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 122:  90%|████████▉ | 216/241 [00:06<00:00, 33.49it/s, loss=0.00026, v_num=3845523, train_loss_step=0.000249, train_loss_epoch=0.000221]\n",
      "Validating:  50%|█████     | 19/38 [00:01<00:01, 13.31it/s]\u001b[A\n",
      "Epoch 122: 100%|██████████| 241/241 [00:06<00:00, 36.33it/s, loss=0.00026, v_num=3845523, train_loss_step=0.000249, train_loss_epoch=0.000221]\n",
      "Epoch 123:  84%|████████▍ | 203/241 [00:04<00:00, 44.49it/s, loss=0.000218, v_num=3845523, train_loss_step=0.000193, train_loss_epoch=0.000221]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 123:  90%|████████▉ | 216/241 [00:06<00:00, 34.75it/s, loss=0.000218, v_num=3845523, train_loss_step=0.000193, train_loss_epoch=0.000221]\n",
      "Epoch 123: 100%|██████████| 241/241 [00:06<00:00, 37.63it/s, loss=0.000218, v_num=3845523, train_loss_step=0.000193, train_loss_epoch=0.000221]\n",
      "Epoch 124:  84%|████████▍ | 203/241 [00:04<00:00, 47.85it/s, loss=0.000245, v_num=3845523, train_loss_step=0.000244, train_loss_epoch=0.000221]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:05,  1.77s/it]\u001b[A\n",
      "Epoch 124:  90%|████████▉ | 216/241 [00:06<00:00, 34.69it/s, loss=0.000245, v_num=3845523, train_loss_step=0.000244, train_loss_epoch=0.000221]\n",
      "Epoch 124: 100%|██████████| 241/241 [00:06<00:00, 37.53it/s, loss=0.000245, v_num=3845523, train_loss_step=0.000244, train_loss_epoch=0.000221]\n",
      "Epoch 125:  84%|████████▍ | 203/241 [00:04<00:00, 42.87it/s, loss=0.000208, v_num=3845523, train_loss_step=0.000193, train_loss_epoch=0.00022] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 125:  90%|████████▉ | 216/241 [00:06<00:00, 32.46it/s, loss=0.000208, v_num=3845523, train_loss_step=0.000193, train_loss_epoch=0.00022]\n",
      "Epoch 125: 100%|██████████| 241/241 [00:06<00:00, 35.20it/s, loss=0.000208, v_num=3845523, train_loss_step=0.000193, train_loss_epoch=0.00022]\n",
      "Epoch 126:  84%|████████▍ | 203/241 [00:04<00:00, 42.56it/s, loss=0.000216, v_num=3845523, train_loss_step=0.000203, train_loss_epoch=0.000216]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:04,  1.74s/it]\u001b[A\n",
      "Epoch 126:  90%|████████▉ | 216/241 [00:06<00:00, 32.08it/s, loss=0.000216, v_num=3845523, train_loss_step=0.000203, train_loss_epoch=0.000216]\n",
      "Epoch 126: 100%|██████████| 241/241 [00:06<00:00, 34.81it/s, loss=0.000216, v_num=3845523, train_loss_step=0.000203, train_loss_epoch=0.000216]\n",
      "Epoch 127:  84%|████████▍ | 203/241 [00:04<00:00, 45.02it/s, loss=0.000257, v_num=3845523, train_loss_step=0.000248, train_loss_epoch=0.000224]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:59,  1.60s/it]\u001b[A\n",
      "Validating:   5%|▌         | 2/38 [00:01<00:28,  1.27it/s]\u001b[A\n",
      "Epoch 127:  90%|████████▉ | 216/241 [00:06<00:00, 33.47it/s, loss=0.000257, v_num=3845523, train_loss_step=0.000248, train_loss_epoch=0.000224]\n",
      "Epoch 127: 100%|██████████| 241/241 [00:06<00:00, 36.27it/s, loss=0.000257, v_num=3845523, train_loss_step=0.000248, train_loss_epoch=0.000224]\n",
      "Epoch 128:  84%|████████▍ | 203/241 [00:04<00:00, 48.24it/s, loss=0.000216, v_num=3845523, train_loss_step=0.000197, train_loss_epoch=0.000217]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 128:  90%|████████▉ | 216/241 [00:06<00:00, 35.12it/s, loss=0.000216, v_num=3845523, train_loss_step=0.000197, train_loss_epoch=0.000217]\n",
      "Epoch 128: 100%|██████████| 241/241 [00:06<00:00, 37.92it/s, loss=0.000216, v_num=3845523, train_loss_step=0.000197, train_loss_epoch=0.000217]\n",
      "Epoch 129:  84%|████████▍ | 203/241 [00:04<00:00, 48.15it/s, loss=0.00022, v_num=3845523, train_loss_step=0.000192, train_loss_epoch=0.000218] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 129:  90%|████████▉ | 216/241 [00:05<00:00, 36.94it/s, loss=0.00022, v_num=3845523, train_loss_step=0.000192, train_loss_epoch=0.000218]\n",
      "Validating:  45%|████▍     | 17/38 [00:01<00:01, 14.18it/s]\u001b[A\n",
      "Epoch 129: 100%|██████████| 241/241 [00:06<00:00, 39.94it/s, loss=0.00022, v_num=3845523, train_loss_step=0.000192, train_loss_epoch=0.000218]\n",
      "Epoch 130:  84%|████████▍ | 203/241 [00:04<00:00, 49.29it/s, loss=0.00022, v_num=3845523, train_loss_step=0.000223, train_loss_epoch=0.000215] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:57,  1.57s/it]\u001b[A\n",
      "Epoch 130:  90%|████████▉ | 216/241 [00:06<00:00, 35.31it/s, loss=0.00022, v_num=3845523, train_loss_step=0.000223, train_loss_epoch=0.000215]\n",
      "Epoch 130: 100%|██████████| 241/241 [00:06<00:00, 38.13it/s, loss=0.00022, v_num=3845523, train_loss_step=0.000223, train_loss_epoch=0.000215]\n",
      "Epoch 131:  84%|████████▍ | 203/241 [00:04<00:00, 46.87it/s, loss=0.000245, v_num=3845523, train_loss_step=0.000239, train_loss_epoch=0.000215]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 131:  90%|████████▉ | 216/241 [00:06<00:00, 34.37it/s, loss=0.000245, v_num=3845523, train_loss_step=0.000239, train_loss_epoch=0.000215]\n",
      "Validating:  34%|███▍      | 13/38 [00:01<00:02,  9.09it/s]\u001b[A\n",
      "Epoch 131: 100%|██████████| 241/241 [00:06<00:00, 37.15it/s, loss=0.000245, v_num=3845523, train_loss_step=0.000239, train_loss_epoch=0.000215]\n",
      "Epoch 132:  84%|████████▍ | 203/241 [00:03<00:00, 54.50it/s, loss=0.000231, v_num=3845523, train_loss_step=0.00023, train_loss_epoch=0.000214] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 132:  90%|████████▉ | 216/241 [00:05<00:00, 39.76it/s, loss=0.000231, v_num=3845523, train_loss_step=0.00023, train_loss_epoch=0.000214]\n",
      "Validating:  37%|███▋      | 14/38 [00:01<00:02, 11.16it/s]\u001b[A\n",
      "Epoch 132: 100%|██████████| 241/241 [00:05<00:00, 42.79it/s, loss=0.000231, v_num=3845523, train_loss_step=0.00023, train_loss_epoch=0.000214]\n",
      "Epoch 133:  84%|████████▍ | 203/241 [00:04<00:00, 45.54it/s, loss=0.000198, v_num=3845523, train_loss_step=0.000205, train_loss_epoch=0.000213]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 133:  90%|████████▉ | 216/241 [00:06<00:00, 35.38it/s, loss=0.000198, v_num=3845523, train_loss_step=0.000205, train_loss_epoch=0.000213]\n",
      "Validating:  39%|███▉      | 15/38 [00:01<00:01, 12.39it/s]\u001b[A\n",
      "Epoch 133: 100%|██████████| 241/241 [00:06<00:00, 38.32it/s, loss=0.000198, v_num=3845523, train_loss_step=0.000205, train_loss_epoch=0.000213]\n",
      "Epoch 134:  84%|████████▍ | 203/241 [00:04<00:00, 47.12it/s, loss=0.000215, v_num=3845523, train_loss_step=0.000202, train_loss_epoch=0.000215]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:04,  1.74s/it]\u001b[A\n",
      "Epoch 134:  90%|████████▉ | 216/241 [00:06<00:00, 34.68it/s, loss=0.000215, v_num=3845523, train_loss_step=0.000202, train_loss_epoch=0.000215]\n",
      "Epoch 134: 100%|██████████| 241/241 [00:06<00:00, 37.52it/s, loss=0.000215, v_num=3845523, train_loss_step=0.000202, train_loss_epoch=0.000215]\n",
      "Epoch 135:  84%|████████▍ | 203/241 [00:04<00:00, 47.26it/s, loss=0.00026, v_num=3845523, train_loss_step=0.000236, train_loss_epoch=0.000218] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:07,  1.82s/it]\u001b[A\n",
      "Epoch 135:  90%|████████▉ | 216/241 [00:06<00:00, 34.60it/s, loss=0.00026, v_num=3845523, train_loss_step=0.000236, train_loss_epoch=0.000218]\n",
      "Epoch 135: 100%|██████████| 241/241 [00:06<00:00, 37.42it/s, loss=0.00026, v_num=3845523, train_loss_step=0.000236, train_loss_epoch=0.000218]\n",
      "Epoch 136:  84%|████████▍ | 203/241 [00:04<00:00, 44.42it/s, loss=0.000221, v_num=3845523, train_loss_step=0.000181, train_loss_epoch=0.000213]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 136:  90%|████████▉ | 216/241 [00:05<00:00, 37.01it/s, loss=0.000221, v_num=3845523, train_loss_step=0.000181, train_loss_epoch=0.000213]\n",
      "Epoch 136: 100%|██████████| 241/241 [00:05<00:00, 40.24it/s, loss=0.000221, v_num=3845523, train_loss_step=0.000181, train_loss_epoch=0.000213]\n",
      "Epoch 137:  84%|████████▍ | 203/241 [00:03<00:00, 53.22it/s, loss=0.000256, v_num=3845523, train_loss_step=0.000243, train_loss_epoch=0.000216]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 137:  90%|████████▉ | 216/241 [00:05<00:00, 42.35it/s, loss=0.000256, v_num=3845523, train_loss_step=0.000243, train_loss_epoch=0.000216]\n",
      "Epoch 137: 100%|██████████| 241/241 [00:05<00:00, 45.81it/s, loss=0.000256, v_num=3845523, train_loss_step=0.000243, train_loss_epoch=0.000216]\n",
      "Epoch 138:  84%|████████▍ | 203/241 [00:03<00:00, 52.54it/s, loss=0.000274, v_num=3845523, train_loss_step=0.000349, train_loss_epoch=0.000214]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 138:  90%|████████▉ | 216/241 [00:05<00:00, 41.93it/s, loss=0.000274, v_num=3845523, train_loss_step=0.000349, train_loss_epoch=0.000214]\n",
      "Epoch 138: 100%|██████████| 241/241 [00:05<00:00, 45.48it/s, loss=0.000274, v_num=3845523, train_loss_step=0.000349, train_loss_epoch=0.000214]\n",
      "Epoch 139:  84%|████████▍ | 203/241 [00:04<00:00, 50.48it/s, loss=0.000212, v_num=3845523, train_loss_step=0.000201, train_loss_epoch=0.000213]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 139:  90%|████████▉ | 216/241 [00:05<00:00, 40.74it/s, loss=0.000212, v_num=3845523, train_loss_step=0.000201, train_loss_epoch=0.000213]\n",
      "Epoch 139: 100%|██████████| 241/241 [00:05<00:00, 44.23it/s, loss=0.000212, v_num=3845523, train_loss_step=0.000201, train_loss_epoch=0.000213]\n",
      "Epoch 140:  84%|████████▍ | 203/241 [00:03<00:00, 52.87it/s, loss=0.000249, v_num=3845523, train_loss_step=0.000207, train_loss_epoch=0.000208]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:43,  1.18s/it]\u001b[A\n",
      "Epoch 140:  90%|████████▉ | 216/241 [00:05<00:00, 41.86it/s, loss=0.000249, v_num=3845523, train_loss_step=0.000207, train_loss_epoch=0.000208]\n",
      "Epoch 140: 100%|██████████| 241/241 [00:05<00:00, 45.44it/s, loss=0.000249, v_num=3845523, train_loss_step=0.000207, train_loss_epoch=0.000208]\n",
      "Epoch 141:  84%|████████▍ | 203/241 [00:04<00:00, 47.36it/s, loss=0.000191, v_num=3845523, train_loss_step=0.000177, train_loss_epoch=0.000211]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 141:  90%|████████▉ | 216/241 [00:05<00:00, 38.75it/s, loss=0.000191, v_num=3845523, train_loss_step=0.000177, train_loss_epoch=0.000211]\n",
      "Epoch 141: 100%|██████████| 241/241 [00:05<00:00, 42.15it/s, loss=0.000191, v_num=3845523, train_loss_step=0.000177, train_loss_epoch=0.000211]\n",
      "Epoch 142:  84%|████████▍ | 203/241 [00:04<00:00, 47.64it/s, loss=0.000201, v_num=3845523, train_loss_step=0.000248, train_loss_epoch=0.000207]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 142:  90%|████████▉ | 216/241 [00:05<00:00, 39.19it/s, loss=0.000201, v_num=3845523, train_loss_step=0.000248, train_loss_epoch=0.000207]\n",
      "Epoch 142: 100%|██████████| 241/241 [00:05<00:00, 42.56it/s, loss=0.000201, v_num=3845523, train_loss_step=0.000248, train_loss_epoch=0.000207]\n",
      "Epoch 143:  84%|████████▍ | 203/241 [00:03<00:00, 51.77it/s, loss=0.000229, v_num=3845523, train_loss_step=0.000233, train_loss_epoch=0.000208]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 143:  90%|████████▉ | 216/241 [00:05<00:00, 41.25it/s, loss=0.000229, v_num=3845523, train_loss_step=0.000233, train_loss_epoch=0.000208]\n",
      "Epoch 143: 100%|██████████| 241/241 [00:05<00:00, 44.82it/s, loss=0.000229, v_num=3845523, train_loss_step=0.000233, train_loss_epoch=0.000208]\n",
      "Epoch 144:  84%|████████▍ | 203/241 [00:03<00:00, 51.04it/s, loss=0.00018, v_num=3845523, train_loss_step=0.000197, train_loss_epoch=0.000213] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 144:  90%|████████▉ | 216/241 [00:05<00:00, 40.70it/s, loss=0.00018, v_num=3845523, train_loss_step=0.000197, train_loss_epoch=0.000213]\n",
      "Epoch 144: 100%|██████████| 241/241 [00:05<00:00, 44.18it/s, loss=0.00018, v_num=3845523, train_loss_step=0.000197, train_loss_epoch=0.000213]\n",
      "Epoch 145:  84%|████████▍ | 203/241 [00:04<00:00, 45.47it/s, loss=0.000204, v_num=3845523, train_loss_step=0.000206, train_loss_epoch=0.000205]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 145:  90%|████████▉ | 216/241 [00:06<00:00, 35.44it/s, loss=0.000204, v_num=3845523, train_loss_step=0.000206, train_loss_epoch=0.000205]\n",
      "Epoch 145: 100%|██████████| 241/241 [00:06<00:00, 38.53it/s, loss=0.000204, v_num=3845523, train_loss_step=0.000206, train_loss_epoch=0.000205]\n",
      "Epoch 146:  84%|████████▍ | 203/241 [00:03<00:00, 52.50it/s, loss=0.000198, v_num=3845523, train_loss_step=0.000172, train_loss_epoch=0.000208]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 146:  90%|████████▉ | 216/241 [00:05<00:00, 39.49it/s, loss=0.000198, v_num=3845523, train_loss_step=0.000172, train_loss_epoch=0.000208]\n",
      "Validating:  53%|█████▎    | 20/38 [00:01<00:01, 16.94it/s]\u001b[A\n",
      "Epoch 146: 100%|██████████| 241/241 [00:05<00:00, 42.88it/s, loss=0.000198, v_num=3845523, train_loss_step=0.000172, train_loss_epoch=0.000208]\n",
      "Epoch 147:  84%|████████▍ | 203/241 [00:04<00:00, 46.55it/s, loss=0.000266, v_num=3845523, train_loss_step=0.000291, train_loss_epoch=0.000206]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 147:  90%|████████▉ | 216/241 [00:05<00:00, 36.18it/s, loss=0.000266, v_num=3845523, train_loss_step=0.000291, train_loss_epoch=0.000206]\n",
      "Epoch 147: 100%|██████████| 241/241 [00:06<00:00, 39.42it/s, loss=0.000266, v_num=3845523, train_loss_step=0.000291, train_loss_epoch=0.000206]\n",
      "Epoch 148:  84%|████████▍ | 203/241 [00:03<00:00, 52.64it/s, loss=0.000218, v_num=3845523, train_loss_step=0.000191, train_loss_epoch=0.000211]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:57,  1.56s/it]\u001b[A\n",
      "Epoch 148:  90%|████████▉ | 216/241 [00:05<00:00, 39.03it/s, loss=0.000218, v_num=3845523, train_loss_step=0.000191, train_loss_epoch=0.000211]\n",
      "Epoch 148: 100%|██████████| 241/241 [00:05<00:00, 42.36it/s, loss=0.000218, v_num=3845523, train_loss_step=0.000191, train_loss_epoch=0.000211]\n",
      "Epoch 149:  84%|████████▍ | 203/241 [00:03<00:00, 55.67it/s, loss=0.000189, v_num=3845523, train_loss_step=0.000198, train_loss_epoch=0.000209]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:56,  1.54s/it]\u001b[A\n",
      "Epoch 149:  90%|████████▉ | 216/241 [00:05<00:00, 36.32it/s, loss=0.000189, v_num=3845523, train_loss_step=0.000198, train_loss_epoch=0.000209]\n",
      "Epoch 149: 100%|██████████| 241/241 [00:06<00:00, 39.40it/s, loss=0.000189, v_num=3845523, train_loss_step=0.000198, train_loss_epoch=0.000209]\n",
      "Epoch 150:  84%|████████▍ | 203/241 [00:03<00:00, 58.82it/s, loss=0.000215, v_num=3845523, train_loss_step=0.000184, train_loss_epoch=0.000201]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 150:  90%|████████▉ | 216/241 [00:05<00:00, 42.48it/s, loss=0.000215, v_num=3845523, train_loss_step=0.000184, train_loss_epoch=0.000201]\n",
      "Epoch 150: 100%|██████████| 241/241 [00:05<00:00, 46.06it/s, loss=0.000215, v_num=3845523, train_loss_step=0.000184, train_loss_epoch=0.000201]\n",
      "Epoch 151:  84%|████████▍ | 203/241 [00:03<00:00, 58.54it/s, loss=0.000183, v_num=3845523, train_loss_step=0.000202, train_loss_epoch=0.000206]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:55,  1.51s/it]\u001b[A\n",
      "Epoch 151:  90%|████████▉ | 216/241 [00:05<00:00, 42.32it/s, loss=0.000183, v_num=3845523, train_loss_step=0.000202, train_loss_epoch=0.000206]\n",
      "Epoch 151: 100%|██████████| 241/241 [00:05<00:00, 45.89it/s, loss=0.000183, v_num=3845523, train_loss_step=0.000202, train_loss_epoch=0.000206]\n",
      "Epoch 152:  84%|████████▍ | 203/241 [00:03<00:00, 61.20it/s, loss=0.000232, v_num=3845523, train_loss_step=0.000226, train_loss_epoch=0.000205]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 152:  90%|████████▉ | 216/241 [00:04<00:00, 44.15it/s, loss=0.000232, v_num=3845523, train_loss_step=0.000226, train_loss_epoch=0.000205]\n",
      "Epoch 152: 100%|██████████| 241/241 [00:05<00:00, 47.68it/s, loss=0.000232, v_num=3845523, train_loss_step=0.000226, train_loss_epoch=0.000205]\n",
      "Epoch 153:  84%|████████▍ | 203/241 [00:03<00:00, 59.93it/s, loss=0.000244, v_num=3845523, train_loss_step=0.000254, train_loss_epoch=0.000208]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 153:  90%|████████▉ | 216/241 [00:04<00:00, 43.39it/s, loss=0.000244, v_num=3845523, train_loss_step=0.000254, train_loss_epoch=0.000208]\n",
      "Epoch 153: 100%|██████████| 241/241 [00:05<00:00, 46.99it/s, loss=0.000244, v_num=3845523, train_loss_step=0.000254, train_loss_epoch=0.000208]\n",
      "Epoch 154:  84%|████████▍ | 203/241 [00:03<00:00, 60.85it/s, loss=0.000225, v_num=3845523, train_loss_step=0.000215, train_loss_epoch=0.000206]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 154:  90%|████████▉ | 216/241 [00:04<00:00, 43.38it/s, loss=0.000225, v_num=3845523, train_loss_step=0.000215, train_loss_epoch=0.000206]\n",
      "Epoch 154: 100%|██████████| 241/241 [00:05<00:00, 46.94it/s, loss=0.000225, v_num=3845523, train_loss_step=0.000215, train_loss_epoch=0.000206]\n",
      "Epoch 155:  84%|████████▍ | 203/241 [00:03<00:00, 59.06it/s, loss=0.000192, v_num=3845523, train_loss_step=0.000195, train_loss_epoch=0.000204]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 155:  90%|████████▉ | 216/241 [00:05<00:00, 42.29it/s, loss=0.000192, v_num=3845523, train_loss_step=0.000195, train_loss_epoch=0.000204]\n",
      "Epoch 155: 100%|██████████| 241/241 [00:05<00:00, 45.84it/s, loss=0.000192, v_num=3845523, train_loss_step=0.000195, train_loss_epoch=0.000204]\n",
      "Epoch 156:  84%|████████▍ | 203/241 [00:04<00:00, 47.75it/s, loss=0.00019, v_num=3845523, train_loss_step=0.000181, train_loss_epoch=0.000201] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 156:  90%|████████▉ | 216/241 [00:06<00:00, 34.64it/s, loss=0.00019, v_num=3845523, train_loss_step=0.000181, train_loss_epoch=0.000201]\n",
      "Epoch 156: 100%|██████████| 241/241 [00:06<00:00, 37.67it/s, loss=0.00019, v_num=3845523, train_loss_step=0.000181, train_loss_epoch=0.000201]\n",
      "Epoch 157:  84%|████████▍ | 203/241 [00:04<00:00, 50.66it/s, loss=0.000238, v_num=3845523, train_loss_step=0.000206, train_loss_epoch=0.000203]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 157:  90%|████████▉ | 216/241 [00:06<00:00, 33.88it/s, loss=0.000238, v_num=3845523, train_loss_step=0.000206, train_loss_epoch=0.000203]\n",
      "Epoch 157: 100%|██████████| 241/241 [00:06<00:00, 36.89it/s, loss=0.000238, v_num=3845523, train_loss_step=0.000206, train_loss_epoch=0.000203]\n",
      "Epoch 158:  84%|████████▍ | 203/241 [00:04<00:00, 47.08it/s, loss=0.000223, v_num=3845523, train_loss_step=0.000181, train_loss_epoch=0.000203]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:57,  1.55s/it]\u001b[A\n",
      "Epoch 158:  90%|████████▉ | 216/241 [00:05<00:00, 36.12it/s, loss=0.000223, v_num=3845523, train_loss_step=0.000181, train_loss_epoch=0.000203]\n",
      "Epoch 158: 100%|██████████| 241/241 [00:06<00:00, 39.23it/s, loss=0.000223, v_num=3845523, train_loss_step=0.000181, train_loss_epoch=0.000203]\n",
      "Epoch 159:  84%|████████▍ | 203/241 [00:04<00:00, 47.38it/s, loss=0.000209, v_num=3845523, train_loss_step=0.000219, train_loss_epoch=0.0002]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 159:  90%|████████▉ | 216/241 [00:06<00:00, 35.31it/s, loss=0.000209, v_num=3845523, train_loss_step=0.000219, train_loss_epoch=0.0002]\n",
      "Epoch 159: 100%|██████████| 241/241 [00:06<00:00, 38.39it/s, loss=0.000209, v_num=3845523, train_loss_step=0.000219, train_loss_epoch=0.0002]\n",
      "Epoch 160:  84%|████████▍ | 203/241 [00:04<00:00, 47.00it/s, loss=0.000215, v_num=3845523, train_loss_step=0.000172, train_loss_epoch=0.000201]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 160:  90%|████████▉ | 216/241 [00:06<00:00, 32.20it/s, loss=0.000215, v_num=3845523, train_loss_step=0.000172, train_loss_epoch=0.000201]\n",
      "Epoch 160: 100%|██████████| 241/241 [00:06<00:00, 35.14it/s, loss=0.000215, v_num=3845523, train_loss_step=0.000172, train_loss_epoch=0.000201]\n",
      "Epoch 161:  84%|████████▍ | 203/241 [00:03<00:00, 52.37it/s, loss=0.000199, v_num=3845523, train_loss_step=0.000265, train_loss_epoch=0.000199]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 161:  90%|████████▉ | 216/241 [00:05<00:00, 39.42it/s, loss=0.000199, v_num=3845523, train_loss_step=0.000265, train_loss_epoch=0.000199]\n",
      "Epoch 161: 100%|██████████| 241/241 [00:05<00:00, 42.78it/s, loss=0.000199, v_num=3845523, train_loss_step=0.000265, train_loss_epoch=0.000199]\n",
      "Epoch 162:  84%|████████▍ | 203/241 [00:04<00:00, 50.13it/s, loss=0.000199, v_num=3845523, train_loss_step=0.000176, train_loss_epoch=0.000203]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 162:  90%|████████▉ | 216/241 [00:06<00:00, 35.16it/s, loss=0.000199, v_num=3845523, train_loss_step=0.000176, train_loss_epoch=0.000203]\n",
      "Epoch 162: 100%|██████████| 241/241 [00:06<00:00, 38.28it/s, loss=0.000199, v_num=3845523, train_loss_step=0.000176, train_loss_epoch=0.000203]\n",
      "Epoch 163:  84%|████████▍ | 203/241 [00:04<00:00, 49.05it/s, loss=0.000205, v_num=3845523, train_loss_step=0.000192, train_loss_epoch=0.000203]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:56,  1.53s/it]\u001b[A\n",
      "Epoch 163:  90%|████████▉ | 216/241 [00:06<00:00, 35.86it/s, loss=0.000205, v_num=3845523, train_loss_step=0.000192, train_loss_epoch=0.000203]\n",
      "Epoch 163: 100%|██████████| 241/241 [00:06<00:00, 39.04it/s, loss=0.000205, v_num=3845523, train_loss_step=0.000192, train_loss_epoch=0.000203]\n",
      "Epoch 164:  84%|████████▍ | 203/241 [00:04<00:00, 49.48it/s, loss=0.000202, v_num=3845523, train_loss_step=0.000166, train_loss_epoch=0.000199]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:00,  1.64s/it]\u001b[A\n",
      "Epoch 164:  90%|████████▉ | 216/241 [00:06<00:00, 35.63it/s, loss=0.000202, v_num=3845523, train_loss_step=0.000166, train_loss_epoch=0.000199]\n",
      "Epoch 164: 100%|██████████| 241/241 [00:06<00:00, 38.76it/s, loss=0.000202, v_num=3845523, train_loss_step=0.000166, train_loss_epoch=0.000199]\n",
      "Epoch 165:  84%|████████▍ | 203/241 [00:04<00:00, 49.43it/s, loss=0.000221, v_num=3845523, train_loss_step=0.000216, train_loss_epoch=0.000201]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:55,  1.50s/it]\u001b[A\n",
      "Epoch 165:  90%|████████▉ | 216/241 [00:05<00:00, 37.70it/s, loss=0.000221, v_num=3845523, train_loss_step=0.000216, train_loss_epoch=0.000201]\n",
      "Epoch 165: 100%|██████████| 241/241 [00:05<00:00, 40.94it/s, loss=0.000221, v_num=3845523, train_loss_step=0.000216, train_loss_epoch=0.000201]\n",
      "Epoch 166:  84%|████████▍ | 203/241 [00:03<00:00, 55.27it/s, loss=0.000206, v_num=3845523, train_loss_step=0.000173, train_loss_epoch=0.0002]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 166:  90%|████████▉ | 216/241 [00:05<00:00, 40.79it/s, loss=0.000206, v_num=3845523, train_loss_step=0.000173, train_loss_epoch=0.0002]\n",
      "Epoch 166: 100%|██████████| 241/241 [00:05<00:00, 44.29it/s, loss=0.000206, v_num=3845523, train_loss_step=0.000173, train_loss_epoch=0.0002]\n",
      "Epoch 167:  84%|████████▍ | 203/241 [00:03<00:00, 55.88it/s, loss=0.000226, v_num=3845523, train_loss_step=0.000208, train_loss_epoch=0.0002]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 167:  90%|████████▉ | 216/241 [00:05<00:00, 41.09it/s, loss=0.000226, v_num=3845523, train_loss_step=0.000208, train_loss_epoch=0.0002]\n",
      "Validating:  47%|████▋     | 18/38 [00:01<00:01, 15.09it/s]\u001b[A\n",
      "Epoch 167: 100%|██████████| 241/241 [00:05<00:00, 44.60it/s, loss=0.000226, v_num=3845523, train_loss_step=0.000208, train_loss_epoch=0.0002]\n",
      "Epoch 168:  84%|████████▍ | 203/241 [00:04<00:00, 50.34it/s, loss=0.000202, v_num=3845523, train_loss_step=0.000189, train_loss_epoch=0.000196]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 168:  90%|████████▉ | 216/241 [00:05<00:00, 36.31it/s, loss=0.000202, v_num=3845523, train_loss_step=0.000189, train_loss_epoch=0.000196]\n",
      "Epoch 168: 100%|██████████| 241/241 [00:06<00:00, 39.23it/s, loss=0.000202, v_num=3845523, train_loss_step=0.000189, train_loss_epoch=0.000196]\n",
      "Epoch 169:  84%|████████▍ | 203/241 [00:03<00:00, 56.49it/s, loss=0.000203, v_num=3845523, train_loss_step=0.000169, train_loss_epoch=0.000202]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 169:  90%|████████▉ | 216/241 [00:05<00:00, 39.94it/s, loss=0.000203, v_num=3845523, train_loss_step=0.000169, train_loss_epoch=0.000202]\n",
      "Epoch 169: 100%|██████████| 241/241 [00:05<00:00, 43.32it/s, loss=0.000203, v_num=3845523, train_loss_step=0.000169, train_loss_epoch=0.000202]\n",
      "Epoch 170:  84%|████████▍ | 203/241 [00:04<00:00, 50.36it/s, loss=0.000203, v_num=3845523, train_loss_step=0.000174, train_loss_epoch=0.000198]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 170:  90%|████████▉ | 216/241 [00:05<00:00, 37.18it/s, loss=0.000203, v_num=3845523, train_loss_step=0.000174, train_loss_epoch=0.000198]\n",
      "Epoch 170: 100%|██████████| 241/241 [00:06<00:00, 40.15it/s, loss=0.000203, v_num=3845523, train_loss_step=0.000174, train_loss_epoch=0.000198]\n",
      "Epoch 171:  84%|████████▍ | 203/241 [00:04<00:00, 50.10it/s, loss=0.000228, v_num=3845523, train_loss_step=0.000229, train_loss_epoch=0.000194]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 171:  90%|████████▉ | 216/241 [00:06<00:00, 35.05it/s, loss=0.000228, v_num=3845523, train_loss_step=0.000229, train_loss_epoch=0.000194]\n",
      "Epoch 171: 100%|██████████| 241/241 [00:06<00:00, 37.86it/s, loss=0.000228, v_num=3845523, train_loss_step=0.000229, train_loss_epoch=0.000194]\n",
      "Epoch 172:  84%|████████▍ | 203/241 [00:03<00:00, 54.76it/s, loss=0.00019, v_num=3845523, train_loss_step=0.000226, train_loss_epoch=0.000198] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 172:  90%|████████▉ | 216/241 [00:05<00:00, 38.12it/s, loss=0.00019, v_num=3845523, train_loss_step=0.000226, train_loss_epoch=0.000198]\n",
      "Epoch 172: 100%|██████████| 241/241 [00:05<00:00, 41.04it/s, loss=0.00019, v_num=3845523, train_loss_step=0.000226, train_loss_epoch=0.000198]\n",
      "Epoch 173:  84%|████████▍ | 203/241 [00:03<00:00, 51.95it/s, loss=0.00019, v_num=3845523, train_loss_step=0.000204, train_loss_epoch=0.000193] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 173:  90%|████████▉ | 216/241 [00:05<00:00, 38.54it/s, loss=0.00019, v_num=3845523, train_loss_step=0.000204, train_loss_epoch=0.000193]\n",
      "Epoch 173: 100%|██████████| 241/241 [00:05<00:00, 41.36it/s, loss=0.00019, v_num=3845523, train_loss_step=0.000204, train_loss_epoch=0.000193]\n",
      "Epoch 174:  84%|████████▍ | 203/241 [00:03<00:00, 51.43it/s, loss=0.000215, v_num=3845523, train_loss_step=0.000249, train_loss_epoch=0.000198]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:03,  1.71s/it]\u001b[A\n",
      "Epoch 174:  90%|████████▉ | 216/241 [00:05<00:00, 37.06it/s, loss=0.000215, v_num=3845523, train_loss_step=0.000249, train_loss_epoch=0.000198]\n",
      "Epoch 174: 100%|██████████| 241/241 [00:06<00:00, 39.93it/s, loss=0.000215, v_num=3845523, train_loss_step=0.000249, train_loss_epoch=0.000198]\n",
      "Epoch 175:  84%|████████▍ | 203/241 [00:04<00:00, 42.02it/s, loss=0.000245, v_num=3845523, train_loss_step=0.000278, train_loss_epoch=0.000196]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 175:  90%|████████▉ | 216/241 [00:06<00:00, 33.30it/s, loss=0.000245, v_num=3845523, train_loss_step=0.000278, train_loss_epoch=0.000196]\n",
      "Epoch 175: 100%|██████████| 241/241 [00:06<00:00, 36.12it/s, loss=0.000245, v_num=3845523, train_loss_step=0.000278, train_loss_epoch=0.000196]\n",
      "Epoch 176:  84%|████████▍ | 203/241 [00:04<00:00, 44.31it/s, loss=0.000195, v_num=3845523, train_loss_step=0.000195, train_loss_epoch=0.000198]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 176:  90%|████████▉ | 216/241 [00:06<00:00, 32.82it/s, loss=0.000195, v_num=3845523, train_loss_step=0.000195, train_loss_epoch=0.000198]\n",
      "Epoch 176: 100%|██████████| 241/241 [00:06<00:00, 35.57it/s, loss=0.000195, v_num=3845523, train_loss_step=0.000195, train_loss_epoch=0.000198]\n",
      "Epoch 177:  84%|████████▍ | 203/241 [00:04<00:00, 43.74it/s, loss=0.000229, v_num=3845523, train_loss_step=0.000237, train_loss_epoch=0.000194]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:59,  1.60s/it]\u001b[A\n",
      "Epoch 177:  90%|████████▉ | 216/241 [00:06<00:00, 33.05it/s, loss=0.000229, v_num=3845523, train_loss_step=0.000237, train_loss_epoch=0.000194]\n",
      "Epoch 177: 100%|██████████| 241/241 [00:06<00:00, 35.83it/s, loss=0.000229, v_num=3845523, train_loss_step=0.000237, train_loss_epoch=0.000194]\n",
      "Epoch 178:  84%|████████▍ | 203/241 [00:04<00:00, 41.24it/s, loss=0.000199, v_num=3845523, train_loss_step=0.000186, train_loss_epoch=0.000195]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:01,  1.67s/it]\u001b[A\n",
      "Validating:   5%|▌         | 2/38 [00:01<00:28,  1.26it/s]\u001b[A\n",
      "Epoch 178:  90%|████████▉ | 216/241 [00:06<00:00, 31.34it/s, loss=0.000199, v_num=3845523, train_loss_step=0.000186, train_loss_epoch=0.000195]\n",
      "Epoch 178: 100%|██████████| 241/241 [00:07<00:00, 34.04it/s, loss=0.000199, v_num=3845523, train_loss_step=0.000186, train_loss_epoch=0.000195]\n",
      "Epoch 179:  84%|████████▍ | 203/241 [00:04<00:00, 46.82it/s, loss=0.000198, v_num=3845523, train_loss_step=0.00017, train_loss_epoch=0.000192] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 179:  90%|████████▉ | 216/241 [00:06<00:00, 34.10it/s, loss=0.000198, v_num=3845523, train_loss_step=0.00017, train_loss_epoch=0.000192]\n",
      "Epoch 179: 100%|██████████| 241/241 [00:06<00:00, 36.93it/s, loss=0.000198, v_num=3845523, train_loss_step=0.00017, train_loss_epoch=0.000192]\n",
      "Epoch 180:  84%|████████▍ | 203/241 [00:04<00:00, 45.81it/s, loss=0.000196, v_num=3845523, train_loss_step=0.000206, train_loss_epoch=0.000193]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:06,  1.79s/it]\u001b[A\n",
      "Epoch 180:  90%|████████▉ | 216/241 [00:06<00:00, 32.86it/s, loss=0.000196, v_num=3845523, train_loss_step=0.000206, train_loss_epoch=0.000193]\n",
      "Epoch 180: 100%|██████████| 241/241 [00:06<00:00, 35.59it/s, loss=0.000196, v_num=3845523, train_loss_step=0.000206, train_loss_epoch=0.000193]\n",
      "Epoch 181:  84%|████████▍ | 203/241 [00:05<00:00, 38.96it/s, loss=0.000195, v_num=3845523, train_loss_step=0.000162, train_loss_epoch=0.000194]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 181:  90%|████████▉ | 216/241 [00:06<00:00, 31.26it/s, loss=0.000195, v_num=3845523, train_loss_step=0.000162, train_loss_epoch=0.000194]\n",
      "Validating:  63%|██████▎   | 24/38 [00:01<00:00, 19.22it/s]\u001b[A\n",
      "Epoch 181: 100%|██████████| 241/241 [00:07<00:00, 33.99it/s, loss=0.000195, v_num=3845523, train_loss_step=0.000162, train_loss_epoch=0.000194]\n",
      "Epoch 182:  84%|████████▍ | 203/241 [00:04<00:00, 42.18it/s, loss=0.000221, v_num=3845523, train_loss_step=0.000226, train_loss_epoch=0.000192]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:04,  1.74s/it]\u001b[A\n",
      "Epoch 182:  90%|████████▉ | 216/241 [00:06<00:00, 32.12it/s, loss=0.000221, v_num=3845523, train_loss_step=0.000226, train_loss_epoch=0.000192]\n",
      "Epoch 182: 100%|██████████| 241/241 [00:06<00:00, 34.84it/s, loss=0.000221, v_num=3845523, train_loss_step=0.000226, train_loss_epoch=0.000192]\n",
      "Epoch 183:  84%|████████▍ | 203/241 [00:04<00:00, 45.76it/s, loss=0.000192, v_num=3845523, train_loss_step=0.000187, train_loss_epoch=0.000194]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:00,  1.63s/it]\u001b[A\n",
      "Epoch 183:  90%|████████▉ | 216/241 [00:06<00:00, 34.93it/s, loss=0.000192, v_num=3845523, train_loss_step=0.000187, train_loss_epoch=0.000194]\n",
      "Epoch 183: 100%|██████████| 241/241 [00:06<00:00, 37.84it/s, loss=0.000192, v_num=3845523, train_loss_step=0.000187, train_loss_epoch=0.000194]\n",
      "Epoch 184:  84%|████████▍ | 203/241 [00:04<00:00, 47.04it/s, loss=0.000172, v_num=3845523, train_loss_step=0.000176, train_loss_epoch=0.00019] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:59,  1.62s/it]\u001b[A\n",
      "Validating:   8%|▊         | 3/38 [00:01<00:16,  2.15it/s]\u001b[A\n",
      "Epoch 184:  90%|████████▉ | 216/241 [00:06<00:00, 34.96it/s, loss=0.000172, v_num=3845523, train_loss_step=0.000176, train_loss_epoch=0.00019]\n",
      "Epoch 184: 100%|██████████| 241/241 [00:06<00:00, 37.84it/s, loss=0.000172, v_num=3845523, train_loss_step=0.000176, train_loss_epoch=0.00019]\n",
      "Epoch 185:  84%|████████▍ | 203/241 [00:05<00:00, 39.92it/s, loss=0.000235, v_num=3845523, train_loss_step=0.000193, train_loss_epoch=0.000189]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:03,  1.71s/it]\u001b[A\n",
      "Epoch 185:  90%|████████▉ | 216/241 [00:06<00:00, 31.04it/s, loss=0.000235, v_num=3845523, train_loss_step=0.000193, train_loss_epoch=0.000189]\n",
      "Epoch 185: 100%|██████████| 241/241 [00:07<00:00, 33.74it/s, loss=0.000235, v_num=3845523, train_loss_step=0.000193, train_loss_epoch=0.000189]\n",
      "Epoch 186:  84%|████████▍ | 203/241 [00:04<00:00, 46.91it/s, loss=0.000204, v_num=3845523, train_loss_step=0.000195, train_loss_epoch=0.000196]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 186:  90%|████████▉ | 216/241 [00:05<00:00, 36.24it/s, loss=0.000204, v_num=3845523, train_loss_step=0.000195, train_loss_epoch=0.000196]\n",
      "Validating:  42%|████▏     | 16/38 [00:01<00:01, 13.33it/s]\u001b[A\n",
      "Epoch 186: 100%|██████████| 241/241 [00:06<00:00, 39.16it/s, loss=0.000204, v_num=3845523, train_loss_step=0.000195, train_loss_epoch=0.000196]\n",
      "Epoch 187:  84%|████████▍ | 203/241 [00:04<00:00, 48.43it/s, loss=0.000247, v_num=3845523, train_loss_step=0.000262, train_loss_epoch=0.000191]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 187:  90%|████████▉ | 216/241 [00:05<00:00, 36.15it/s, loss=0.000247, v_num=3845523, train_loss_step=0.000262, train_loss_epoch=0.000191]\n",
      "Epoch 187: 100%|██████████| 241/241 [00:06<00:00, 39.05it/s, loss=0.000247, v_num=3845523, train_loss_step=0.000262, train_loss_epoch=0.000191]\n",
      "Epoch 188:  84%|████████▍ | 203/241 [00:04<00:00, 49.93it/s, loss=0.00019, v_num=3845523, train_loss_step=0.000159, train_loss_epoch=0.000194] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 188:  90%|████████▉ | 216/241 [00:05<00:00, 37.51it/s, loss=0.00019, v_num=3845523, train_loss_step=0.000159, train_loss_epoch=0.000194]\n",
      "Epoch 188: 100%|██████████| 241/241 [00:05<00:00, 40.50it/s, loss=0.00019, v_num=3845523, train_loss_step=0.000159, train_loss_epoch=0.000194]\n",
      "Epoch 189:  84%|████████▍ | 203/241 [00:04<00:00, 49.65it/s, loss=0.000228, v_num=3845523, train_loss_step=0.000197, train_loss_epoch=0.000186]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:00,  1.64s/it]\u001b[A\n",
      "Epoch 189:  90%|████████▉ | 216/241 [00:05<00:00, 36.51it/s, loss=0.000228, v_num=3845523, train_loss_step=0.000197, train_loss_epoch=0.000186]\n",
      "Epoch 189: 100%|██████████| 241/241 [00:06<00:00, 39.38it/s, loss=0.000228, v_num=3845523, train_loss_step=0.000197, train_loss_epoch=0.000186]\n",
      "Epoch 190:  84%|████████▍ | 203/241 [00:04<00:00, 47.71it/s, loss=0.000223, v_num=3845523, train_loss_step=0.000225, train_loss_epoch=0.000194]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:00,  1.63s/it]\u001b[A\n",
      "Epoch 190:  90%|████████▉ | 216/241 [00:06<00:00, 35.52it/s, loss=0.000223, v_num=3845523, train_loss_step=0.000225, train_loss_epoch=0.000194]\n",
      "Epoch 190: 100%|██████████| 241/241 [00:06<00:00, 38.26it/s, loss=0.000223, v_num=3845523, train_loss_step=0.000225, train_loss_epoch=0.000194]\n",
      "Epoch 191:  84%|████████▍ | 203/241 [00:04<00:00, 47.07it/s, loss=0.000194, v_num=3845523, train_loss_step=0.000176, train_loss_epoch=0.00019] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 191:  90%|████████▉ | 216/241 [00:05<00:00, 38.44it/s, loss=0.000194, v_num=3845523, train_loss_step=0.000176, train_loss_epoch=0.00019]\n",
      "Epoch 191: 100%|██████████| 241/241 [00:05<00:00, 41.79it/s, loss=0.000194, v_num=3845523, train_loss_step=0.000176, train_loss_epoch=0.00019]\n",
      "Epoch 192:  84%|████████▍ | 203/241 [00:04<00:00, 48.93it/s, loss=0.000182, v_num=3845523, train_loss_step=0.00016, train_loss_epoch=0.000185] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 192:  90%|████████▉ | 216/241 [00:05<00:00, 39.17it/s, loss=0.000182, v_num=3845523, train_loss_step=0.00016, train_loss_epoch=0.000185]\n",
      "Epoch 192: 100%|██████████| 241/241 [00:05<00:00, 42.60it/s, loss=0.000182, v_num=3845523, train_loss_step=0.00016, train_loss_epoch=0.000185]\n",
      "Epoch 193:  84%|████████▍ | 203/241 [00:04<00:00, 47.95it/s, loss=0.000202, v_num=3845523, train_loss_step=0.000191, train_loss_epoch=0.000191]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 193:  90%|████████▉ | 216/241 [00:05<00:00, 38.76it/s, loss=0.000202, v_num=3845523, train_loss_step=0.000191, train_loss_epoch=0.000191]\n",
      "Epoch 193: 100%|██████████| 241/241 [00:05<00:00, 42.12it/s, loss=0.000202, v_num=3845523, train_loss_step=0.000191, train_loss_epoch=0.000191]\n",
      "Epoch 194:  84%|████████▍ | 203/241 [00:04<00:00, 48.81it/s, loss=0.000198, v_num=3845523, train_loss_step=0.000178, train_loss_epoch=0.000189]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 194:  90%|████████▉ | 216/241 [00:05<00:00, 40.06it/s, loss=0.000198, v_num=3845523, train_loss_step=0.000178, train_loss_epoch=0.000189]\n",
      "Epoch 194: 100%|██████████| 241/241 [00:05<00:00, 43.51it/s, loss=0.000198, v_num=3845523, train_loss_step=0.000178, train_loss_epoch=0.000189]\n",
      "Epoch 195:  84%|████████▍ | 203/241 [00:04<00:00, 49.92it/s, loss=0.000244, v_num=3845523, train_loss_step=0.000188, train_loss_epoch=0.000187]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 195:  90%|████████▉ | 216/241 [00:05<00:00, 40.10it/s, loss=0.000244, v_num=3845523, train_loss_step=0.000188, train_loss_epoch=0.000187]\n",
      "Epoch 195: 100%|██████████| 241/241 [00:05<00:00, 43.51it/s, loss=0.000244, v_num=3845523, train_loss_step=0.000188, train_loss_epoch=0.000187]\n",
      "Epoch 196:  84%|████████▍ | 203/241 [00:03<00:00, 51.50it/s, loss=0.000199, v_num=3845523, train_loss_step=0.000175, train_loss_epoch=0.000192]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 196:  90%|████████▉ | 216/241 [00:05<00:00, 41.06it/s, loss=0.000199, v_num=3845523, train_loss_step=0.000175, train_loss_epoch=0.000192]\n",
      "Epoch 196: 100%|██████████| 241/241 [00:05<00:00, 44.59it/s, loss=0.000199, v_num=3845523, train_loss_step=0.000175, train_loss_epoch=0.000192]\n",
      "Epoch 197:  84%|████████▍ | 203/241 [00:04<00:00, 50.37it/s, loss=0.000185, v_num=3845523, train_loss_step=0.000163, train_loss_epoch=0.000185]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 197:  90%|████████▉ | 216/241 [00:05<00:00, 40.63it/s, loss=0.000185, v_num=3845523, train_loss_step=0.000163, train_loss_epoch=0.000185]\n",
      "Epoch 197: 100%|██████████| 241/241 [00:05<00:00, 44.14it/s, loss=0.000185, v_num=3845523, train_loss_step=0.000163, train_loss_epoch=0.000185]\n",
      "Epoch 198:  84%|████████▍ | 203/241 [00:04<00:00, 47.19it/s, loss=0.000208, v_num=3845523, train_loss_step=0.000203, train_loss_epoch=0.000189]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 198:  90%|████████▉ | 216/241 [00:05<00:00, 38.61it/s, loss=0.000208, v_num=3845523, train_loss_step=0.000203, train_loss_epoch=0.000189]\n",
      "Validating:  50%|█████     | 19/38 [00:01<00:00, 19.85it/s]\u001b[A\n",
      "Epoch 198: 100%|██████████| 241/241 [00:05<00:00, 41.99it/s, loss=0.000208, v_num=3845523, train_loss_step=0.000203, train_loss_epoch=0.000189]\n",
      "Epoch 199:  84%|████████▍ | 203/241 [00:04<00:00, 48.81it/s, loss=0.000235, v_num=3845523, train_loss_step=0.0002, train_loss_epoch=0.00019]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 199:  90%|████████▉ | 216/241 [00:05<00:00, 39.25it/s, loss=0.000235, v_num=3845523, train_loss_step=0.0002, train_loss_epoch=0.00019]\n",
      "Epoch 199: 100%|██████████| 241/241 [00:05<00:00, 42.62it/s, loss=0.000235, v_num=3845523, train_loss_step=0.0002, train_loss_epoch=0.00019]\n",
      "Epoch 200:  84%|████████▍ | 203/241 [00:04<00:00, 49.99it/s, loss=0.000186, v_num=3845523, train_loss_step=0.000158, train_loss_epoch=0.000187]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 200:  90%|████████▉ | 216/241 [00:05<00:00, 40.34it/s, loss=0.000186, v_num=3845523, train_loss_step=0.000158, train_loss_epoch=0.000187]\n",
      "Epoch 200: 100%|██████████| 241/241 [00:05<00:00, 43.36it/s, loss=0.000186, v_num=3845523, train_loss_step=0.000158, train_loss_epoch=0.000187]\n",
      "Epoch 201:  84%|████████▍ | 203/241 [00:05<00:00, 38.96it/s, loss=0.000223, v_num=3845523, train_loss_step=0.000182, train_loss_epoch=0.000188]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 201:  90%|████████▉ | 216/241 [00:06<00:00, 33.16it/s, loss=0.000223, v_num=3845523, train_loss_step=0.000182, train_loss_epoch=0.000188]\n",
      "Epoch 201: 100%|██████████| 241/241 [00:06<00:00, 36.08it/s, loss=0.000223, v_num=3845523, train_loss_step=0.000182, train_loss_epoch=0.000188]\n",
      "Epoch 202:  84%|████████▍ | 203/241 [00:03<00:00, 50.88it/s, loss=0.000199, v_num=3845523, train_loss_step=0.000218, train_loss_epoch=0.000187]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 202:  90%|████████▉ | 216/241 [00:05<00:00, 40.84it/s, loss=0.000199, v_num=3845523, train_loss_step=0.000218, train_loss_epoch=0.000187]\n",
      "Epoch 202: 100%|██████████| 241/241 [00:05<00:00, 44.38it/s, loss=0.000199, v_num=3845523, train_loss_step=0.000218, train_loss_epoch=0.000187]\n",
      "Epoch 203:  84%|████████▍ | 203/241 [00:04<00:00, 47.72it/s, loss=0.000233, v_num=3845523, train_loss_step=0.000234, train_loss_epoch=0.000186]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 203:  90%|████████▉ | 216/241 [00:05<00:00, 38.87it/s, loss=0.000233, v_num=3845523, train_loss_step=0.000234, train_loss_epoch=0.000186]\n",
      "Epoch 203: 100%|██████████| 241/241 [00:05<00:00, 42.20it/s, loss=0.000233, v_num=3845523, train_loss_step=0.000234, train_loss_epoch=0.000186]\n",
      "Epoch 204:  84%|████████▍ | 203/241 [00:03<00:00, 53.42it/s, loss=0.000209, v_num=3845523, train_loss_step=0.000204, train_loss_epoch=0.000189]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 204:  90%|████████▉ | 216/241 [00:05<00:00, 38.26it/s, loss=0.000209, v_num=3845523, train_loss_step=0.000204, train_loss_epoch=0.000189]\n",
      "Epoch 204: 100%|██████████| 241/241 [00:05<00:00, 41.53it/s, loss=0.000209, v_num=3845523, train_loss_step=0.000204, train_loss_epoch=0.000189]\n",
      "Epoch 205:  84%|████████▍ | 203/241 [00:03<00:00, 57.00it/s, loss=0.0002, v_num=3845523, train_loss_step=0.00016, train_loss_epoch=0.000184]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 205:  90%|████████▉ | 216/241 [00:05<00:00, 41.29it/s, loss=0.0002, v_num=3845523, train_loss_step=0.00016, train_loss_epoch=0.000184]\n",
      "Epoch 205: 100%|██████████| 241/241 [00:05<00:00, 44.72it/s, loss=0.0002, v_num=3845523, train_loss_step=0.00016, train_loss_epoch=0.000184]\n",
      "Epoch 206:  84%|████████▍ | 203/241 [00:03<00:00, 59.76it/s, loss=0.000213, v_num=3845523, train_loss_step=0.000202, train_loss_epoch=0.000183]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:56,  1.52s/it]\u001b[A\n",
      "Epoch 206:  90%|████████▉ | 216/241 [00:05<00:00, 42.79it/s, loss=0.000213, v_num=3845523, train_loss_step=0.000202, train_loss_epoch=0.000183]\n",
      "Epoch 206: 100%|██████████| 241/241 [00:05<00:00, 46.34it/s, loss=0.000213, v_num=3845523, train_loss_step=0.000202, train_loss_epoch=0.000183]\n",
      "Epoch 207:  84%|████████▍ | 203/241 [00:03<00:00, 58.85it/s, loss=0.000223, v_num=3845523, train_loss_step=0.000289, train_loss_epoch=0.000188]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 207:  90%|████████▉ | 216/241 [00:05<00:00, 39.50it/s, loss=0.000223, v_num=3845523, train_loss_step=0.000289, train_loss_epoch=0.000188]\n",
      "Epoch 207: 100%|██████████| 241/241 [00:05<00:00, 42.85it/s, loss=0.000223, v_num=3845523, train_loss_step=0.000289, train_loss_epoch=0.000188]\n",
      "Epoch 208:  84%|████████▍ | 203/241 [00:03<00:00, 57.53it/s, loss=0.000227, v_num=3845523, train_loss_step=0.000209, train_loss_epoch=0.000182]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 208:  90%|████████▉ | 216/241 [00:06<00:00, 35.90it/s, loss=0.000227, v_num=3845523, train_loss_step=0.000209, train_loss_epoch=0.000182]\n",
      "Epoch 208: 100%|██████████| 241/241 [00:06<00:00, 39.03it/s, loss=0.000227, v_num=3845523, train_loss_step=0.000209, train_loss_epoch=0.000182]\n",
      "Epoch 209:  84%|████████▍ | 203/241 [00:04<00:00, 48.36it/s, loss=0.000172, v_num=3845523, train_loss_step=0.000157, train_loss_epoch=0.000188]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 209:  90%|████████▉ | 216/241 [00:05<00:00, 36.69it/s, loss=0.000172, v_num=3845523, train_loss_step=0.000157, train_loss_epoch=0.000188]\n",
      "Epoch 209: 100%|██████████| 241/241 [00:06<00:00, 39.90it/s, loss=0.000172, v_num=3845523, train_loss_step=0.000157, train_loss_epoch=0.000188]\n",
      "Epoch 210:  84%|████████▍ | 203/241 [00:03<00:00, 55.60it/s, loss=0.000224, v_num=3845523, train_loss_step=0.000293, train_loss_epoch=0.00018] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 210:  90%|████████▉ | 216/241 [00:05<00:00, 41.02it/s, loss=0.000224, v_num=3845523, train_loss_step=0.000293, train_loss_epoch=0.00018]\n",
      "Epoch 210: 100%|██████████| 241/241 [00:05<00:00, 44.47it/s, loss=0.000224, v_num=3845523, train_loss_step=0.000293, train_loss_epoch=0.00018]\n",
      "Epoch 211:  84%|████████▍ | 203/241 [00:03<00:00, 58.42it/s, loss=0.00018, v_num=3845523, train_loss_step=0.000172, train_loss_epoch=0.000187] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 211:  90%|████████▉ | 216/241 [00:05<00:00, 42.40it/s, loss=0.00018, v_num=3845523, train_loss_step=0.000172, train_loss_epoch=0.000187]\n",
      "Validating:  45%|████▍     | 17/38 [00:01<00:01, 14.25it/s]\u001b[A\n",
      "Epoch 211: 100%|██████████| 241/241 [00:05<00:00, 45.74it/s, loss=0.00018, v_num=3845523, train_loss_step=0.000172, train_loss_epoch=0.000187]\n",
      "Epoch 212:  84%|████████▍ | 203/241 [00:03<00:00, 59.52it/s, loss=0.000233, v_num=3845523, train_loss_step=0.000222, train_loss_epoch=0.000181]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 212:  90%|████████▉ | 216/241 [00:05<00:00, 43.13it/s, loss=0.000233, v_num=3845523, train_loss_step=0.000222, train_loss_epoch=0.000181]\n",
      "Validating:  63%|██████▎   | 24/38 [00:01<00:00, 20.29it/s]\u001b[A\n",
      "Epoch 212: 100%|██████████| 241/241 [00:05<00:00, 46.61it/s, loss=0.000233, v_num=3845523, train_loss_step=0.000222, train_loss_epoch=0.000181]\n",
      "Epoch 213:  84%|████████▍ | 203/241 [00:03<00:00, 52.99it/s, loss=0.000196, v_num=3845523, train_loss_step=0.00019, train_loss_epoch=0.000188] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 213:  90%|████████▉ | 216/241 [00:05<00:00, 39.46it/s, loss=0.000196, v_num=3845523, train_loss_step=0.00019, train_loss_epoch=0.000188]\n",
      "Epoch 213: 100%|██████████| 241/241 [00:05<00:00, 42.81it/s, loss=0.000196, v_num=3845523, train_loss_step=0.00019, train_loss_epoch=0.000188]\n",
      "Epoch 214:  84%|████████▍ | 203/241 [00:03<00:00, 51.71it/s, loss=0.000198, v_num=3845523, train_loss_step=0.000212, train_loss_epoch=0.000182]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 214:  90%|████████▉ | 216/241 [00:05<00:00, 38.81it/s, loss=0.000198, v_num=3845523, train_loss_step=0.000212, train_loss_epoch=0.000182]\n",
      "Epoch 214: 100%|██████████| 241/241 [00:05<00:00, 42.17it/s, loss=0.000198, v_num=3845523, train_loss_step=0.000212, train_loss_epoch=0.000182]\n",
      "Epoch 215:  84%|████████▍ | 203/241 [00:04<00:00, 48.42it/s, loss=0.000167, v_num=3845523, train_loss_step=0.000187, train_loss_epoch=0.000183]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 215:  90%|████████▉ | 216/241 [00:05<00:00, 36.99it/s, loss=0.000167, v_num=3845523, train_loss_step=0.000187, train_loss_epoch=0.000183]\n",
      "Epoch 215: 100%|██████████| 241/241 [00:05<00:00, 40.18it/s, loss=0.000167, v_num=3845523, train_loss_step=0.000187, train_loss_epoch=0.000183]\n",
      "Epoch 216:  84%|████████▍ | 203/241 [00:04<00:00, 50.69it/s, loss=0.000227, v_num=3845523, train_loss_step=0.00019, train_loss_epoch=0.00018]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 216:  90%|████████▉ | 216/241 [00:05<00:00, 38.71it/s, loss=0.000227, v_num=3845523, train_loss_step=0.00019, train_loss_epoch=0.00018]\n",
      "Epoch 216: 100%|██████████| 241/241 [00:05<00:00, 42.08it/s, loss=0.000227, v_num=3845523, train_loss_step=0.00019, train_loss_epoch=0.00018]\n",
      "Epoch 217:  84%|████████▍ | 203/241 [00:04<00:00, 50.11it/s, loss=0.000229, v_num=3845523, train_loss_step=0.000317, train_loss_epoch=0.000189]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 217:  90%|████████▉ | 216/241 [00:05<00:00, 37.27it/s, loss=0.000229, v_num=3845523, train_loss_step=0.000317, train_loss_epoch=0.000189]\n",
      "Epoch 217: 100%|██████████| 241/241 [00:05<00:00, 40.48it/s, loss=0.000229, v_num=3845523, train_loss_step=0.000317, train_loss_epoch=0.000189]\n",
      "Epoch 218:  84%|████████▍ | 203/241 [00:04<00:00, 47.47it/s, loss=0.000169, v_num=3845523, train_loss_step=0.00019, train_loss_epoch=0.000181] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 218:  90%|████████▉ | 216/241 [00:05<00:00, 36.09it/s, loss=0.000169, v_num=3845523, train_loss_step=0.00019, train_loss_epoch=0.000181]\n",
      "Epoch 218: 100%|██████████| 241/241 [00:06<00:00, 39.22it/s, loss=0.000169, v_num=3845523, train_loss_step=0.00019, train_loss_epoch=0.000181]\n",
      "Epoch 219:  84%|████████▍ | 203/241 [00:04<00:00, 48.97it/s, loss=0.000229, v_num=3845523, train_loss_step=0.000209, train_loss_epoch=0.00018]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 219:  90%|████████▉ | 216/241 [00:05<00:00, 37.38it/s, loss=0.000229, v_num=3845523, train_loss_step=0.000209, train_loss_epoch=0.00018]\n",
      "Validating:  53%|█████▎    | 20/38 [00:01<00:01, 16.66it/s]\u001b[A\n",
      "Epoch 219: 100%|██████████| 241/241 [00:05<00:00, 40.62it/s, loss=0.000229, v_num=3845523, train_loss_step=0.000209, train_loss_epoch=0.00018]\n",
      "Epoch 220:  84%|████████▍ | 203/241 [00:03<00:00, 52.97it/s, loss=0.000164, v_num=3845523, train_loss_step=0.000167, train_loss_epoch=0.000186]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 220:  90%|████████▉ | 216/241 [00:05<00:00, 37.79it/s, loss=0.000164, v_num=3845523, train_loss_step=0.000167, train_loss_epoch=0.000186]\n",
      "Epoch 220: 100%|██████████| 241/241 [00:05<00:00, 41.06it/s, loss=0.000164, v_num=3845523, train_loss_step=0.000167, train_loss_epoch=0.000186]\n",
      "Epoch 221:  84%|████████▍ | 203/241 [00:04<00:00, 50.03it/s, loss=0.000186, v_num=3845523, train_loss_step=0.000161, train_loss_epoch=0.000178]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 221:  90%|████████▉ | 216/241 [00:05<00:00, 38.15it/s, loss=0.000186, v_num=3845523, train_loss_step=0.000161, train_loss_epoch=0.000178]\n",
      "Epoch 221: 100%|██████████| 241/241 [00:05<00:00, 41.48it/s, loss=0.000186, v_num=3845523, train_loss_step=0.000161, train_loss_epoch=0.000178]\n",
      "Epoch 222:  84%|████████▍ | 203/241 [00:03<00:00, 53.85it/s, loss=0.000182, v_num=3845523, train_loss_step=0.000351, train_loss_epoch=0.000184]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 222:  90%|████████▉ | 216/241 [00:05<00:00, 40.04it/s, loss=0.000182, v_num=3845523, train_loss_step=0.000351, train_loss_epoch=0.000184]\n",
      "Epoch 222: 100%|██████████| 241/241 [00:05<00:00, 43.45it/s, loss=0.000182, v_num=3845523, train_loss_step=0.000351, train_loss_epoch=0.000184]\n",
      "Epoch 223:  84%|████████▍ | 203/241 [00:03<00:00, 55.21it/s, loss=0.000195, v_num=3845523, train_loss_step=0.00017, train_loss_epoch=0.000178] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 223:  90%|████████▉ | 216/241 [00:05<00:00, 38.41it/s, loss=0.000195, v_num=3845523, train_loss_step=0.00017, train_loss_epoch=0.000178]\n",
      "Epoch 223: 100%|██████████| 241/241 [00:05<00:00, 41.46it/s, loss=0.000195, v_num=3845523, train_loss_step=0.00017, train_loss_epoch=0.000178]\n",
      "Epoch 224:  84%|████████▍ | 203/241 [00:03<00:00, 52.42it/s, loss=0.000239, v_num=3845523, train_loss_step=0.000281, train_loss_epoch=0.000183]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<01:01,  1.67s/it]\u001b[A\n",
      "Epoch 224:  90%|████████▉ | 216/241 [00:05<00:00, 37.02it/s, loss=0.000239, v_num=3845523, train_loss_step=0.000281, train_loss_epoch=0.000183]\n",
      "Epoch 224: 100%|██████████| 241/241 [00:06<00:00, 39.91it/s, loss=0.000239, v_num=3845523, train_loss_step=0.000281, train_loss_epoch=0.000183]\n",
      "Epoch 225:  84%|████████▍ | 203/241 [00:03<00:00, 51.57it/s, loss=0.000189, v_num=3845523, train_loss_step=0.000165, train_loss_epoch=0.000185]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 225:  90%|████████▉ | 216/241 [00:05<00:00, 38.67it/s, loss=0.000189, v_num=3845523, train_loss_step=0.000165, train_loss_epoch=0.000185]\n",
      "Epoch 225: 100%|██████████| 241/241 [00:05<00:00, 41.75it/s, loss=0.000189, v_num=3845523, train_loss_step=0.000165, train_loss_epoch=0.000185]\n",
      "Epoch 226:  84%|████████▍ | 203/241 [00:03<00:00, 55.30it/s, loss=0.00018, v_num=3845523, train_loss_step=0.000281, train_loss_epoch=0.00018]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 226:  90%|████████▉ | 216/241 [00:05<00:00, 40.51it/s, loss=0.00018, v_num=3845523, train_loss_step=0.000281, train_loss_epoch=0.00018]\n",
      "Epoch 226: 100%|██████████| 241/241 [00:05<00:00, 44.35it/s, loss=0.00018, v_num=3845523, train_loss_step=0.000281, train_loss_epoch=0.00018]\n",
      "Epoch 226: 100%|██████████| 241/241 [00:05<00:00, 43.14it/s, loss=0.00018, v_num=3845523, train_loss_step=0.000281, train_loss_epoch=0.00018]\n",
      "Epoch 227:  84%|████████▍ | 203/241 [00:03<00:00, 50.77it/s, loss=0.000193, v_num=3845523, train_loss_step=0.000187, train_loss_epoch=0.000176]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 227:  93%|█████████▎| 225/241 [00:05<00:00, 39.39it/s, loss=0.000193, v_num=3845523, train_loss_step=0.000187, train_loss_epoch=0.000176]\n",
      "Epoch 227: 100%|██████████| 241/241 [00:05<00:00, 40.86it/s, loss=0.000193, v_num=3845523, train_loss_step=0.000187, train_loss_epoch=0.000176]\n",
      "Epoch 228:  84%|████████▍ | 203/241 [00:03<00:00, 52.16it/s, loss=0.000218, v_num=3845523, train_loss_step=0.000215, train_loss_epoch=0.00018] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:57,  1.56s/it]\u001b[A\n",
      "Epoch 228:  93%|█████████▎| 225/241 [00:05<00:00, 40.12it/s, loss=0.000218, v_num=3845523, train_loss_step=0.000215, train_loss_epoch=0.00018]\n",
      "Epoch 228: 100%|██████████| 241/241 [00:05<00:00, 41.67it/s, loss=0.000218, v_num=3845523, train_loss_step=0.000215, train_loss_epoch=0.00018]\n",
      "Epoch 229:  84%|████████▍ | 203/241 [00:03<00:00, 51.66it/s, loss=0.000165, v_num=3845523, train_loss_step=0.000153, train_loss_epoch=0.000185]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 229:  93%|█████████▎| 225/241 [00:05<00:00, 37.97it/s, loss=0.000165, v_num=3845523, train_loss_step=0.000153, train_loss_epoch=0.000185]\n",
      "Epoch 229: 100%|██████████| 241/241 [00:06<00:00, 39.54it/s, loss=0.000165, v_num=3845523, train_loss_step=0.000153, train_loss_epoch=0.000185]\n",
      "Epoch 230:  84%|████████▍ | 203/241 [00:03<00:00, 55.52it/s, loss=0.000195, v_num=3845523, train_loss_step=0.00016, train_loss_epoch=0.000176] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 230:  93%|█████████▎| 225/241 [00:05<00:00, 42.22it/s, loss=0.000195, v_num=3845523, train_loss_step=0.00016, train_loss_epoch=0.000176]\n",
      "Epoch 230: 100%|██████████| 241/241 [00:05<00:00, 43.88it/s, loss=0.000195, v_num=3845523, train_loss_step=0.00016, train_loss_epoch=0.000176]\n",
      "Epoch 231:  84%|████████▍ | 203/241 [00:03<00:00, 52.38it/s, loss=0.000213, v_num=3845523, train_loss_step=0.00016, train_loss_epoch=0.00018] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:59,  1.61s/it]\u001b[A\n",
      "Epoch 231:  93%|█████████▎| 225/241 [00:05<00:00, 40.00it/s, loss=0.000213, v_num=3845523, train_loss_step=0.00016, train_loss_epoch=0.00018]\n",
      "Epoch 231: 100%|██████████| 241/241 [00:05<00:00, 41.56it/s, loss=0.000213, v_num=3845523, train_loss_step=0.00016, train_loss_epoch=0.00018]\n",
      "Epoch 232:  84%|████████▍ | 203/241 [00:04<00:00, 47.41it/s, loss=0.000169, v_num=3845523, train_loss_step=0.000149, train_loss_epoch=0.000181]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 232:  93%|█████████▎| 225/241 [00:05<00:00, 37.74it/s, loss=0.000169, v_num=3845523, train_loss_step=0.000149, train_loss_epoch=0.000181]\n",
      "Validating:  58%|█████▊    | 22/38 [00:01<00:00, 17.98it/s]\u001b[A\n",
      "Epoch 232: 100%|██████████| 241/241 [00:06<00:00, 39.37it/s, loss=0.000169, v_num=3845523, train_loss_step=0.000149, train_loss_epoch=0.000181]\n",
      "Epoch 233:  84%|████████▍ | 203/241 [00:04<00:00, 47.57it/s, loss=0.000201, v_num=3845523, train_loss_step=0.000156, train_loss_epoch=0.000176]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:59,  1.62s/it]\u001b[A\n",
      "Validating:   5%|▌         | 2/38 [00:01<00:29,  1.23it/s]\u001b[A\n",
      "Epoch 233:  93%|█████████▎| 225/241 [00:06<00:00, 36.05it/s, loss=0.000201, v_num=3845523, train_loss_step=0.000156, train_loss_epoch=0.000176]\n",
      "Epoch 233: 100%|██████████| 241/241 [00:06<00:00, 37.52it/s, loss=0.000201, v_num=3845523, train_loss_step=0.000156, train_loss_epoch=0.000176]\n",
      "Epoch 234:  84%|████████▍ | 203/241 [00:04<00:00, 44.81it/s, loss=0.000198, v_num=3845523, train_loss_step=0.00017, train_loss_epoch=0.000182] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 234:  93%|█████████▎| 225/241 [00:06<00:00, 36.01it/s, loss=0.000198, v_num=3845523, train_loss_step=0.00017, train_loss_epoch=0.000182]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator='gpu', devices=1)\n",
    "trainer.fit(model=mlp, train_dataloader=train_batches, val_dataloaders=val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "12abe946-bfdf-4e70-a916-8f7285803d14",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "                                                          \u001b[A\n",
      "Validating:   0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:01<00:59,  1.62s/it]\u001b[A\n",
      "Validating: 100%|██████████| 38/38 [00:01<00:00, 28.19it/s]\u001b[A--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'val_loss': 0.00020720479369629174}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "                                                           \u001b[A"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.00020720479369629174}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(mlp, val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a414773-da77-4ab5-8c25-8dec4ca13c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 13/13 [00:01<00:00, 11.12it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 13/13 [00:01<00:00,  8.28it/s]\n",
      "Epoch 234: 100%|██████████| 241/241 [00:20<00:00, 11.59it/s, loss=0.000198, v_num=3845523, train_loss_step=0.00017, train_loss_epoch=0.000182]"
     ]
    }
   ],
   "source": [
    "trainer.test(mlp, test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "44ba5e4b-6477-4a31-9602-2318be2cc285",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = 0\n",
    "for X, y in iter(test_batches):\n",
    "    pred = mlp(X)\n",
    "    with torch.no_grad():\n",
    "        mse += F.mse_loss(y, pred)\n",
    "mse /= len(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "59719992-e83c-4173-ac00-493571924059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.056e-04 / RMSE: 0.014340\n"
     ]
    }
   ],
   "source": [
    "print(f\"MSE: {mse:.3e} / RMSE: {np.sqrt(mse):.<3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78643e26-05f1-4c15-b519-79db2e795a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
