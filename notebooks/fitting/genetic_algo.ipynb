{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b059c733-c51a-4e6b-99fd-33bbb32c3be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import glob\n",
    "import random\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc63d47-0a11-4de5-8390-748007e9e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, \"../../python\")\n",
    "sys.path.insert(1, \"../../..\")\n",
    "import util\n",
    "import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6016cff8-0a88-4e57-a42e-531581a1de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"custom\")  # custom style sheet\n",
    "plt.style.use(\"muted\")  # muted color theme from SciencePlots\n",
    "cm_seq = sns.cubehelix_palette(\n",
    "    start=0, rot=-0.70, gamma=0.40, light=0.9, dark=0.1, as_cmap=True, reverse=True\n",
    ")\n",
    "cm_seq2 = sns.cubehelix_palette(\n",
    "    start=0, rot=-0.70, gamma=0.40, light=0.8, dark=0.1, as_cmap=True, reverse=False\n",
    ")\n",
    "colors = mpl.colors.to_rgba_array(\n",
    "    [\n",
    "        \"#364B9A\",\n",
    "        \"#4A7BB7\",\n",
    "        \"#6EA6CD\",\n",
    "        \"#98CAE1\",\n",
    "        \"#C2E4EF\",\n",
    "        \"#EAECCC\",\n",
    "        \"#FEDA8B\",\n",
    "        \"#FDB366\",\n",
    "        \"#F67E4B\",\n",
    "        \"#DD3D2D\",\n",
    "        \"#A50026\",\n",
    "    ]\n",
    ")\n",
    "cm_div = mpl.colors.LinearSegmentedColormap.from_list(\"\", colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c356caa0-e665-46b6-8848-c42c554880f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0009215f-61d8-4a99-b3be-021bcffc3041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c11dc6ca-074f-490f-ab24-3ed17e1ecb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_constructor(*model_args, **model_kwargs):\n",
    "    return ga.MultiLayerNet(*model_args, **model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9242d667-6c1b-48f4-b076-d83a90d9c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.optim.Adam\n",
    "optimizer = a(mlp.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c2fb5e12-8c6b-4893-9e47-91c66da25456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.optim.adam.Adam"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8646aeda-5ba9-48d2-92a0-55cbed3a7dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "94fead44-8882-4f8b-8d0e-3af05f0604eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15347083-bf5c-4916-8ce4-8fab9b2925a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = ga.MultiLayerNet(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4eed0eb9-c22c-4586-8f0b-4de30b3aca2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.optim.optimizer.Optimizer"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.optim.Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60d12891-9d81-4bfb-a9e3-55db4d4a2f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp = ga.MultiLayerNet()\n",
    "input_dim = 3\n",
    "model_args = [input_dim]\n",
    "fitness_fn = torch.nn.MSELoss()\n",
    "feature_list = np.arange(62)\n",
    "g = ga.GeneticAlgorithm(mlp_constructor, model_args, {}, , fitness_fn, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29eeaa7d-2f31-4fb1-b935-6d015da321f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2748dbd3-cef2-4b29-a4cf-0892fe37262a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.fitness_fn(torch.Tensor([1, 2]), torch.Tensor([3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32582c15-7f02-49e8-8d63-b1becf04ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.fitnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec9b8e44-1417-4cbc-86bc-6b4ac0e8dbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MultiLayerNet(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=30, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=30, out_features=1, bias=True)\n",
      "    (13): Sigmoid()\n",
      "  )\n",
      ")\n",
      "        Model Args: [3]\n",
      "        Model Kwargs: {}\n",
      "        Feature set: [31 16 58]\n",
      "        Training function: None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__repr__ returned non-string (type NoneType)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/project/dinner/scguo/anaconda3/envs/py39/lib/python3.9/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dinner/scguo/anaconda3/envs/py39/lib/python3.9/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0;31m# printer registered in self.type_pprinters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;31m# deferred printer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dinner/scguo/anaconda3/envs/py39/lib/python3.9/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    553\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreakable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;31m# Special case for 1-item tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dinner/scguo/anaconda3/envs/py39/lib/python3.9/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    392\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                                 \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                             \u001b[0;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dinner/scguo/anaconda3/envs/py39/lib/python3.9/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __repr__ returned non-string (type NoneType)"
     ]
    }
   ],
   "source": [
    "g.individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ba8e5953-31e0-4bba-bad3-93da0878ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_fn(model, dataloader, loss_fn, optimizer, indices=None, **kwargs):\n",
    "    size = len(dataloader.dataset)\n",
    "    # if indices is None:\n",
    "    #     indices = np.arange(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X[..., indices])\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7f5ffeb0-7cf0-4449-8fe1-ce501c27e0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.020032  [    0/4150115]\n",
      "loss: 0.019274  [1638400/4150115]\n",
      "loss: 0.017420  [3276800/4150115]\n"
     ]
    }
   ],
   "source": [
    "training_fn(mlp, batches, fitness_fn, optimizer, indices=[1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9b725948-3d39-489c-9e2a-d15431e09eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mlp(X[0, [1,2,3]])\n",
    "loss = fitness_fn(pred, y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d3e97e69-4f95-4236-9a7d-63c72e00549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8dc3b5c7-d69b-4ed4-9ba2-ec46abf19611",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0f93b811-0123-4c3d-927b-9c80b8f32dda",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('net.0.weight',\n",
       "              tensor([[ 0.3266,  0.1367, -0.0217],\n",
       "                      [-0.4050, -0.3973, -0.3435],\n",
       "                      [-0.5753,  0.3009,  0.3371],\n",
       "                      [-0.0408,  0.4110,  0.6375],\n",
       "                      [ 0.3711,  0.4602,  0.2713],\n",
       "                      [-0.0249,  0.4882,  0.1810],\n",
       "                      [-0.2101,  0.3422, -0.2819],\n",
       "                      [-0.0307,  0.6222, -0.1243],\n",
       "                      [ 0.0590,  0.2028,  0.0099],\n",
       "                      [-0.6049,  0.2348,  0.5337],\n",
       "                      [-0.4241, -0.3018,  0.4183],\n",
       "                      [-0.4677,  0.0084,  0.5790],\n",
       "                      [-0.5060,  0.2210, -0.3350],\n",
       "                      [-0.0408, -0.1774,  0.2993],\n",
       "                      [ 0.2959, -0.4763,  0.0695],\n",
       "                      [ 0.2401, -0.2408, -0.5435],\n",
       "                      [-0.4813,  0.3001,  0.3782],\n",
       "                      [-0.0155,  0.5526,  0.4008],\n",
       "                      [ 0.2101,  0.3215,  0.1659],\n",
       "                      [ 0.2570,  0.5030,  0.0666],\n",
       "                      [-0.3269,  0.2553,  0.4251],\n",
       "                      [-0.2601,  0.5904,  0.2390],\n",
       "                      [-0.3880,  0.4653,  0.2449],\n",
       "                      [ 0.2148, -0.0520, -0.0834],\n",
       "                      [ 0.0526,  0.4075,  0.2769],\n",
       "                      [-0.0332,  0.2293,  0.6312],\n",
       "                      [-0.2685, -0.2111, -0.6244],\n",
       "                      [ 0.5894, -0.1723,  0.0157],\n",
       "                      [-0.5786,  0.6140, -0.4264],\n",
       "                      [ 0.4844,  0.2812,  0.6063]])),\n",
       "             ('net.0.bias',\n",
       "              tensor([-0.1507,  0.2306, -0.0476, -0.3613,  0.5801,  0.0589,  0.5879, -0.6694,\n",
       "                      -0.1053, -0.5019,  0.8280,  0.4440, -0.0285,  0.3745,  0.0152, -0.4053,\n",
       "                      -0.0859, -0.0348,  0.3630, -0.1127, -0.4464,  0.4490, -0.1851, -0.1644,\n",
       "                       0.2209,  0.0454,  0.5343,  0.0458,  0.4646,  0.4636])),\n",
       "             ('net.2.weight',\n",
       "              tensor([[-5.0988e-02, -1.5079e-01,  1.3666e-01,  2.9766e-01,  1.6152e-01,\n",
       "                        2.2253e-01, -1.2899e-02,  3.6484e-01,  2.0044e-01,  3.0854e-03,\n",
       "                       -1.0887e-01, -1.1288e-01, -1.3552e-01, -4.9527e-02, -4.3026e-03,\n",
       "                       -2.2367e-03,  1.2950e-01,  2.3633e-01,  1.5527e-02, -3.3630e-03,\n",
       "                       -6.5694e-02, -3.3386e-02,  7.1944e-02,  8.7862e-02,  5.9367e-02,\n",
       "                        6.3032e-02, -2.4950e-01, -8.1973e-02,  1.1576e-01,  7.1745e-02],\n",
       "                      [-1.6090e-01, -5.5741e-02,  1.6857e-01,  2.2821e-02,  2.4050e-02,\n",
       "                       -5.3440e-02,  1.8405e-02,  1.2272e-01, -4.0961e-02, -1.5114e-01,\n",
       "                        1.0326e-01, -1.7242e-01, -1.4221e-01, -1.5443e-01, -7.4103e-03,\n",
       "                       -1.4397e-01, -4.0200e-02, -1.6712e-01, -1.1532e-01, -3.4366e-02,\n",
       "                       -1.0127e-01, -8.2966e-02, -1.2030e-01,  5.8870e-02,  7.1562e-02,\n",
       "                        7.9020e-02,  1.7047e-01,  8.4510e-02, -1.8329e-01, -7.7672e-03],\n",
       "                      [ 6.5742e-02,  2.2129e-02,  8.6045e-02,  1.2741e-01, -2.8874e-02,\n",
       "                       -1.4017e-01,  1.8950e-01,  1.1976e-01,  8.0270e-02,  1.5712e-01,\n",
       "                       -3.9237e-02,  6.7939e-02,  1.9323e-01, -7.1251e-02,  1.2314e-02,\n",
       "                       -1.4737e-01,  1.0556e-01, -1.3403e-01,  1.3760e-01, -1.0337e-01,\n",
       "                        6.2185e-02,  8.8449e-02,  1.8467e-02,  7.9792e-02,  6.5335e-02,\n",
       "                       -9.9988e-03, -1.4209e-01,  1.1769e-01,  4.4080e-02, -1.6093e-01],\n",
       "                      [-1.1715e-01,  3.7293e-02, -1.0440e-01,  2.9344e-01,  1.0203e-01,\n",
       "                        4.4159e-01,  8.0387e-02,  5.0646e-01,  9.5112e-02,  1.4397e-01,\n",
       "                       -2.6525e-01, -2.0137e-01, -3.4437e-02, -2.5354e-01, -5.5505e-02,\n",
       "                       -1.6915e-01, -2.7125e-02, -5.0699e-02,  6.4433e-02,  1.1640e-01,\n",
       "                       -3.3622e-02,  2.8530e-02, -3.8592e-02,  1.4007e-01, -5.4655e-02,\n",
       "                        2.0417e-01, -7.7762e-02,  1.7675e-01,  3.4938e-02, -3.1828e-03],\n",
       "                      [ 8.6913e-02, -9.9746e-02, -3.1127e-02, -1.8103e-01, -1.4497e-01,\n",
       "                       -4.3856e-02,  6.7695e-02,  9.5796e-02, -6.9849e-02, -1.1034e-01,\n",
       "                       -2.4586e-02,  7.9212e-02,  4.6163e-02, -1.2662e-01,  1.1301e-01,\n",
       "                       -3.1120e-02,  4.6600e-02,  1.3232e-01,  1.0292e-01, -7.1762e-02,\n",
       "                       -9.5729e-03, -2.2375e-02, -1.5526e-01, -1.2721e-02, -1.5002e-01,\n",
       "                        1.3789e-01,  3.7795e-03, -9.6212e-03,  1.1067e-01, -1.2285e-01],\n",
       "                      [-5.4497e-02, -1.2291e-01,  1.1121e-01,  1.7998e-01,  5.2606e-02,\n",
       "                        1.1375e-01, -1.6387e-01,  2.0623e-01,  6.4301e-02,  8.6423e-02,\n",
       "                       -1.3543e-01, -3.3447e-02, -2.4106e-03, -1.7727e-01, -1.4033e-01,\n",
       "                        1.4412e-01,  1.8529e-02,  6.7110e-02,  1.8866e-01,  3.8843e-02,\n",
       "                        1.5983e-01, -1.9449e-02, -5.3427e-02,  1.4361e-01,  6.2085e-02,\n",
       "                       -4.3559e-02,  1.0941e-01, -2.7173e-02,  1.2861e-01,  4.6709e-02],\n",
       "                      [-1.9520e-01, -8.2608e-02, -7.0249e-02, -1.0269e-01, -8.8364e-02,\n",
       "                        4.8849e-02,  1.5804e-01, -1.6355e-01, -6.1612e-01,  1.4898e-01,\n",
       "                        1.6689e-01, -8.5217e-03,  1.4962e-02, -3.8432e-02, -5.1963e-02,\n",
       "                       -3.4096e-01,  5.6826e-02,  1.4003e-01,  1.9255e-01, -6.4142e-02,\n",
       "                        1.6626e-01,  1.9253e-01,  1.4663e-01,  6.1037e-02, -1.2607e-01,\n",
       "                        9.1673e-02,  1.6638e-01,  2.0671e-01,  1.5770e-01,  4.6075e-02],\n",
       "                      [ 4.4952e-02, -1.4931e-02,  1.7702e-01,  2.3175e-02,  1.1019e-02,\n",
       "                        1.6325e-01,  7.5550e-02, -1.3099e-01, -1.5243e-01,  1.2970e-01,\n",
       "                       -6.4451e-03, -3.6483e-02,  1.5908e-01,  5.7355e-02,  9.0339e-02,\n",
       "                       -1.7847e-01, -6.7441e-02, -1.1759e-01, -1.6833e-02, -5.1349e-02,\n",
       "                        7.0999e-02,  8.9242e-02, -5.0567e-02,  2.9086e-02,  5.0613e-02,\n",
       "                       -3.8013e-02,  6.7315e-03,  1.3552e-02,  7.2621e-02, -5.9774e-02],\n",
       "                      [ 4.2452e-02, -2.3534e-02,  1.5164e-01, -6.4121e-02,  9.8455e-02,\n",
       "                        1.7266e-01, -3.2829e-02,  1.2718e-01,  3.9887e-01,  1.5345e-01,\n",
       "                        6.2541e-03, -3.5785e-02, -3.1365e-02, -1.4010e-01, -1.6309e-01,\n",
       "                       -1.8223e-01,  1.9594e-01,  1.8101e-01,  1.2768e-01,  9.2465e-02,\n",
       "                        8.9670e-02, -9.4525e-02,  1.1035e-01,  5.8050e-02, -1.3294e-01,\n",
       "                       -1.1779e-01,  1.4896e-01, -9.6587e-02, -8.2841e-02,  4.6054e-02],\n",
       "                      [-1.6586e-01,  3.9055e-02,  1.5905e-01, -1.2295e-01,  7.4868e-02,\n",
       "                        1.4704e-01, -7.6976e-02, -1.3947e-01, -5.5082e-01, -1.4131e-01,\n",
       "                        1.8738e-01,  1.2656e-01, -1.2252e-01,  1.9161e-01, -7.3073e-02,\n",
       "                       -2.2285e-01,  3.6915e-02, -6.8389e-02,  1.7012e-01, -4.1634e-01,\n",
       "                        1.3646e-02,  1.1526e-01,  8.1490e-02, -2.0856e-01,  1.4747e-01,\n",
       "                       -2.9517e-02,  2.3314e-02, -6.7295e-02,  8.8951e-02,  3.7316e-01],\n",
       "                      [ 2.1397e-02,  1.4078e-01, -5.8146e-02, -1.6685e-01, -4.2454e-02,\n",
       "                        9.0187e-02, -1.6271e-02, -4.3533e-02, -5.3366e-02, -3.3071e-02,\n",
       "                        5.2139e-02, -7.4190e-02,  8.6207e-02,  3.7389e-02, -1.3717e-01,\n",
       "                       -4.8658e-02,  2.5145e-02, -1.5789e-01, -1.3103e-01, -5.3881e-02,\n",
       "                       -1.4965e-01,  1.4445e-01, -1.1893e-01, -8.2688e-02, -4.1868e-02,\n",
       "                       -2.4884e-02, -1.3052e-02, -1.4361e-01, -9.6321e-02, -1.4478e-01],\n",
       "                      [ 6.8701e-02, -4.3563e-02,  8.7226e-02, -3.1056e-02,  1.4088e-01,\n",
       "                        1.5046e-02, -1.5706e-01,  1.3944e-01, -8.9991e-02,  1.3517e-01,\n",
       "                        1.2155e-01, -5.8004e-02,  7.4094e-03,  9.6984e-02,  1.4018e-01,\n",
       "                       -3.0629e-02,  1.8612e-01,  3.7156e-02,  5.4139e-02, -1.4874e-01,\n",
       "                        1.0565e-01,  5.9724e-02,  1.8486e-01,  3.0254e-02, -1.1359e-01,\n",
       "                        1.0092e-02, -2.4133e-02,  1.1722e-02,  1.3745e-01,  1.0967e-01],\n",
       "                      [-3.8705e-02, -1.4924e-01,  5.5187e-02, -1.5394e-01,  1.6932e-01,\n",
       "                       -3.4736e-03, -1.4609e-01, -2.9806e-02, -1.8135e-01,  7.6283e-02,\n",
       "                        3.8597e-02,  5.3130e-03, -3.6293e-02, -6.9666e-02, -1.0675e-01,\n",
       "                        4.5996e-02,  8.1268e-02, -4.1803e-02, -1.5599e-01, -1.7834e-01,\n",
       "                        1.4043e-01,  2.9354e-02, -9.8148e-02, -8.6394e-02, -3.7623e-02,\n",
       "                       -7.5693e-02, -1.0177e-01, -1.5363e-01, -9.2792e-02, -1.0669e-02],\n",
       "                      [ 1.9159e-01, -7.5426e-02, -7.4065e-03, -1.4566e-02,  1.9397e-01,\n",
       "                       -2.0760e-03,  2.0096e-02,  6.2960e-02,  3.1800e-02,  1.4498e-01,\n",
       "                       -2.5918e-02,  8.2685e-02, -7.9629e-02, -6.3887e-03,  1.8311e-02,\n",
       "                        8.6209e-02,  1.9452e-02,  2.6649e-01,  8.3287e-02, -7.5056e-02,\n",
       "                       -3.9080e-02,  1.0358e-01,  9.7669e-02, -1.0964e-01,  2.1451e-02,\n",
       "                        1.0639e-01, -9.3652e-02,  1.5627e-01, -1.2057e-01,  1.6683e-01],\n",
       "                      [-3.7346e-01,  1.7312e-01,  4.4811e-02, -1.5559e-02,  2.8541e-01,\n",
       "                        1.0876e-01,  2.1706e-01, -4.2578e-01, -3.6648e-01, -1.7899e-01,\n",
       "                        1.3716e-01,  3.0467e-03, -2.4862e-02,  5.7217e-02,  4.4850e-02,\n",
       "                       -1.9286e-01,  1.3401e-01, -1.1989e-01,  1.5184e-01, -3.2738e-01,\n",
       "                       -1.7217e-01, -1.0787e-01, -1.6092e-01, -1.5686e-01,  3.2654e-02,\n",
       "                        2.4074e-03,  7.4363e-02, -2.3243e-01,  1.6721e-01,  3.2014e-01],\n",
       "                      [-9.8782e-02, -1.2145e-01,  1.0130e-01,  1.5235e-01,  5.0086e-02,\n",
       "                       -2.6193e-02,  4.0080e-02, -3.2904e-02,  1.7187e-01,  1.1189e-01,\n",
       "                        4.6461e-02,  1.9250e-01,  1.2941e-01, -1.4337e-01,  1.2059e-01,\n",
       "                       -1.9191e-01, -1.0121e-01,  8.8214e-03,  4.9690e-02, -9.4266e-02,\n",
       "                       -1.1142e-01, -6.8337e-02, -4.6098e-02, -1.5420e-01, -2.0793e-01,\n",
       "                        1.4975e-01, -5.2507e-02, -5.9832e-03,  1.3729e-02,  1.3414e-01],\n",
       "                      [ 1.7984e-01,  6.1626e-02,  1.7715e-01,  8.4248e-02,  7.7336e-02,\n",
       "                        8.6288e-02, -2.9988e-02,  2.5584e-01,  2.4983e-02, -5.1341e-02,\n",
       "                       -4.3171e-02,  1.5969e-01,  3.7352e-02,  3.9760e-02, -1.5265e-01,\n",
       "                       -1.7223e-01, -2.7510e-02,  1.4325e-01, -6.3781e-02, -1.3226e-02,\n",
       "                        9.8365e-02, -1.1912e-01,  1.8235e-01,  6.3622e-02,  1.9738e-02,\n",
       "                        1.3286e-01, -1.0093e-01, -1.8489e-01,  1.6156e-01,  1.8654e-01],\n",
       "                      [-1.5936e-01, -1.2666e-01, -1.7325e-02,  4.2632e-02,  8.7670e-02,\n",
       "                        1.3539e-02, -1.7897e-01,  2.2764e-02,  9.2240e-02,  4.2338e-02,\n",
       "                       -1.3267e-01,  9.8551e-02, -1.5985e-01,  1.1795e-01,  1.0556e-01,\n",
       "                       -1.4741e-01, -1.5615e-01, -1.2827e-01,  1.2387e-01,  1.3694e-01,\n",
       "                        9.7739e-02, -4.7558e-02, -1.9853e-02, -1.3531e-01, -1.7231e-01,\n",
       "                       -1.2552e-01, -1.2958e-01, -1.3486e-01,  3.3069e-02, -7.4132e-02],\n",
       "                      [-4.2434e-02, -4.3562e-02, -9.7295e-02,  3.4266e-01,  1.2841e-01,\n",
       "                        3.0375e-01, -3.7905e-02,  6.6559e-01,  1.4774e-01, -9.3612e-02,\n",
       "                       -2.2144e-01,  4.3647e-03,  5.6804e-02, -3.1966e-01,  2.7848e-02,\n",
       "                       -1.3898e-01, -5.6618e-02,  3.9132e-02,  1.7995e-01,  2.6841e-02,\n",
       "                        1.1569e-01, -9.6316e-02,  1.7942e-01,  5.4323e-02, -6.2601e-02,\n",
       "                        1.2560e-02, -6.6617e-02,  2.2787e-01,  1.0924e-01,  1.2102e-01],\n",
       "                      [-1.9952e-01,  1.8669e-01, -1.6310e-01,  1.4533e-01, -6.7468e-02,\n",
       "                       -8.5153e-02,  1.4684e-01,  2.0410e-01, -6.3205e-02,  7.9953e-02,\n",
       "                        5.0678e-02, -4.8552e-02, -6.5590e-02,  1.1476e-02,  1.9418e-03,\n",
       "                       -2.6566e-02,  1.7733e-01,  9.7051e-02, -9.5296e-02,  4.2700e-02,\n",
       "                       -1.3406e-01,  1.0215e-01, -9.9937e-02,  8.4893e-02,  2.8918e-02,\n",
       "                        1.3130e-01, -4.8736e-02,  9.0574e-02,  1.0863e-01, -2.3983e-02],\n",
       "                      [-1.9835e-01,  6.2546e-02,  6.0979e-02, -8.9870e-02,  2.8194e-01,\n",
       "                        9.5938e-04, -1.2113e-01, -1.9141e-01, -5.9815e-02,  1.4111e-01,\n",
       "                        1.0628e-01, -2.2797e-02, -1.9870e-01, -2.2120e-02,  1.9143e-02,\n",
       "                       -9.2141e-02,  1.2610e-01,  4.9019e-02,  1.8217e-01, -3.2078e-01,\n",
       "                       -1.0741e-01, -5.6425e-02,  1.3876e-02, -1.3137e-01,  8.6188e-02,\n",
       "                       -1.1747e-01,  1.2631e-01, -1.1505e-01,  1.8639e-02,  9.0442e-02],\n",
       "                      [-2.9337e-02, -1.4376e-01,  2.0527e-01, -4.2067e-02, -1.4418e-01,\n",
       "                        5.7067e-04,  1.2510e-01,  1.9159e-01,  3.2395e-01,  1.8493e-01,\n",
       "                        2.3900e-02,  1.4344e-01,  1.7014e-02,  4.2492e-02, -6.9101e-02,\n",
       "                       -4.6196e-02, -1.0620e-01, -2.4533e-02, -3.0564e-01,  1.6452e-01,\n",
       "                        2.0222e-01, -1.1374e-01,  2.7704e-02,  2.6021e-02, -2.9703e-03,\n",
       "                        8.9484e-02, -2.9015e-02, -1.7365e-01, -1.3529e-01, -8.7782e-02],\n",
       "                      [ 9.9057e-02, -1.4205e-01,  1.4191e-01,  3.2439e-01,  1.5636e-02,\n",
       "                        8.2049e-02, -2.0403e-01,  2.4021e-01,  1.5930e-01, -4.1806e-03,\n",
       "                       -7.3678e-02, -8.2481e-02,  1.7911e-01, -2.5876e-02, -9.8330e-02,\n",
       "                        5.3102e-02,  9.8693e-02,  3.1053e-02,  7.6925e-02,  1.1174e-01,\n",
       "                        2.1092e-01, -9.0194e-02,  5.0550e-02, -1.3100e-01, -9.4621e-02,\n",
       "                        2.1266e-01, -1.7902e-01,  5.1081e-03,  1.4862e-01,  8.0493e-02],\n",
       "                      [-7.2114e-02, -1.3950e-01,  1.1114e-01, -1.0351e-01, -8.4909e-02,\n",
       "                        7.0956e-02,  6.4904e-02,  1.8530e-01,  1.8267e-01,  1.9191e-01,\n",
       "                        5.9105e-03, -7.7774e-02,  1.9850e-01,  3.9272e-02,  2.2882e-02,\n",
       "                        4.4677e-02,  1.9244e-01,  4.2159e-02, -9.1200e-02,  2.8261e-02,\n",
       "                        1.4497e-01,  1.9525e-01, -8.2054e-02, -6.9477e-02, -1.6981e-01,\n",
       "                       -6.5919e-02,  2.0106e-01,  4.5732e-02,  1.8732e-01,  7.8806e-02],\n",
       "                      [ 3.7223e-01, -8.3995e-02,  1.3939e-01,  2.8443e-02,  2.2662e-01,\n",
       "                        1.0974e-02,  1.0030e-01, -3.2196e-01, -2.4139e-03, -3.8021e-02,\n",
       "                       -7.4994e-02,  4.0712e-02,  7.7714e-02,  1.6619e-01,  4.0766e-01,\n",
       "                        3.5757e-01,  1.4720e-01, -7.4193e-03,  2.8467e-01,  7.9978e-02,\n",
       "                       -1.1658e-01,  1.7881e-01,  1.0515e-01,  3.3503e-01, -1.9205e-01,\n",
       "                        6.2491e-02,  5.9777e-02,  2.7941e-01,  3.8733e-02,  1.6645e-01],\n",
       "                      [ 1.4433e-01, -1.8407e-02, -1.9012e-01, -4.5793e-02,  9.0177e-02,\n",
       "                        1.5762e-01,  9.9651e-03, -1.4401e-01, -1.5629e-01,  8.1324e-02,\n",
       "                       -1.3457e-01,  1.4471e-01, -7.0885e-03,  4.4786e-02, -1.7510e-02,\n",
       "                       -1.9034e-01,  5.4892e-03,  1.5466e-01, -4.3579e-02, -2.0728e-01,\n",
       "                        4.5226e-02, -1.5480e-01,  1.2082e-02, -1.1391e-01,  8.4582e-02,\n",
       "                       -2.9121e-02,  1.2323e-01, -9.0298e-02,  4.5395e-02,  3.3054e-02],\n",
       "                      [-5.7228e-02, -5.8215e-02, -3.7582e-02, -1.8119e-01, -1.6831e-01,\n",
       "                        1.7064e-01,  3.0067e-02,  1.4106e-01, -1.2296e-01, -1.2709e-01,\n",
       "                       -1.6538e-01,  5.2213e-02, -1.5404e-02, -1.7947e-01, -7.9137e-02,\n",
       "                       -1.3860e-01, -1.3919e-01, -1.8024e-01, -1.1444e-01,  1.3084e-01,\n",
       "                       -5.6537e-02,  3.7930e-02, -1.0164e-01,  5.8159e-02, -3.7656e-02,\n",
       "                       -1.6715e-01,  1.2582e-01, -3.7504e-02, -8.8188e-02, -6.2881e-02],\n",
       "                      [-3.0732e-02,  2.2173e-02,  1.4955e-01,  1.6302e-01, -9.0744e-02,\n",
       "                        3.4917e-02, -8.1618e-02,  7.7454e-02, -6.4679e-02,  9.3100e-02,\n",
       "                       -1.5428e-01, -8.9680e-02, -5.2927e-02, -1.0363e-01, -1.2080e-01,\n",
       "                       -4.1299e-02,  6.0776e-02,  1.2388e-01,  2.1137e-02, -6.2860e-02,\n",
       "                       -8.1607e-02, -5.9572e-02, -8.8374e-02, -8.4613e-02, -7.8412e-02,\n",
       "                        4.7916e-02,  4.0352e-02,  1.3903e-01, -3.3486e-02, -1.5377e-01],\n",
       "                      [ 1.6271e-01,  9.3628e-02, -7.1370e-03,  2.6198e-01,  1.8683e-01,\n",
       "                        1.8468e-01, -4.2887e-02,  2.5743e-01,  1.3247e-01,  1.7458e-01,\n",
       "                       -3.9101e-02, -1.8304e-02, -1.1118e-01,  1.1693e-01, -1.7653e-01,\n",
       "                       -7.7853e-02,  6.0661e-02, -3.4747e-03,  1.6221e-01,  1.9833e-01,\n",
       "                       -1.0913e-01,  1.7665e-01, -4.5377e-02, -1.0957e-01, -1.3332e-01,\n",
       "                        1.6332e-01, -1.2014e-01,  1.1695e-01,  4.8393e-02,  1.6870e-01],\n",
       "                      [ 1.6359e-01,  1.4672e-01, -1.2482e-02,  1.5833e-01,  4.4416e-02,\n",
       "                        9.5697e-02, -2.1075e-02,  1.2678e-01, -9.2331e-02, -8.9741e-03,\n",
       "                        1.2425e-01,  1.4166e-01,  9.7364e-02,  1.6474e-01, -1.9099e-01,\n",
       "                       -2.8136e-02,  2.5255e-03,  2.1160e-02,  1.3088e-02,  3.0100e-02,\n",
       "                        1.3014e-01,  1.4793e-01, -3.4037e-03,  1.5827e-01,  2.7560e-02,\n",
       "                        1.7033e-01,  7.2183e-02, -1.6371e-01,  7.5851e-02,  1.4490e-01]])),\n",
       "             ('net.2.bias',\n",
       "              tensor([-0.2878, -0.0501,  0.2138,  0.1151, -0.0324,  0.0296,  0.2801,  0.3943,\n",
       "                      -0.0034,  0.1839, -0.0138,  0.1040, -0.0336,  0.0798,  0.3752,  0.1362,\n",
       "                       0.0257,  0.1344,  0.1996, -0.0869,  0.1369, -0.2334, -0.2804,  0.1371,\n",
       "                       0.0521,  0.1837, -0.0502,  0.0393, -0.0341,  0.1982])),\n",
       "             ('net.4.weight',\n",
       "              tensor([[-0.1512, -0.1584, -0.1756, -0.1632,  0.1439, -0.0143, -0.0585, -0.1230,\n",
       "                        0.1639,  0.0201, -0.0152, -0.0519,  0.0563, -0.0392, -0.1423, -0.0296,\n",
       "                       -0.1812,  0.0970, -0.0353,  0.1186, -0.1717, -0.0976,  0.1628, -0.0082,\n",
       "                        0.0414,  0.0592, -0.1501, -0.1789,  0.0033, -0.1320],\n",
       "                      [-0.1954, -0.1751,  0.0701, -0.1733, -0.0018, -0.1489, -0.0445,  0.0412,\n",
       "                       -0.0181, -0.1360,  0.0317,  0.1308,  0.1410, -0.1589,  0.2509,  0.1257,\n",
       "                        0.1723, -0.0507,  0.2003, -0.0039, -0.0541,  0.1355, -0.1436,  0.1995,\n",
       "                        0.1683, -0.1065,  0.0770,  0.0752, -0.0309,  0.0063],\n",
       "                      [-0.1098,  0.0826,  0.1255, -0.1608,  0.1916,  0.0927,  0.2065,  0.1320,\n",
       "                        0.0961,  0.2004, -0.0924,  0.1511,  0.0358, -0.0706,  0.0092, -0.0948,\n",
       "                        0.0654, -0.1519,  0.1382,  0.1678, -0.0339,  0.1741, -0.2696,  0.0751,\n",
       "                        0.1437,  0.1517,  0.1579, -0.0574,  0.0189,  0.1303],\n",
       "                      [-0.1260, -0.1565,  0.0055, -0.0834, -0.1241,  0.0683,  0.0359,  0.0555,\n",
       "                       -0.0943, -0.1150, -0.1431,  0.0338, -0.0392, -0.2564,  0.1714,  0.0470,\n",
       "                       -0.0004,  0.1354, -0.1013,  0.0693,  0.1265,  0.1179,  0.0684,  0.0065,\n",
       "                       -0.0150,  0.0133, -0.0867,  0.0498, -0.1579, -0.0248],\n",
       "                      [ 0.1509,  0.0970,  0.0106,  0.0974,  0.0912,  0.1113,  0.1593, -0.1708,\n",
       "                       -0.0064, -0.1968,  0.0011, -0.1152, -0.0039, -0.1261, -0.1883,  0.0524,\n",
       "                        0.2582,  0.1180,  0.1406,  0.1864, -0.1041,  0.2499, -0.0887, -0.1468,\n",
       "                       -0.0598, -0.2348,  0.0685, -0.0740,  0.1326,  0.0307],\n",
       "                      [-0.0806, -0.0397,  0.0354,  0.0450, -0.1676,  0.0626,  0.1451,  0.0564,\n",
       "                        0.0994,  0.0912,  0.1373,  0.1571,  0.0797, -0.0531, -0.0049,  0.0334,\n",
       "                        0.1866,  0.1331, -0.1494,  0.1915,  0.1376,  0.1542, -0.1337,  0.0522,\n",
       "                        0.0940, -0.1039,  0.0386, -0.0668, -0.0195,  0.1599],\n",
       "                      [-0.0733,  0.0200, -0.0730,  0.2421,  0.1337,  0.0154,  0.1501,  0.0296,\n",
       "                        0.0330,  0.1390, -0.0295, -0.0069,  0.0813,  0.1713, -0.3164,  0.1610,\n",
       "                       -0.1121,  0.0609,  0.2504, -0.1457,  0.1346,  0.2232,  0.1057,  0.0406,\n",
       "                       -0.1091, -0.0575,  0.0868, -0.0311,  0.1689, -0.0372],\n",
       "                      [-0.0941, -0.1457,  0.0788,  0.1330, -0.1187,  0.0438, -0.1585,  0.1275,\n",
       "                        0.0568,  0.1558,  0.1068, -0.0605,  0.0856, -0.1436, -0.1015,  0.0888,\n",
       "                       -0.0974, -0.0724, -0.0688, -0.1604, -0.0104, -0.0515, -0.0870,  0.1197,\n",
       "                        0.0693, -0.1320,  0.1023,  0.0260,  0.0060, -0.1713],\n",
       "                      [-0.1123,  0.1400, -0.1430,  0.0319, -0.0331,  0.0968,  0.0208,  0.1305,\n",
       "                        0.1647, -0.1519,  0.1527, -0.1765, -0.1251,  0.0467,  0.0426, -0.1752,\n",
       "                       -0.1605,  0.0764, -0.1586, -0.0192,  0.0241, -0.1608, -0.1780,  0.1049,\n",
       "                       -0.1332, -0.1291, -0.1469,  0.0427,  0.0233, -0.1215],\n",
       "                      [ 0.1767, -0.0884, -0.1098,  0.1353,  0.0645, -0.1681,  0.0492, -0.1259,\n",
       "                       -0.0380,  0.1506,  0.1633, -0.1492, -0.0731, -0.0539,  0.1025, -0.0234,\n",
       "                        0.1404, -0.0578, -0.1266, -0.0964, -0.1506,  0.0247,  0.1455,  0.0421,\n",
       "                        0.0619, -0.1298,  0.0157,  0.1804, -0.1705, -0.1761],\n",
       "                      [ 0.0791,  0.1120, -0.0171,  0.0723,  0.1746,  0.1796,  0.0839,  0.1208,\n",
       "                        0.1711, -0.0317,  0.1361, -0.1459,  0.0719, -0.1202,  0.0872, -0.0423,\n",
       "                       -0.1403, -0.0342, -0.0449, -0.1780,  0.0322,  0.1088, -0.1301, -0.1250,\n",
       "                       -0.1000,  0.0244, -0.1573,  0.1148,  0.0059,  0.0113],\n",
       "                      [-0.0783,  0.0873,  0.1748,  0.1247, -0.0636, -0.1504,  0.1974, -0.0093,\n",
       "                        0.1776, -0.0960,  0.0245,  0.0663,  0.1278, -0.0924,  0.0420,  0.1568,\n",
       "                       -0.0777,  0.1009, -0.1582,  0.0979,  0.0572,  0.0987,  0.1069,  0.1606,\n",
       "                        0.1564,  0.0680,  0.0240, -0.0509,  0.1493, -0.1333],\n",
       "                      [ 0.0888, -0.0811,  0.0644,  0.1882,  0.1162, -0.0272, -0.2032, -0.1815,\n",
       "                       -0.1143, -0.0548, -0.0380, -0.0178,  0.0014,  0.1566, -0.2306, -0.1234,\n",
       "                        0.1275,  0.1583,  0.2190,  0.1510,  0.0513,  0.1244,  0.2072,  0.1535,\n",
       "                       -0.1073, -0.0984, -0.0488, -0.0244, -0.0344,  0.0981],\n",
       "                      [ 0.0439,  0.0748,  0.0556, -0.1145, -0.0287,  0.1146, -0.1784,  0.0581,\n",
       "                        0.1025, -0.0071,  0.1328,  0.1489,  0.1030,  0.1312, -0.2005,  0.0877,\n",
       "                        0.0355, -0.1673,  0.0866,  0.0242,  0.0535, -0.1406,  0.0112,  0.1022,\n",
       "                       -0.0030, -0.0838, -0.1607, -0.1346,  0.1144,  0.0550],\n",
       "                      [ 0.0321, -0.0858,  0.0913, -0.0851,  0.0816, -0.1117, -0.0218,  0.0283,\n",
       "                       -0.0409, -0.1360, -0.1126,  0.0528, -0.0676,  0.1351,  0.0635, -0.1981,\n",
       "                       -0.1397,  0.0349,  0.1424, -0.1333,  0.1225, -0.0794,  0.0251, -0.0126,\n",
       "                        0.0092, -0.0533,  0.1151,  0.0960, -0.0572,  0.0679],\n",
       "                      [-0.1605, -0.0748, -0.0489,  0.0226, -0.0775, -0.0555, -0.0064,  0.1361,\n",
       "                       -0.1594, -0.1762,  0.1666, -0.0368, -0.1554, -0.1113, -0.1358,  0.0188,\n",
       "                       -0.0358,  0.1225, -0.1281,  0.0173, -0.1735,  0.0767,  0.0881, -0.1039,\n",
       "                        0.0486, -0.0361, -0.0420, -0.0678,  0.1388, -0.1686],\n",
       "                      [ 0.1817, -0.1172,  0.0805,  0.1325,  0.1136, -0.0415,  0.0981, -0.0227,\n",
       "                       -0.1622, -0.1323,  0.1083, -0.0741, -0.1056, -0.1502, -0.0455, -0.1437,\n",
       "                       -0.0946, -0.0176, -0.0663, -0.0734,  0.0748, -0.1579, -0.0234,  0.0686,\n",
       "                       -0.0896, -0.1764, -0.1373, -0.0655,  0.0177, -0.1392],\n",
       "                      [ 0.1306,  0.1152,  0.1217, -0.0477,  0.1531,  0.1120, -0.0889, -0.2040,\n",
       "                        0.2155, -0.1150,  0.1350,  0.0981, -0.1206,  0.0663, -0.2455,  0.0305,\n",
       "                        0.0892, -0.0745,  0.0855, -0.1301, -0.0624,  0.0387,  0.0777, -0.0134,\n",
       "                       -0.0256, -0.1065,  0.0025, -0.0622,  0.0166, -0.0757],\n",
       "                      [-0.0988, -0.0143, -0.0404,  0.0507, -0.1305, -0.1816,  0.1117, -0.0157,\n",
       "                        0.1275,  0.0003, -0.0384, -0.1044, -0.1188, -0.1552, -0.1703, -0.1784,\n",
       "                       -0.1343, -0.0779,  0.1488, -0.0343, -0.1255,  0.1267,  0.0596, -0.1529,\n",
       "                       -0.0589, -0.0482,  0.1528,  0.1456,  0.0219,  0.1709],\n",
       "                      [ 0.2637, -0.1420, -0.0378,  0.1551,  0.0183,  0.2221, -0.1179,  0.1633,\n",
       "                        0.1042, -0.1844,  0.1110,  0.0243, -0.0433, -0.0033, -0.3063, -0.1230,\n",
       "                        0.1411, -0.0120,  0.0223, -0.1628, -0.0476,  0.1491,  0.1919,  0.0954,\n",
       "                       -0.1662, -0.1720, -0.1300, -0.0772,  0.0721,  0.1470],\n",
       "                      [ 0.1036, -0.0201,  0.1745,  0.2190, -0.0076,  0.1196,  0.0105,  0.0877,\n",
       "                        0.0787,  0.1325,  0.1107,  0.0004, -0.0866,  0.0471, -0.1223,  0.0998,\n",
       "                        0.0426,  0.0144,  0.0995,  0.0035, -0.0784, -0.0763,  0.0263,  0.2015,\n",
       "                       -0.1860, -0.0322, -0.1813,  0.1575,  0.1641,  0.0653],\n",
       "                      [ 0.1430, -0.1186, -0.0930,  0.1332, -0.0366,  0.1786, -0.0159, -0.0874,\n",
       "                        0.0321, -0.0590, -0.1486,  0.1553,  0.0386,  0.1527,  0.0175, -0.0583,\n",
       "                        0.0821, -0.0060, -0.0251,  0.1472, -0.0630,  0.2229, -0.0790,  0.1208,\n",
       "                        0.0432,  0.1305,  0.0598,  0.1810, -0.0424, -0.1259],\n",
       "                      [-0.1455, -0.1025, -0.0525, -0.1313,  0.1777,  0.1500, -0.0357,  0.1607,\n",
       "                       -0.0067,  0.0473, -0.0247, -0.0922,  0.1798, -0.0907, -0.0006, -0.0952,\n",
       "                        0.0815, -0.1434,  0.0153,  0.0154, -0.1005, -0.1688,  0.0881, -0.1197,\n",
       "                        0.1220, -0.1642, -0.1776,  0.0810, -0.2059, -0.0471],\n",
       "                      [ 0.1916, -0.1406,  0.0598,  0.1173,  0.0121, -0.0737, -0.0795,  0.1926,\n",
       "                        0.0228,  0.1096, -0.1346,  0.1268, -0.0927, -0.1971, -0.1270,  0.1628,\n",
       "                        0.1500,  0.0763,  0.1078, -0.0503, -0.0157,  0.1401,  0.1366, -0.0276,\n",
       "                        0.0189,  0.1148, -0.0536, -0.1554, -0.0983, -0.0298],\n",
       "                      [-0.0398,  0.1605, -0.0034,  0.0268, -0.0476,  0.0752,  0.0368, -0.1079,\n",
       "                       -0.0884,  0.0271,  0.0411,  0.0031,  0.1818, -0.0536,  0.1000, -0.1780,\n",
       "                        0.1004,  0.0454, -0.0089,  0.0135,  0.0313, -0.1552,  0.0654,  0.0204,\n",
       "                       -0.1293, -0.1224,  0.0428, -0.0809,  0.0135, -0.1539],\n",
       "                      [-0.1460,  0.1667,  0.1902,  0.0734, -0.1352,  0.1257, -0.0414, -0.0274,\n",
       "                        0.1721, -0.0125, -0.1346, -0.0475, -0.0410, -0.0082,  0.2278, -0.0166,\n",
       "                        0.0099,  0.0435,  0.1322, -0.0721, -0.0476, -0.0386, -0.2325,  0.1312,\n",
       "                       -0.0376, -0.0607,  0.1814,  0.0392, -0.1328,  0.2082],\n",
       "                      [-0.0219, -0.0906,  0.0146, -0.1026,  0.0802,  0.0551,  0.0483, -0.0044,\n",
       "                       -0.0676, -0.0944, -0.0281,  0.0346, -0.0292, -0.0333,  0.0766, -0.0880,\n",
       "                       -0.1109,  0.0747,  0.0369, -0.0121, -0.0166, -0.1644, -0.1695,  0.0842,\n",
       "                       -0.0329, -0.0886,  0.0604, -0.1125, -0.1729, -0.1621],\n",
       "                      [ 0.2271,  0.0773,  0.1199, -0.0690, -0.0820,  0.0431, -0.0884, -0.1092,\n",
       "                        0.0834, -0.0963, -0.1029,  0.1758, -0.1754, -0.0520, -0.3016, -0.0384,\n",
       "                       -0.0010,  0.1776,  0.0848,  0.0496, -0.0690,  0.0502,  0.1076,  0.1001,\n",
       "                       -0.1332, -0.0120,  0.1411, -0.0986,  0.1642,  0.0421],\n",
       "                      [-0.0585, -0.0506,  0.0235, -0.0830,  0.1765, -0.1301, -0.0072,  0.1786,\n",
       "                       -0.1442,  0.0416, -0.0850,  0.1620,  0.0960, -0.0529,  0.2830, -0.1149,\n",
       "                       -0.0485, -0.1671, -0.0456, -0.1455,  0.2054, -0.0831,  0.0250,  0.0569,\n",
       "                       -0.0235, -0.0574,  0.1460, -0.1139, -0.1482,  0.0799],\n",
       "                      [-0.0459,  0.1689, -0.0235,  0.1006,  0.0893,  0.1073,  0.1743,  0.0605,\n",
       "                       -0.1021,  0.1991,  0.1525, -0.0160,  0.0572,  0.0504,  0.1876,  0.1822,\n",
       "                       -0.0347,  0.1317, -0.0947, -0.1343,  0.1318,  0.1938,  0.1801,  0.1797,\n",
       "                       -0.0841, -0.0134, -0.0074,  0.0016,  0.2078,  0.1271]])),\n",
       "             ('net.4.bias',\n",
       "              tensor([ 0.0542,  0.2542,  0.2065, -0.0937, -0.0037,  0.1095,  0.0620, -0.0198,\n",
       "                      -0.0313,  0.1000, -0.0937, -0.0011, -0.2055,  0.0145, -0.0798, -0.0639,\n",
       "                       0.1063,  0.0569, -0.0772,  0.1146, -0.1254, -0.1351,  0.1717, -0.0452,\n",
       "                       0.0147,  0.2401, -0.0125, -0.1389,  0.1277,  0.2331])),\n",
       "             ('net.6.weight',\n",
       "              tensor([[ 0.0521,  0.1714,  0.0772,  0.1267, -0.1782,  0.0055, -0.0474,  0.0874,\n",
       "                        0.0574, -0.0665,  0.0294,  0.0828, -0.0649,  0.0032, -0.0367, -0.0459,\n",
       "                        0.0967,  0.0089, -0.0448, -0.0255, -0.0989,  0.1414, -0.0807, -0.0696,\n",
       "                        0.1219,  0.2019, -0.0401, -0.1233,  0.1318,  0.1034],\n",
       "                      [-0.0458,  0.0165, -0.0015,  0.0955, -0.0501, -0.0906, -0.1806, -0.0491,\n",
       "                        0.1823, -0.0948, -0.0286, -0.1229, -0.0998,  0.0744, -0.0314,  0.1154,\n",
       "                        0.0068,  0.1344, -0.1451,  0.0649,  0.0814, -0.0203, -0.0646,  0.1355,\n",
       "                       -0.0569, -0.1241, -0.0728, -0.0206,  0.0120, -0.0717],\n",
       "                      [-0.0789, -0.1032, -0.0558, -0.1325,  0.3057, -0.0124,  0.0165, -0.0555,\n",
       "                       -0.0313, -0.1509, -0.0225, -0.0731,  0.2724, -0.0037,  0.0896,  0.1084,\n",
       "                        0.1720,  0.0649,  0.1781,  0.0734,  0.2395,  0.1931,  0.1036,  0.1753,\n",
       "                        0.1062, -0.1972,  0.1606,  0.1840, -0.2842, -0.0040],\n",
       "                      [ 0.0024,  0.0190,  0.1825, -0.1357, -0.1118, -0.0925,  0.0119, -0.1147,\n",
       "                       -0.1596,  0.1548,  0.1767,  0.0248, -0.2116,  0.0986, -0.0956,  0.0895,\n",
       "                       -0.1002, -0.1036, -0.1280,  0.0384, -0.0566, -0.0613, -0.1360,  0.0681,\n",
       "                        0.0468,  0.1665,  0.1269, -0.3460,  0.1059,  0.1219],\n",
       "                      [-0.1321, -0.0507, -0.1649,  0.0012,  0.1493, -0.1492, -0.0207,  0.0767,\n",
       "                       -0.0383, -0.0949,  0.1411,  0.0646,  0.0872, -0.0271, -0.0515,  0.0679,\n",
       "                       -0.0782,  0.1103, -0.1176,  0.1487,  0.0092,  0.1535,  0.0176,  0.1140,\n",
       "                        0.1287,  0.0742,  0.1654, -0.1063,  0.1232,  0.0788],\n",
       "                      [-0.1421,  0.1404, -0.0209,  0.1581,  0.0627,  0.0728, -0.1381, -0.0698,\n",
       "                        0.1148, -0.1205,  0.0685, -0.0373, -0.0435, -0.1192,  0.0562,  0.1041,\n",
       "                        0.0914, -0.0356,  0.1637, -0.1523, -0.0929,  0.1284,  0.1314, -0.1905,\n",
       "                        0.1181, -0.1209, -0.0123,  0.0508,  0.1044,  0.0669],\n",
       "                      [ 0.0609,  0.1201, -0.1621,  0.1817,  0.1763, -0.0752, -0.0546, -0.1699,\n",
       "                       -0.0270, -0.1772,  0.1364, -0.1185,  0.1304, -0.1115, -0.0770,  0.1280,\n",
       "                        0.1703, -0.1430, -0.1270,  0.0723, -0.0883, -0.0930,  0.0025, -0.0523,\n",
       "                       -0.0485,  0.1072,  0.0378, -0.1772,  0.0251, -0.1314],\n",
       "                      [-0.0090, -0.0636, -0.0560, -0.1705, -0.0736, -0.1266, -0.0871,  0.1554,\n",
       "                        0.1419, -0.1705,  0.0157,  0.0712,  0.1417, -0.1621, -0.0228, -0.0569,\n",
       "                        0.0531, -0.1353,  0.0097,  0.1332, -0.0121, -0.0882,  0.1088,  0.0220,\n",
       "                       -0.0794, -0.1683,  0.0839, -0.1532,  0.1629, -0.0941],\n",
       "                      [ 0.0139,  0.1496,  0.1278,  0.1736, -0.0365,  0.0561, -0.0920,  0.1572,\n",
       "                       -0.1698,  0.1433, -0.1090,  0.1988, -0.1477, -0.0113, -0.0279, -0.0230,\n",
       "                        0.1286, -0.2661, -0.1053, -0.2476, -0.0334,  0.0489, -0.1123,  0.1519,\n",
       "                        0.0343,  0.1453, -0.1479, -0.1022, -0.0973,  0.1987],\n",
       "                      [-0.0451, -0.0068,  0.1559,  0.0502,  0.2455,  0.1906,  0.1594, -0.0284,\n",
       "                       -0.0170, -0.0334, -0.0286,  0.0820, -0.0890, -0.0518, -0.0199,  0.0817,\n",
       "                        0.0523,  0.2305,  0.0706,  0.0398,  0.1463,  0.1522, -0.0632,  0.0970,\n",
       "                       -0.0727,  0.0153, -0.0963,  0.2272,  0.1105,  0.1709],\n",
       "                      [-0.0118,  0.1376, -0.0742,  0.1330, -0.0800,  0.0954,  0.0483,  0.1233,\n",
       "                        0.0923, -0.1011, -0.0262, -0.1215, -0.0087, -0.1442, -0.1708, -0.0079,\n",
       "                        0.1374, -0.1625,  0.0166, -0.1008,  0.0901,  0.0133, -0.0214,  0.0702,\n",
       "                       -0.1465, -0.1273, -0.1421,  0.1709,  0.1521, -0.1500],\n",
       "                      [-0.0445, -0.0930, -0.1008,  0.1618, -0.0932,  0.0864,  0.0754, -0.1320,\n",
       "                        0.1140,  0.0313,  0.1491,  0.0089, -0.0875,  0.0286,  0.0374,  0.1229,\n",
       "                       -0.1348,  0.0455,  0.0743,  0.0474, -0.1006, -0.0561, -0.0019,  0.0327,\n",
       "                       -0.1779,  0.0097, -0.1133, -0.0611, -0.0566,  0.0579],\n",
       "                      [-0.1738,  0.0140,  0.0453,  0.0137,  0.0024, -0.1667,  0.0055,  0.1557,\n",
       "                       -0.1557,  0.1561,  0.0586,  0.0290, -0.0513,  0.0797,  0.1494,  0.0166,\n",
       "                       -0.1176, -0.1224,  0.1539, -0.0297, -0.1835, -0.1279, -0.1824, -0.0665,\n",
       "                       -0.1345,  0.0509,  0.0836, -0.0848, -0.0886, -0.0463],\n",
       "                      [-0.0995,  0.0646, -0.0848, -0.0230,  0.2077,  0.1909, -0.1979,  0.0935,\n",
       "                        0.0699,  0.0372, -0.1820,  0.1302,  0.1269,  0.0958, -0.1028, -0.0040,\n",
       "                        0.1780,  0.0837,  0.1740,  0.1542,  0.0937,  0.0981,  0.0153,  0.0937,\n",
       "                       -0.0093,  0.0790,  0.1287,  0.0304,  0.0827,  0.0551],\n",
       "                      [-0.1607,  0.1076,  0.0446, -0.0106, -0.1885, -0.1416, -0.0300, -0.0592,\n",
       "                       -0.1182,  0.1701,  0.0203,  0.0970, -0.0208, -0.0601, -0.1741,  0.0911,\n",
       "                        0.1646, -0.3345, -0.0017,  0.1457, -0.1536, -0.1521,  0.1093,  0.0332,\n",
       "                        0.1335,  0.1403,  0.0788, -0.1491, -0.1427,  0.1636],\n",
       "                      [-0.1580,  0.0219, -0.0461,  0.1288,  0.2939, -0.0923,  0.1304,  0.0373,\n",
       "                       -0.0571, -0.0900, -0.1119, -0.0742, -0.0792,  0.2081, -0.0343,  0.0203,\n",
       "                        0.1380,  0.1977,  0.1730,  0.1518,  0.0885,  0.1798,  0.1636, -0.0195,\n",
       "                        0.1650,  0.1076, -0.0493,  0.1247, -0.1866,  0.1800],\n",
       "                      [-0.1815,  0.1146, -0.0310, -0.1686,  0.0281,  0.1787,  0.2171, -0.0660,\n",
       "                       -0.1046,  0.0542,  0.0411, -0.0222,  0.2312, -0.0907, -0.1044,  0.0322,\n",
       "                       -0.0604,  0.1612,  0.0243,  0.2473,  0.1631,  0.1799, -0.0331, -0.0566,\n",
       "                        0.1602, -0.1481, -0.1481,  0.0881, -0.1948, -0.0034],\n",
       "                      [-0.0550, -0.0758,  0.1563,  0.0257, -0.1761, -0.1094,  0.0388,  0.1148,\n",
       "                       -0.0039,  0.0595,  0.0307,  0.0746,  0.0722, -0.0089, -0.0603,  0.1688,\n",
       "                        0.1383,  0.1351,  0.0032, -0.0826, -0.0979, -0.0502,  0.0546,  0.0472,\n",
       "                        0.1443,  0.1540,  0.1003, -0.1616, -0.0976, -0.1739],\n",
       "                      [ 0.0355, -0.1943,  0.0689,  0.0195, -0.0570, -0.0227,  0.2216,  0.1165,\n",
       "                       -0.0641, -0.0389,  0.0473, -0.1786,  0.0493,  0.1652, -0.1008,  0.0308,\n",
       "                        0.1400, -0.0773,  0.0414,  0.1361,  0.0575, -0.1503,  0.0758, -0.0882,\n",
       "                        0.1459,  0.0830, -0.1780,  0.0059, -0.1188,  0.1268],\n",
       "                      [-0.1821,  0.1617, -0.1250, -0.1963, -0.0132,  0.0671, -0.1612,  0.0263,\n",
       "                       -0.1453, -0.1820,  0.0617, -0.1106, -0.1251,  0.1256,  0.1987,  0.1630,\n",
       "                       -0.1484, -0.0875, -0.0658,  0.0708, -0.0824,  0.1109,  0.0472,  0.0353,\n",
       "                        0.0338,  0.0321, -0.1413, -0.0138, -0.1218, -0.0446],\n",
       "                      [ 0.0962,  0.0799,  0.1465, -0.0815,  0.0054,  0.1842,  0.0787,  0.0894,\n",
       "                        0.0033,  0.1380,  0.1122, -0.1432, -0.0175, -0.0962, -0.1116,  0.0551,\n",
       "                       -0.1159,  0.0425, -0.0184, -0.0383,  0.1232, -0.1142,  0.1292,  0.0829,\n",
       "                        0.0631,  0.1379, -0.0161,  0.1421,  0.0228,  0.0348],\n",
       "                      [ 0.1485, -0.1283, -0.0902, -0.0511, -0.1061, -0.1642, -0.1348, -0.0400,\n",
       "                       -0.0990, -0.1681,  0.0093,  0.0199,  0.0323,  0.1656,  0.0015,  0.1418,\n",
       "                       -0.0553,  0.0447, -0.0142, -0.0254, -0.1903,  0.1366, -0.0275, -0.1590,\n",
       "                        0.0154,  0.1620,  0.0053,  0.0749,  0.1112, -0.1068],\n",
       "                      [ 0.0818,  0.1465,  0.1392,  0.1503, -0.0811, -0.0449, -0.1621, -0.1312,\n",
       "                       -0.0020,  0.1269, -0.0579, -0.1179, -0.1574,  0.0417,  0.0023,  0.0640,\n",
       "                       -0.0549, -0.3127,  0.0752, -0.0402,  0.1086,  0.1613,  0.0201, -0.0735,\n",
       "                        0.0944,  0.1526, -0.0797, -0.0714, -0.0520,  0.0448],\n",
       "                      [ 0.1624, -0.0478,  0.0118,  0.0353, -0.2065,  0.1405,  0.1095,  0.0752,\n",
       "                       -0.0636,  0.0010,  0.1811,  0.1997, -0.1040,  0.0886, -0.1592, -0.0932,\n",
       "                        0.0610, -0.3105, -0.0235,  0.0773,  0.0927, -0.0290, -0.0539,  0.0502,\n",
       "                       -0.0995,  0.0112, -0.1622, -0.3107, -0.0634, -0.1572],\n",
       "                      [ 0.0843,  0.0502, -0.0297,  0.1344,  0.1857, -0.1741,  0.1498, -0.0009,\n",
       "                       -0.1614, -0.1246,  0.0421,  0.0820,  0.1385, -0.0497,  0.1690,  0.1349,\n",
       "                       -0.0564,  0.2004, -0.0362,  0.2798, -0.0237,  0.1579,  0.0646,  0.1562,\n",
       "                        0.0894, -0.1203,  0.0587,  0.3116,  0.0555,  0.1517],\n",
       "                      [ 0.0398, -0.1188, -0.1334, -0.1524,  0.0846,  0.1285,  0.0452,  0.0581,\n",
       "                        0.0003, -0.0645,  0.0749,  0.1171,  0.2266,  0.1834, -0.0976,  0.0173,\n",
       "                       -0.1763,  0.2833, -0.1747,  0.1493,  0.1095, -0.1172,  0.0269,  0.1223,\n",
       "                        0.0325, -0.2208, -0.1469,  0.1197, -0.2129, -0.0747],\n",
       "                      [ 0.1050,  0.0516, -0.0152,  0.0412,  0.0622,  0.1730,  0.0888, -0.0998,\n",
       "                       -0.1736,  0.1387, -0.0636,  0.1365,  0.0048, -0.0638,  0.1309, -0.0601,\n",
       "                       -0.1703,  0.1841, -0.1694, -0.0285, -0.0192,  0.1183,  0.0299,  0.0117,\n",
       "                       -0.1510, -0.0750,  0.1147,  0.0216, -0.0645,  0.0949],\n",
       "                      [-0.0929, -0.0090, -0.1812, -0.1926,  0.1709, -0.0915,  0.1312, -0.1440,\n",
       "                       -0.0772,  0.0086, -0.1597, -0.0301,  0.0107,  0.1317,  0.0615, -0.0243,\n",
       "                        0.1775,  0.0600, -0.1304, -0.0290,  0.0243,  0.0390,  0.1568, -0.0106,\n",
       "                        0.1639, -0.1001, -0.0246,  0.0214, -0.0604,  0.0464],\n",
       "                      [ 0.1567,  0.1141,  0.0611,  0.1906, -0.2312, -0.0584, -0.1879,  0.1424,\n",
       "                        0.1331,  0.0224, -0.0446,  0.1036,  0.1080, -0.1537, -0.1716, -0.1012,\n",
       "                        0.1666,  0.0793, -0.0041, -0.1040,  0.1649, -0.0073, -0.0533,  0.1252,\n",
       "                       -0.0363,  0.1604,  0.0879, -0.0260,  0.0093,  0.1618],\n",
       "                      [ 0.1076, -0.0579,  0.0180, -0.0755,  0.0749, -0.0584,  0.1633, -0.0991,\n",
       "                       -0.1424, -0.0439,  0.1415, -0.0778,  0.1938, -0.0601, -0.0385,  0.0628,\n",
       "                       -0.0600,  0.0156,  0.0287,  0.1040, -0.0927, -0.1013,  0.0125, -0.0482,\n",
       "                        0.0867, -0.2334,  0.1163, -0.0685, -0.0416, -0.0240]])),\n",
       "             ('net.6.bias',\n",
       "              tensor([ 0.1595, -0.0236,  0.1793,  0.0627,  0.0532, -0.1021, -0.0078,  0.1044,\n",
       "                       0.1183, -0.1322,  0.0494, -0.1103,  0.0165,  0.0120,  0.0721,  0.1715,\n",
       "                       0.1297,  0.0400,  0.0428,  0.1091, -0.1594,  0.0205,  0.0845, -0.0720,\n",
       "                      -0.0093, -0.1670, -0.1019,  0.1382,  0.0839,  0.2067])),\n",
       "             ('net.8.weight',\n",
       "              tensor([[ 0.1963,  0.0170, -0.1883, -0.0103,  0.0779, -0.0128,  0.0488,  0.0226,\n",
       "                        0.1218, -0.0388, -0.1733, -0.1211, -0.0725,  0.0077, -0.0217,  0.0852,\n",
       "                       -0.0130,  0.0181, -0.1175,  0.0623,  0.1468, -0.1498,  0.1443,  0.1142,\n",
       "                       -0.1676, -0.0100,  0.1478, -0.0565,  0.0485, -0.0266],\n",
       "                      [-0.0680, -0.1331,  0.0799,  0.1683,  0.0026,  0.0223,  0.1262, -0.0359,\n",
       "                       -0.1185, -0.0571,  0.0716, -0.0342, -0.1402, -0.1258,  0.1501,  0.0045,\n",
       "                        0.0010, -0.1213,  0.1091,  0.2103,  0.0265,  0.0789, -0.0056,  0.0676,\n",
       "                       -0.0477,  0.0570, -0.0312,  0.1937,  0.1683,  0.1517],\n",
       "                      [-0.1693, -0.1423,  0.1159,  0.0224, -0.0065,  0.0203,  0.1510, -0.0526,\n",
       "                       -0.0669, -0.1866, -0.0074, -0.0155, -0.0637, -0.1857, -0.0320,  0.0186,\n",
       "                       -0.0053, -0.0213,  0.0308,  0.1000, -0.0436,  0.1119, -0.0787, -0.1735,\n",
       "                       -0.0019, -0.1004,  0.0250,  0.0176, -0.1337, -0.1283],\n",
       "                      [-0.1230,  0.1569, -0.0909,  0.0863,  0.0136, -0.0883,  0.0245,  0.1103,\n",
       "                        0.1522,  0.1617, -0.0030, -0.0936,  0.0613,  0.0701,  0.1593, -0.0922,\n",
       "                       -0.0276, -0.1030,  0.0460, -0.0791, -0.0766,  0.0559, -0.0611, -0.0218,\n",
       "                       -0.0191, -0.2911,  0.0803, -0.0552,  0.0381, -0.0444],\n",
       "                      [-0.1030,  0.1587,  0.2091,  0.1070,  0.1697, -0.1848, -0.1590,  0.1602,\n",
       "                        0.0990,  0.1076, -0.0384, -0.0215, -0.0951, -0.1161, -0.0978,  0.1581,\n",
       "                        0.1302, -0.0859,  0.0115, -0.0385,  0.0415, -0.0769,  0.0330, -0.1494,\n",
       "                       -0.0606,  0.0209, -0.1634, -0.0154, -0.0182, -0.0321],\n",
       "                      [-0.0846,  0.1080,  0.0918, -0.1178, -0.1349,  0.0736,  0.1290,  0.1507,\n",
       "                       -0.1513, -0.1639, -0.1791,  0.0173,  0.0747,  0.0353,  0.1615,  0.1057,\n",
       "                       -0.0805,  0.0962, -0.0472,  0.1237, -0.1255,  0.0963,  0.1293, -0.0650,\n",
       "                        0.1218,  0.0833,  0.0808, -0.2200, -0.0607,  0.0625],\n",
       "                      [ 0.1447, -0.1631,  0.0708, -0.1803, -0.1102,  0.1342,  0.0502, -0.1357,\n",
       "                       -0.1132, -0.0911, -0.1071,  0.1330, -0.1223,  0.1447, -0.0015, -0.1016,\n",
       "                       -0.1102,  0.0686, -0.1555, -0.0061, -0.0714,  0.1675,  0.0493, -0.0306,\n",
       "                        0.0715, -0.0973, -0.0600,  0.0822,  0.0528, -0.0294],\n",
       "                      [ 0.0726,  0.0738,  0.0564,  0.1107,  0.0272, -0.1608, -0.1131, -0.0049,\n",
       "                        0.0905, -0.0083, -0.0900,  0.1464, -0.1299,  0.1067, -0.1038,  0.0955,\n",
       "                        0.0586, -0.0635, -0.1134,  0.0428, -0.0402, -0.0562, -0.0886,  0.1866,\n",
       "                       -0.0617, -0.2481,  0.0941, -0.0374, -0.1094, -0.0092],\n",
       "                      [ 0.1068, -0.1027, -0.0763,  0.0219,  0.1674,  0.0950,  0.0799, -0.0828,\n",
       "                        0.0150, -0.0231,  0.1731,  0.1271,  0.1150,  0.1487, -0.0631,  0.1020,\n",
       "                       -0.0783, -0.0517,  0.0158, -0.0540,  0.2028, -0.0549,  0.1487,  0.1228,\n",
       "                        0.0188, -0.1331,  0.0344,  0.0876,  0.1089, -0.2074],\n",
       "                      [-0.0005, -0.0625, -0.1209, -0.0585, -0.2317, -0.0341, -0.1002, -0.1408,\n",
       "                       -0.0104,  0.1630, -0.0793,  0.0352,  0.0226, -0.0821,  0.0856,  0.1897,\n",
       "                        0.0181,  0.0656, -0.1189,  0.0080,  0.1818, -0.1520,  0.0236,  0.2036,\n",
       "                       -0.1555, -0.1313,  0.1326, -0.2371,  0.0704, -0.2748],\n",
       "                      [ 0.0476, -0.0837,  0.2278, -0.0404,  0.0070, -0.1096,  0.0268, -0.1605,\n",
       "                       -0.1859,  0.0855,  0.0298, -0.0717, -0.0875,  0.1930, -0.1061,  0.1030,\n",
       "                        0.1098, -0.1387,  0.1989,  0.1006, -0.0601,  0.1653,  0.0790,  0.1468,\n",
       "                        0.1537,  0.1878,  0.0922,  0.0882, -0.1442,  0.2168],\n",
       "                      [-0.0945, -0.1489, -0.1685,  0.1606,  0.0272, -0.1156, -0.0005, -0.1666,\n",
       "                        0.1403,  0.0728,  0.0131,  0.1699,  0.0915,  0.1122, -0.0421, -0.1222,\n",
       "                       -0.0907,  0.0505, -0.0530,  0.0645, -0.0576, -0.1205,  0.1207,  0.0608,\n",
       "                       -0.0666, -0.3152,  0.1058, -0.0078,  0.0806,  0.0310],\n",
       "                      [-0.0952,  0.0136, -0.0897, -0.0941, -0.0595,  0.0065,  0.0141,  0.1423,\n",
       "                       -0.0230,  0.0794, -0.0689, -0.0026, -0.1169, -0.1205,  0.0372, -0.0516,\n",
       "                        0.1401,  0.0416, -0.0234, -0.1603, -0.0762,  0.1299,  0.1215, -0.1772,\n",
       "                       -0.0431, -0.0879,  0.0095,  0.0992,  0.1049, -0.0163],\n",
       "                      [ 0.0364,  0.0481,  0.1569, -0.1182,  0.0467,  0.0434,  0.1685,  0.0403,\n",
       "                        0.0442,  0.0198,  0.0948, -0.0927, -0.1239, -0.1415,  0.1050, -0.0812,\n",
       "                       -0.1343,  0.0761, -0.2007,  0.0752,  0.0158,  0.0467,  0.0628,  0.1258,\n",
       "                        0.1558, -0.0164, -0.1861,  0.0672,  0.0912,  0.0967],\n",
       "                      [ 0.1884, -0.0271, -0.3923,  0.2305,  0.1756, -0.1554,  0.1524, -0.0677,\n",
       "                        0.0718,  0.0518, -0.0330, -0.1153,  0.0414, -0.0129,  0.0627, -0.0248,\n",
       "                        0.1918, -0.1650,  0.2987, -0.1765, -0.1422,  0.1472,  0.0249, -0.1718,\n",
       "                       -0.2814, -0.4517, -0.1039,  0.4159, -0.0165,  0.1857],\n",
       "                      [ 0.0121,  0.0025,  0.2808, -0.1581, -0.0771, -0.0611, -0.1389, -0.0843,\n",
       "                       -0.0607, -0.0122,  0.1758,  0.0438,  0.0610,  0.1418,  0.1247, -0.1240,\n",
       "                        0.0012,  0.1313,  0.1667,  0.1622, -0.0140,  0.0224,  0.0091, -0.1803,\n",
       "                        0.2016,  0.2185,  0.1034, -0.0595, -0.0298,  0.1561],\n",
       "                      [-0.0549, -0.1809,  0.1905, -0.1615,  0.1459,  0.0171,  0.0615, -0.1743,\n",
       "                       -0.0425,  0.1347,  0.1028, -0.0439,  0.1722, -0.0317, -0.2266,  0.2501,\n",
       "                       -0.0011, -0.0883, -0.0705,  0.0922,  0.0191,  0.0288, -0.0740, -0.0807,\n",
       "                        0.2585,  0.2375,  0.0888,  0.0217,  0.1154,  0.1805],\n",
       "                      [ 0.0276, -0.1146,  0.0450,  0.1317,  0.2427, -0.0208,  0.0957, -0.1740,\n",
       "                        0.0212,  0.1774,  0.0968, -0.0868, -0.0006,  0.1269, -0.1454, -0.0964,\n",
       "                       -0.1102, -0.0924,  0.0205, -0.1031,  0.1009, -0.1109, -0.0737,  0.1937,\n",
       "                        0.0879, -0.1760, -0.0815,  0.0163,  0.1766,  0.1383],\n",
       "                      [-0.0982, -0.0968,  0.1961, -0.0441,  0.0034, -0.1167,  0.1723, -0.1436,\n",
       "                       -0.1428,  0.0469, -0.1142, -0.0565,  0.0776,  0.0791, -0.2907,  0.0665,\n",
       "                        0.1133, -0.1469, -0.0415, -0.0315,  0.1270, -0.1282, -0.1125, -0.0282,\n",
       "                        0.0985,  0.2353,  0.0276, -0.0565, -0.1024,  0.2485],\n",
       "                      [ 0.1581,  0.1663, -0.0454, -0.0282,  0.1373,  0.0978,  0.0049,  0.1005,\n",
       "                       -0.1924,  0.1475, -0.0770,  0.1573, -0.1746, -0.0244, -0.0189, -0.1362,\n",
       "                       -0.0865,  0.0458, -0.0558, -0.1137,  0.0718,  0.0162, -0.1099, -0.0295,\n",
       "                       -0.1547,  0.0615, -0.0281,  0.0948,  0.0449, -0.1182],\n",
       "                      [ 0.1861,  0.0859, -0.2132,  0.1384, -0.2629,  0.0066, -0.0434,  0.0931,\n",
       "                        0.0769,  0.0766, -0.1390,  0.0818, -0.0036,  0.0814, -0.0259,  0.0118,\n",
       "                        0.1439, -0.1602,  0.1717,  0.0208,  0.1877,  0.0861, -0.1072, -0.0745,\n",
       "                        0.0827, -0.2196, -0.0961, -0.1630,  0.1067, -0.0427],\n",
       "                      [-0.1763, -0.1625,  0.1693, -0.1150,  0.0689,  0.0201, -0.0886,  0.0692,\n",
       "                        0.0302,  0.1609,  0.0434, -0.1389,  0.0878,  0.1674, -0.1474,  0.0387,\n",
       "                        0.1275, -0.2260, -0.0822, -0.1722, -0.0197, -0.1782,  0.0447, -0.0571,\n",
       "                        0.1597, -0.0575, -0.0997, -0.0184, -0.1386,  0.0944],\n",
       "                      [ 0.0234,  0.0532,  0.0757, -0.0714, -0.1481, -0.1299, -0.0071, -0.1785,\n",
       "                       -0.0793,  0.1064,  0.0200,  0.0268,  0.1701,  0.0028,  0.1522, -0.0632,\n",
       "                       -0.2126,  0.1571,  0.1181,  0.1097, -0.0541, -0.0971,  0.0795, -0.1958,\n",
       "                        0.0827,  0.0917, -0.0058, -0.1193,  0.0094, -0.0313],\n",
       "                      [ 0.1337, -0.1597, -0.0091,  0.2058,  0.1083,  0.1110, -0.0079,  0.1785,\n",
       "                       -0.0323,  0.0839,  0.1577, -0.1188, -0.1510, -0.0009, -0.0277,  0.0567,\n",
       "                        0.0926,  0.0095, -0.1129, -0.1708, -0.0280,  0.0477,  0.0662,  0.1445,\n",
       "                       -0.1603, -0.1847, -0.1150, -0.0456,  0.0371,  0.1009],\n",
       "                      [-0.1950,  0.0356, -0.0836, -0.0422,  0.0879, -0.1090,  0.0785, -0.1226,\n",
       "                        0.1261, -0.0716, -0.0020, -0.1741,  0.0114, -0.1879, -0.1632, -0.0791,\n",
       "                        0.1044, -0.0053, -0.1283, -0.1791,  0.1348,  0.1576, -0.0649, -0.0848,\n",
       "                       -0.0977, -0.1154, -0.0845,  0.0446, -0.0853,  0.0964],\n",
       "                      [-0.0037, -0.1201,  0.0126, -0.1563, -0.0611,  0.0432,  0.0256, -0.0036,\n",
       "                       -0.1239,  0.1627,  0.1260,  0.0978, -0.1479, -0.0799, -0.2596,  0.1054,\n",
       "                        0.1777,  0.0765,  0.0845,  0.0713, -0.0706, -0.0581, -0.1461,  0.0021,\n",
       "                       -0.0807, -0.1393, -0.0869,  0.0114, -0.0669, -0.0694],\n",
       "                      [ 0.1091,  0.1051,  0.1570,  0.1865,  0.2296,  0.0389, -0.0343, -0.0986,\n",
       "                       -0.1289,  0.1425,  0.0226, -0.0933,  0.0243,  0.1482,  0.1835,  0.1044,\n",
       "                        0.0991,  0.0848, -0.0113, -0.1665,  0.0945,  0.0634, -0.0642, -0.0025,\n",
       "                       -0.1051,  0.0506, -0.0710,  0.1593, -0.1387,  0.1641],\n",
       "                      [ 0.1113,  0.1696, -0.1787,  0.0907,  0.0215, -0.0667, -0.0690,  0.0893,\n",
       "                       -0.1311, -0.0737, -0.1481, -0.0905, -0.1358,  0.0482, -0.1529, -0.0946,\n",
       "                        0.1175, -0.1243,  0.0960,  0.1097,  0.0462,  0.1181, -0.0718, -0.0496,\n",
       "                        0.0423,  0.0587, -0.1644, -0.1929, -0.0255,  0.0173],\n",
       "                      [-0.0706,  0.0641,  0.1317, -0.1275, -0.0066,  0.0366,  0.0400,  0.1252,\n",
       "                       -0.1387,  0.1159,  0.0857,  0.1781,  0.1114, -0.0089, -0.1400, -0.0765,\n",
       "                        0.1173, -0.0360,  0.2013,  0.1281,  0.0143,  0.0359,  0.1234, -0.0702,\n",
       "                        0.1565,  0.1783, -0.0113, -0.0284, -0.0830,  0.0280],\n",
       "                      [ 0.0738,  0.0513,  0.0513, -0.1636,  0.0687,  0.1317, -0.1542, -0.1375,\n",
       "                       -0.0775,  0.1301,  0.1227,  0.0576, -0.0654, -0.0240, -0.2097,  0.1105,\n",
       "                        0.1477, -0.0138, -0.0060,  0.1466, -0.0423, -0.1252, -0.1929, -0.1021,\n",
       "                        0.2435,  0.0625,  0.1208,  0.1626, -0.0272,  0.1678]])),\n",
       "             ('net.8.bias',\n",
       "              tensor([ 0.0089,  0.1159, -0.1171,  0.2008,  0.1057, -0.0321, -0.0207, -0.1094,\n",
       "                      -0.0795, -0.0316,  0.0859,  0.2144, -0.0671, -0.1687,  0.2775,  0.0607,\n",
       "                       0.1424, -0.0791,  0.1266,  0.0941,  0.0426, -0.1511,  0.0250,  0.0431,\n",
       "                       0.1256,  0.1483, -0.1368,  0.0156,  0.1885,  0.1865])),\n",
       "             ('net.10.weight',\n",
       "              tensor([[ 0.1349,  0.0138,  0.0563,  0.1749, -0.1547,  0.1051, -0.0778, -0.0030,\n",
       "                       -0.0154,  0.0962, -0.1064,  0.1804, -0.0317, -0.0093,  0.2760, -0.0005,\n",
       "                       -0.0417,  0.1241, -0.2530, -0.0717,  0.0612, -0.0988,  0.0141,  0.1218,\n",
       "                        0.1284,  0.0823,  0.1595,  0.0215, -0.1149,  0.0725],\n",
       "                      [-0.0912, -0.0256,  0.1580, -0.1782,  0.0672,  0.1376,  0.0580,  0.0383,\n",
       "                       -0.1231, -0.0508,  0.1107, -0.0443,  0.0520, -0.0657, -0.0950,  0.1544,\n",
       "                       -0.0986,  0.0343, -0.0832, -0.0074, -0.0172,  0.0149, -0.0050,  0.1457,\n",
       "                        0.0937,  0.0439, -0.1064, -0.1528, -0.0125, -0.1402],\n",
       "                      [ 0.0726,  0.1516,  0.0146, -0.0215, -0.0602,  0.0239,  0.1172, -0.1341,\n",
       "                       -0.0100,  0.0229, -0.1355,  0.0099,  0.0279,  0.0317,  0.1963,  0.1782,\n",
       "                        0.0325, -0.0723, -0.0882, -0.0753,  0.1726, -0.1751,  0.1287,  0.2116,\n",
       "                        0.0503,  0.0604,  0.0323,  0.1386,  0.0615,  0.0302],\n",
       "                      [-0.0009, -0.1445,  0.1017,  0.0292,  0.0029,  0.0697,  0.0988,  0.2590,\n",
       "                        0.0565,  0.1262,  0.1227, -0.1786,  0.0097,  0.0880, -0.0420, -0.2240,\n",
       "                        0.1228, -0.0959,  0.0743, -0.0215, -0.1451, -0.2009, -0.1971,  0.0523,\n",
       "                        0.1714, -0.0034, -0.0082,  0.1351, -0.1793,  0.0679],\n",
       "                      [ 0.0624,  0.0277, -0.1357,  0.1312, -0.0665, -0.0217, -0.1523,  0.1767,\n",
       "                        0.1720,  0.0751,  0.0127,  0.0598, -0.1419, -0.1649,  0.0418, -0.2170,\n",
       "                        0.1283, -0.0935, -0.1465,  0.0200, -0.0646, -0.1830,  0.0171,  0.0408,\n",
       "                        0.0192,  0.1106,  0.1597, -0.0699, -0.0623,  0.1465],\n",
       "                      [-0.0017, -0.1054, -0.1139, -0.0884,  0.0038, -0.0743,  0.1510, -0.0066,\n",
       "                        0.0664, -0.0244,  0.1770, -0.1734,  0.0130, -0.0428, -0.3618,  0.1548,\n",
       "                        0.1572,  0.0973,  0.1638,  0.0782, -0.0643,  0.0778, -0.0351, -0.0385,\n",
       "                        0.0464,  0.1157,  0.1444,  0.1790,  0.0420,  0.0857],\n",
       "                      [ 0.0833,  0.0175, -0.0056, -0.0073,  0.2500,  0.0536,  0.1326, -0.1473,\n",
       "                       -0.1485,  0.0778,  0.2212, -0.1487,  0.0596,  0.0256, -0.2070,  0.2150,\n",
       "                        0.0897,  0.0251,  0.1038,  0.0714, -0.1367,  0.2610,  0.0908,  0.0524,\n",
       "                       -0.0064,  0.0663, -0.0171, -0.0040,  0.1442,  0.1084],\n",
       "                      [ 0.0670, -0.2391,  0.1084, -0.0379,  0.0518, -0.0078, -0.0672,  0.1101,\n",
       "                        0.0800,  0.0641, -0.0332, -0.2061,  0.0134, -0.0324,  0.1970, -0.0324,\n",
       "                       -0.1546,  0.0259,  0.0479,  0.0600, -0.1413,  0.0275, -0.0746, -0.0023,\n",
       "                       -0.0331,  0.1171, -0.0974,  0.0766,  0.1628,  0.1296],\n",
       "                      [ 0.0229, -0.0798,  0.0842, -0.1466,  0.0084,  0.0658,  0.0200,  0.1562,\n",
       "                       -0.1457, -0.2272, -0.1691, -0.1848,  0.0126, -0.1700,  0.0552,  0.1714,\n",
       "                        0.1196, -0.0887,  0.1167,  0.0459,  0.0492,  0.0393, -0.3517,  0.0494,\n",
       "                        0.0713,  0.0619, -0.0750,  0.1302, -0.1029,  0.0582],\n",
       "                      [-0.0657,  0.1414,  0.0426, -0.0838, -0.0041,  0.1173, -0.0606, -0.1197,\n",
       "                       -0.1367,  0.1582, -0.1111, -0.1482, -0.0324, -0.1506, -0.0362,  0.0893,\n",
       "                        0.0809, -0.1238, -0.0993, -0.0461, -0.1041, -0.1454,  0.0383, -0.0490,\n",
       "                       -0.0844,  0.0625,  0.1759,  0.1664, -0.0811,  0.0079],\n",
       "                      [ 0.0725,  0.1614, -0.1518, -0.0972, -0.0943, -0.1443,  0.0154,  0.1386,\n",
       "                       -0.1502, -0.0179,  0.1023,  0.1488,  0.1392, -0.0990, -0.1275, -0.1575,\n",
       "                        0.1043,  0.0098,  0.0937, -0.0574, -0.0547, -0.1181, -0.1352, -0.0707,\n",
       "                        0.1047, -0.1478, -0.1370,  0.1049,  0.0546, -0.0681],\n",
       "                      [ 0.0631, -0.1271, -0.1662,  0.0888, -0.1418,  0.0739, -0.1589, -0.1575,\n",
       "                        0.1566,  0.1770, -0.1418,  0.0013,  0.1616,  0.0402,  0.2267,  0.0705,\n",
       "                       -0.0522,  0.0750,  0.0197,  0.0360,  0.1583, -0.1273,  0.1749, -0.0700,\n",
       "                       -0.1237,  0.0607,  0.1359,  0.1225, -0.0942,  0.0528],\n",
       "                      [ 0.1970,  0.0501, -0.1525,  0.0084,  0.0661,  0.0422,  0.0820,  0.1801,\n",
       "                        0.0405,  0.0399, -0.1353,  0.0245,  0.1432,  0.0569,  0.2686,  0.0226,\n",
       "                       -0.0177,  0.1792, -0.0408, -0.0310,  0.1629, -0.1465, -0.0425,  0.1294,\n",
       "                        0.0994, -0.1968,  0.0686, -0.0428, -0.1535,  0.0710],\n",
       "                      [ 0.0528, -0.0523,  0.0895, -0.1605, -0.1046, -0.1031,  0.0082,  0.2401,\n",
       "                       -0.0583,  0.1144,  0.0561, -0.2165, -0.1815, -0.0205, -0.1517,  0.1734,\n",
       "                        0.2165, -0.0530,  0.1105, -0.0777,  0.0266, -0.0198,  0.1970, -0.0825,\n",
       "                        0.0504, -0.0562,  0.0642, -0.0843, -0.0922, -0.0060],\n",
       "                      [ 0.0880,  0.0299, -0.1633, -0.0862,  0.2147,  0.0155,  0.1776, -0.1148,\n",
       "                        0.0266, -0.0961,  0.1859, -0.0371, -0.1233, -0.1413, -0.2336,  0.0086,\n",
       "                        0.2746, -0.0467,  0.0035,  0.1344,  0.1624,  0.0446,  0.0827, -0.1207,\n",
       "                       -0.1042, -0.0300, -0.0182, -0.0987, -0.0862,  0.2252],\n",
       "                      [-0.1703,  0.0989,  0.0128,  0.1645,  0.0144,  0.1210,  0.1550, -0.0005,\n",
       "                        0.0245, -0.1387,  0.0098, -0.1886,  0.0714,  0.0320, -0.1754, -0.0114,\n",
       "                       -0.1130, -0.1400, -0.1001, -0.1518,  0.0484, -0.0324,  0.0333, -0.1573,\n",
       "                        0.0029, -0.1787,  0.1238,  0.0207, -0.1542,  0.0961],\n",
       "                      [ 0.0140,  0.1329, -0.0787,  0.0087,  0.0337,  0.0579,  0.1491,  0.0363,\n",
       "                       -0.0028,  0.0573,  0.2114, -0.0009, -0.0650,  0.1437, -0.2151, -0.1032,\n",
       "                        0.1451,  0.0418,  0.0703, -0.0184, -0.0909,  0.2540, -0.0747, -0.0990,\n",
       "                        0.0787,  0.1800, -0.0082, -0.1051, -0.0365,  0.1029],\n",
       "                      [ 0.1193, -0.1582,  0.1710, -0.0504,  0.1351, -0.1595,  0.0746, -0.1770,\n",
       "                       -0.0985, -0.1614,  0.0785, -0.0698,  0.0349,  0.0489,  0.0921,  0.0306,\n",
       "                       -0.0309, -0.1051, -0.0828,  0.0367, -0.1297,  0.0202,  0.0848, -0.0886,\n",
       "                       -0.1782, -0.0133, -0.1803,  0.1031, -0.0325, -0.1651],\n",
       "                      [-0.1355,  0.0976, -0.0301,  0.0789,  0.0890,  0.0703, -0.1291, -0.1133,\n",
       "                        0.0097, -0.1534,  0.1512, -0.1375, -0.1447,  0.0939,  0.0171, -0.0393,\n",
       "                       -0.0483,  0.0480,  0.0604, -0.0259,  0.0567, -0.1614,  0.0881, -0.1509,\n",
       "                       -0.0485,  0.0157, -0.1644,  0.0037, -0.1494, -0.1545],\n",
       "                      [ 0.1892, -0.1258,  0.0228,  0.2064, -0.1699,  0.0162, -0.1214, -0.1519,\n",
       "                       -0.0943,  0.2075,  0.0398,  0.0702,  0.1342, -0.0607,  0.0152, -0.1096,\n",
       "                       -0.0175,  0.1086, -0.1965,  0.0533,  0.0394,  0.0563, -0.0247,  0.0069,\n",
       "                        0.1411,  0.0866, -0.1671, -0.0007,  0.0136, -0.1332],\n",
       "                      [-0.0771, -0.0292,  0.1612, -0.0426, -0.0795,  0.0156,  0.0890,  0.0570,\n",
       "                        0.0167, -0.0099,  0.0408, -0.1012,  0.1710,  0.0161,  0.0196,  0.0833,\n",
       "                       -0.1487, -0.0104,  0.0261,  0.1305,  0.0574,  0.1221, -0.0577, -0.1723,\n",
       "                        0.0787,  0.0576,  0.0030,  0.0426, -0.1414, -0.1806],\n",
       "                      [-0.1683,  0.0618, -0.0249, -0.1414, -0.0523, -0.0355,  0.1602, -0.0241,\n",
       "                        0.0782, -0.1007, -0.0235, -0.1411,  0.0707,  0.1140,  0.0540,  0.1667,\n",
       "                       -0.0349, -0.1691, -0.1061,  0.1425, -0.1400,  0.0941,  0.0951, -0.1378,\n",
       "                       -0.1453, -0.2188,  0.0496,  0.0434,  0.1164, -0.0662],\n",
       "                      [ 0.0441, -0.0267,  0.0476, -0.0670, -0.0163, -0.0573, -0.0271,  0.0487,\n",
       "                       -0.1660,  0.1029,  0.0213,  0.0803,  0.1639, -0.0709,  0.0155, -0.0592,\n",
       "                        0.0448, -0.1709,  0.1199, -0.0004, -0.0959,  0.0317, -0.1138, -0.0088,\n",
       "                        0.0268,  0.0070, -0.1485,  0.1218, -0.1020,  0.0128],\n",
       "                      [-0.0034, -0.1213,  0.0575,  0.0083, -0.1355,  0.0818, -0.1461, -0.1185,\n",
       "                        0.1493, -0.1432, -0.1921, -0.0874,  0.1422,  0.0729, -0.1224, -0.0663,\n",
       "                       -0.0036, -0.1625,  0.0087,  0.1094, -0.0117, -0.0657,  0.1740, -0.0643,\n",
       "                        0.1144,  0.1108,  0.0281,  0.0270,  0.1573, -0.0284],\n",
       "                      [-0.1129,  0.2192,  0.0239,  0.0088,  0.1906, -0.0945, -0.0503,  0.0162,\n",
       "                       -0.1008, -0.0227,  0.2685, -0.0835,  0.1302,  0.1187, -0.2360,  0.1313,\n",
       "                        0.2504,  0.0970,  0.1191, -0.0311,  0.0353,  0.0316, -0.0554, -0.1060,\n",
       "                       -0.1481,  0.1191,  0.2738, -0.0861,  0.1280,  0.1900],\n",
       "                      [-0.0813, -0.0411,  0.1162, -0.0423, -0.0202, -0.3333, -0.0890,  0.0754,\n",
       "                        0.1419, -0.0770, -0.0363,  0.0957,  0.0443,  0.1506, -0.0650,  0.0980,\n",
       "                        0.1022,  0.1094,  0.3059,  0.0711,  0.1330,  0.0265,  0.1155, -0.0991,\n",
       "                        0.0356, -0.2884, -0.1391, -0.1134, -0.1112, -0.0638],\n",
       "                      [-0.0883, -0.0296,  0.1183,  0.1443, -0.1222,  0.1301, -0.0118, -0.1706,\n",
       "                       -0.0730, -0.0764, -0.0622,  0.0344,  0.0490,  0.0628, -0.0882,  0.0028,\n",
       "                        0.0639, -0.1364,  0.1475, -0.1404,  0.0427, -0.0108, -0.0177, -0.1328,\n",
       "                        0.1726,  0.1686,  0.0501, -0.0015, -0.0046, -0.1544],\n",
       "                      [-0.0922,  0.1580, -0.1491, -0.0660, -0.0776,  0.1813, -0.0279,  0.0693,\n",
       "                       -0.1316,  0.0426,  0.0985,  0.0454,  0.0312, -0.0943, -0.2972,  0.0602,\n",
       "                        0.0194,  0.1206,  0.2507, -0.0050,  0.1553,  0.1024, -0.1114, -0.1402,\n",
       "                       -0.0655,  0.0828, -0.0064,  0.1017,  0.2029,  0.2356],\n",
       "                      [ 0.0643,  0.0453,  0.0290,  0.2108, -0.0857,  0.0264,  0.0046, -0.0166,\n",
       "                        0.0654, -0.0117, -0.1610,  0.1362,  0.0049,  0.0363,  0.0240, -0.0495,\n",
       "                       -0.2125,  0.2068, -0.2930, -0.1040,  0.1149,  0.1064, -0.0789,  0.0043,\n",
       "                       -0.0776,  0.1107,  0.0270,  0.0334,  0.0454, -0.0620],\n",
       "                      [-0.0142,  0.1812,  0.1740, -0.1059, -0.1219, -0.1096,  0.0716, -0.0952,\n",
       "                        0.1570,  0.0198, -0.1647, -0.1381, -0.0194,  0.0062, -0.1770, -0.0394,\n",
       "                        0.1028, -0.0121, -0.0500, -0.0324,  0.0607, -0.0603, -0.1046,  0.0525,\n",
       "                        0.0684, -0.1471,  0.1527,  0.0989,  0.1093, -0.1870]])),\n",
       "             ('net.10.bias',\n",
       "              tensor([ 0.0376, -0.1736, -0.1054, -0.1614, -0.0457, -0.0246,  0.0687, -0.0830,\n",
       "                      -0.2814, -0.1598, -0.1637, -0.0077,  0.0107,  0.1277,  0.0519, -0.0815,\n",
       "                      -0.1267, -0.0653, -0.0810,  0.1528, -0.0705, -0.0632, -0.0725, -0.0531,\n",
       "                       0.2064, -0.2029, -0.1101,  0.0465, -0.0780, -0.1401])),\n",
       "             ('net.12.weight',\n",
       "              tensor([[-0.2054,  0.0174, -0.0540, -0.0609, -0.1525,  0.1946,  0.1769, -0.0274,\n",
       "                       -0.2316, -0.1529,  0.0713, -0.0415, -0.1501,  0.1519,  0.1173, -0.0115,\n",
       "                        0.2095,  0.1354, -0.0914, -0.0704,  0.1231, -0.1353, -0.0522, -0.0398,\n",
       "                        0.1821,  0.0444, -0.1319,  0.1499, -0.1597, -0.0632]])),\n",
       "             ('net.12.bias', tensor([0.1991]))])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fa2069f0-c549-4c5c-be5c-c8acd521095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_trajs = list(\n",
    "    np.load(\"../../data/raw_feat/cv_dist_spin_anton.npy\", allow_pickle=True)\n",
    ")\n",
    "cv_trajs.extend(np.load(\"../../data/raw_feat/cv_dist_spin_anton2.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4884235d-6e3d-450e-a02d-b2b77ff06c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_labels = []\n",
    "for r in (\"R217\", \"R223\", \"R226\", \"R229\", \"R232\"):\n",
    "    for n in (\"D129\", \"D136\", \"D151\", \"D164\", \"E183\", \"D186\"):\n",
    "        sb_labels.append(f\"{r} - {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "68ea6632-4d27-492f-86a4-e81d4ea94618",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_trajs = list(np.load(\"../../data/raw_feat/feat2_raw_anton.npy\", allow_pickle=True))\n",
    "sb_trajs.extend(np.load(\"../../data/raw_feat/feat2_raw_anton2.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fa8ba8fb-dbdd-40f3-a078-fc6c72976359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4150115, 2) (4150115, 60)\n"
     ]
    }
   ],
   "source": [
    "cv_arr = np.concatenate(cv_trajs)\n",
    "sb_arr = np.concatenate(sb_trajs)\n",
    "print(cv_arr.shape, sb_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4b572d82-3db1-4bb8-941f-8d67c5b6e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load committors\n",
    "q = np.load(\"../../data/feat2_dist_du_anton2/qp_downup_3.npy\", allow_pickle=True)[8] # 50 ns\n",
    "w = np.load(\"../../data/feat2_dist_du_anton2/weights_3_feat5ivac.npy\", allow_pickle=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e19724fb-c23f-4468-b5bf-67ea17290dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4150115, 62]) torch.Size([4150115, 1])\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor(np.hstack((cv_arr, sb_arr)))\n",
    "y = torch.Tensor(np.concatenate(q)).unsqueeze(-1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "92b6d4b8-0e26-483a-810c-f9b49e0377dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_dataset = ga.CommittorDataset(X, y)\n",
    "batch_size=16384\n",
    "batches = torch.utils.data.DataLoader(\n",
    "    q_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8fbb3df6-3e6e-4c2b-86ec-a4dae6b842d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = ga.Individual(mlp_constructor, model_args, {}, feature_list, training_fn, torch.optim.Adam, fitness_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "95cc4421-0a9e-4b46-9fe4-b9435cf4908e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16384x62 and 3x30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/jobs/3806103/ipykernel_2291647/3176517082.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/project/dinner/scguo/ci-vsd/notebooks/nn/ga.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataset, **train_params)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/local/jobs/3806103/ipykernel_2291647/2757157570.py\u001b[0m in \u001b[0;36mtraining_fn\u001b[0;34m(model, dataloader, loss_fn, optimizer, **kwargs)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# Compute prediction and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dinner/scguo/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dinner/scguo/ci-vsd/notebooks/nn/ga.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dinner/scguo/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dinner/scguo/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dinner/scguo/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dinner/scguo/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16384x62 and 3x30)"
     ]
    }
   ],
   "source": [
    "i.train(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f34ad38d-2dfd-4a5d-8e71-c1657118a869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MultiLayerNet(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=30, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=30, out_features=1, bias=True)\n",
      "    (13): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Model Args: [3]\n",
      "Model Kwargs: {}\n",
      "Feature set: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61]\n",
      "Training function: <function training_fn at 0x7f1d11340280>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__repr__ returned non-string (type NoneType)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/project/dinner/scguo/anaconda3/envs/py39/lib/python3.9/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dinner/scguo/anaconda3/envs/py39/lib/python3.9/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    392\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                                 \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                             \u001b[0;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dinner/scguo/anaconda3/envs/py39/lib/python3.9/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __repr__ returned non-string (type NoneType)"
     ]
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6f17be-3207-4d05-bef8-524bf05d705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
